# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, grid
# This file is distributed under the same license as the ReNom package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2017.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ReNom 2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2018-02-19 01:26+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.5.3\n"

#: ../../rsts/renom.layers.function.rst:2
msgid "renom.layers.function"
msgstr ""

#: of renom.layers.function.batch_normalize.BatchNormalize:1
msgid ""
"Batch normalization function [1]_. This layer accelerates learning speed "
"with reducing internal covariate shift and allow us to set high learning "
"rate."
msgstr "Batch normalization関数."

#: of renom.layers.function.batch_normalize.BatchNormalize:5
msgid ""
"When the forward propagation, if the argument ``inference`` is set to "
"False this layer calculates moving average of mean and variance. Other "
"wise the ``inference`` is set to True, this layer uses the moving average"
" which calculated in the above mode."
msgstr ""
"順伝播時に引数 ``inference`` "
"にFalseがセットされていた場合,バッチごとの平均、分散を用いてバッチ正規化を行う.さらにそれら平均と分散それぞれの学習時における移動平均が計算される.Trueがセットされていた場合、学習時に取られた統計量の移動平均を用いてバッチ正規化を行う."

#: of renom.layers.function.batch_normalize.BatchNormalize:10
msgid ""
"If the argument mode is set to 'activation', this layer normalizes prior-"
"layer features per unit. Otherwise the argument mode is set to 'feature',"
" this layer normalizes prior-layer features per channel."
msgstr ""
"引数modeに'activation'が与えらた場合, "
"バッチ正規化は各ユニットの出力に対して適用される.modeに'feature'が与えられた場合,バッチ正規化は各チャンネルに対して行われる."

#: of renom.layers.function.batch_normalize.BatchNormalize:13
msgid "The 'feature' mode is only effective for 4D tensor input."
msgstr "上記の理由から'feature'モードは4次元テンソルが入力された場合のみ有効となる."

#: of renom.layers.function.batch_normalize.BatchNormalize:15
#: renom.layers.function.conv2d.Conv2d:9
#: renom.layers.function.deconv2d.Deconv2d:9
#: renom.layers.function.dense.Dense:6
msgid ""
"If the argument `input_size` is passed, this layers' weight is "
"initialized in the __init__ function. Otherwise, the weight is "
"initialized in its first forward calculation."
msgstr ""
"'input_size'が与えられた場合, このレイヤが持つ重みパラメータはレイヤのインスタン化時に初期化される.そうでない場合, "
"重みパラメータは順伝播計算が初めて実行された際にインスタンス化される."

#: of renom.layers.function.batch_normalize.BatchNormalize
#: renom.layers.function.conv2d.Conv2d renom.layers.function.deconv2d.Deconv2d
#: renom.layers.function.dense.Dense renom.layers.function.dropout.Dropout
#: renom.layers.function.dropout.SpatialDropout
#: renom.layers.function.embedding.Embedding renom.layers.function.lrn.Lrn
#: renom.layers.function.lstm.Lstm
#: renom.layers.function.parameterized.Model.load
#: renom.layers.function.parameterized.Model.save
#: renom.layers.function.parameterized.Sequential
#: renom.layers.function.pool2d.AveragePool2d
#: renom.layers.function.pool2d.MaxPool2d
msgid "Parameters"
msgstr ""

#: of renom.layers.function.batch_normalize.BatchNormalize:19
#: renom.layers.function.dense.Dense:12 renom.layers.function.lstm.Lstm:28
msgid "Input unit size."
msgstr "入力ユニットサイズ"

#: of renom.layers.function.batch_normalize.BatchNormalize:21
msgid "Momentum coefficient for the moving average."
msgstr "移動平均計算時に使用するモメンタム係数"

#: of renom.layers.function.batch_normalize.BatchNormalize:23
msgid "'activation'  or 'feature'."
msgstr "'activation' もしくは 'feature'をセット可能"

#: of renom.layers.function.batch_normalize.BatchNormalize:25
msgid "Small number added to avoid division by zero."
msgstr "Zero division エラーを避けるために用いる微小な定数"

#: of renom.layers.function.batch_normalize.BatchNormalize:27
#: renom.layers.function.conv2d.Conv2d:23
#: renom.layers.function.deconv2d.Deconv2d:23
#: renom.layers.function.dense.Dense:14
#: renom.layers.function.embedding.Embedding:17
#: renom.layers.function.lstm.Lstm:30
msgid "Initializer object for weight initialization."
msgstr "重みパラメータの初期値を与えるInitializerオブジェクト."

#: of renom.layers.function.batch_normalize.BatchNormalize:31
#: renom.layers.function.conv2d.Conv2d:27
#: renom.layers.function.deconv2d.Deconv2d:27
#: renom.layers.function.dense.Dense:18
#: renom.layers.function.dropout.Dropout:11
#: renom.layers.function.dropout.SpatialDropout:10
#: renom.layers.function.embedding.Embedding:21
#: renom.layers.function.flatten.Flatten:5 renom.layers.function.lrn.Lrn:22
#: renom.layers.function.lstm.Lstm:34
#: renom.layers.function.parameterized.Model.load:7
#: renom.layers.function.parameterized.Model.save:8
#: renom.layers.function.parameterized.Model.train:5
#: renom.layers.function.parameterized.Model.values:8
#: renom.layers.function.parameterized.Sequential:7
#: renom.layers.function.pool2d.AveragePool2d:12
#: renom.layers.function.pool2d.MaxPool2d:12
msgid "Example"
msgstr ""

#: of renom.layers.function.batch_normalize.BatchNormalize:43
msgid ""
"Sergey Ioffe, Christian Szegedy. Batch Normalization: Accelerating Deep "
"Network Training by Reducing Internal Covariate Shift(2015)"
msgstr ""

#: of renom.layers.function.conv2d.Conv2d:1
#: renom.layers.function.deconv2d.Deconv2d:1
msgid "2d convolution layer."
msgstr "2D畳み込み関数."

#: of renom.layers.function.conv2d.Conv2d:3
#: renom.layers.function.deconv2d.Deconv2d:3
msgid ""
"This class creates a convolution filter to be convolved with the input "
"tensor. The instance of this class only accepts and outputs 4d tensors."
msgstr "このクラスは畳込フィルタを持ち、入力に対してフィルタとの畳込み演算を実行する.4次元テンソルデータのみを入力として受け付ける."

#: of renom.layers.function.conv2d.Conv2d:7
#: renom.layers.function.deconv2d.Deconv2d:7
msgid ""
"At instantiation, in the case of int input, filter, padding, and stride, "
"the shape will be symmetric."
msgstr "インスタンス化時に,フィルタサイズ、パディング、ストッライドなどのパラメータをintもしくはtupleで与えることができる."

#: of renom.layers.function.conv2d.Conv2d:13
#: renom.layers.function.deconv2d.Deconv2d:13
msgid "The dimensionality of the output."
msgstr "出力チャンネル数"

#: of renom.layers.function.conv2d.Conv2d:15
#: renom.layers.function.pool2d.AveragePool2d:4
#: renom.layers.function.pool2d.MaxPool2d:4
msgid "Filter size of the convolution kernel."
msgstr "フィルタサイズ"

#: of renom.layers.function.conv2d.Conv2d:17
#: renom.layers.function.pool2d.AveragePool2d:6
#: renom.layers.function.pool2d.MaxPool2d:6
msgid "Size of the zero-padding around the image."
msgstr "ゼロパディングサイズ"

#: of renom.layers.function.conv2d.Conv2d:19
#: renom.layers.function.pool2d.AveragePool2d:8
#: renom.layers.function.pool2d.MaxPool2d:8
msgid "Stride-size of the convolution."
msgstr "ストライドサイズ"

#: of renom.layers.function.conv2d.Conv2d:21
#: renom.layers.function.deconv2d.Deconv2d:21
msgid "Input unit size. This must be a tuple like (Channel, Height, Width)."
msgstr "入力データサイズ. (channel, height, width)形式のtupleに対応."

#: of renom.layers.function.conv2d.Conv2d:39
msgid "Tensor data format is **NCHW**."
msgstr "テンソルデータのフォーマットは **NCHW**　の並び順となっている."

#: of renom.layers.function.deconv2d.Deconv2d:15
msgid "Filter size to witch used as convolution kernel."
msgstr "フィルタサイズ"

#: of renom.layers.function.deconv2d.Deconv2d:17
msgid "Pad around image by 0 according to this size."
msgstr "ゼロパディングサイズ"

#: of renom.layers.function.deconv2d.Deconv2d:19
msgid "Specifying the strides of the convolution."
msgstr "ストライドサイズ"

#: of renom.layers.function.dense.Dense:1
msgid "Fully connected layer as described bellow."
msgstr "以下の式で表される全結合レイヤ"

#: of renom.layers.function.dense.Dense:3
msgid ":math:`f(x)= w \\cdot x + b`"
msgstr ""

#: of renom.layers.function.dense.Dense:10
#: renom.layers.function.embedding.Embedding:13
#: renom.layers.function.lstm.Lstm:26
msgid "Output unit size."
msgstr "出力ユニットサイズ"

#: of renom.layers.function.dropout.Dropout:1
msgid "Applies Dropout [2]_ to the input."
msgstr "入力に対してドロップアウト [2]_ を適用する."

#: of renom.layers.function.dropout.Dropout:3
msgid ""
"Dropout function randomly selects a fraction (specified by dropout_ratio)"
" of the data sets them to zero. Remaining data will be rescaled by ``1/(1"
" - dropout_ratio)``."
msgstr ""
"``dropout_ratio`` に与えられた割合で入力をランダムに0とする.0とならなかった値に対しては ``1/(1 - "
"dropout_ratio)`` をかけている."

#: of renom.layers.function.dropout.Dropout:7
#: renom.layers.function.dropout.SpatialDropout:4
msgid "Dropout ratio."
msgstr "ドロップアウト率"

#: of renom.layers.function.dropout.Dropout:33
msgid ""
"Hinton, Geoffrey E.; Srivastava, Nitish; Krizhevsky, Alex; Sutskever, "
"Ilya; Salakhutdinov, Ruslan R. (2012). Improving neural networks by "
"preventing co-adaptation of feature detectors"
msgstr ""

#: of renom.layers.function.dropout.SpatialDropout:1
msgid ""
"Applies spatial dropout to the input. This function drops feature maps "
"randomly."
msgstr "チャンネルごとにドロップアウトを適用する."

#: of renom.layers.function.dropout.SpatialDropout
msgid "raises"
msgstr ""

#: of renom.layers.function.dropout.SpatialDropout:7
msgid ""
":exc:`AssertionError` -- An assertion error will be raised if the input "
"tensor dimension is not 4."
msgstr ""

#: of renom.layers.function.dropout.SpatialDropout:35
msgid "SpatialDropout only accepts 4d tensor data."
msgstr "SpatialDropoutは４次元テンソルのみを入力とする."

#: of renom.layers.function.embedding.Embedding:1
msgid ""
"Embedding layer. This layer is the special case of dense layer. The case "
"is that the input value is onehot encoded. Since the onehot encoded input"
" is very sparse, the matrix product performed in the dense layer is "
"redundant."
msgstr ""
"Embedding層. この層は全結合層の特別なケースを表す.Embedding層は入力データがone-"
"hotエンコーディングされた行列である場合に使用できる.One hotエンコーディングされた行列データはスパースであるため, "
"全結合層(Dense)による演算は冗長となる. Embedding層ではone-hotエンコーディングされた入力データを省メモリで扱える."

#: of renom.layers.function.embedding.Embedding:5
msgid "The difference between dense layer and embedding layer is bellow."
msgstr "全結合層とEmbedding層の違いは以下のとおりである."

#: of renom.layers.function.embedding.Embedding:7
msgid "[Dense layer]"
msgstr ""

#: of renom.layers.function.embedding.Embedding:8
msgid "data -> onehot encoding -> onehot data -> dense layer -> embedded data"
msgstr ""

#: of renom.layers.function.embedding.Embedding:10
msgid "[Embedding layer]"
msgstr ""

#: of renom.layers.function.embedding.Embedding:11
msgid "data -> embedding layer -> embedded data"
msgstr ""

#: of renom.layers.function.embedding.Embedding:15
msgid "Input unit size. This is same as number of embedding characters."
msgstr "入力ユニットサイズ. ここで与えられる数はEmbeddingを行う説明変数の数と等しい必要がある."

#: of renom.layers.function.embedding.Embedding:31
msgid ""
"This layer only accepts matrix which shape is (N, 1) and has integer "
"value. *N is batch size."
msgstr "この層はサイズ(N, 1)の行列のみを入力として受け取る. *Nはバッチサイズ."

#: of renom.layers.function.embedding.Embedding:32
msgid "Both ``output_size`` and ``input_size`` must be specified."
msgstr "``output_size``と``input_size``の両方が指定されている必要がある."

#: of renom.layers.function.flatten.Flatten:1
msgid "This function flattens an input tensor. It does not affect the batch size."
msgstr "入力テンソルを二次元テンソルに変形する.第一軸はバッチサイズ、第二軸はデータ次元数となる."

#: of renom.layers.function.lrn.Lrn:1
msgid "Local response normalization function [3]_ ."
msgstr "局所正規化レイヤ."

#: of renom.layers.function.lrn.Lrn:6
msgid ""
":math:`x_{c,i,j}` represents the c th conv filter’s output at the "
"position of (i, j) in the feature map. :math:`y_{c_{out},j,i}` represents"
" the output of local response normalization. :math:`N` is the number of "
"the feature maps. :math:`n` is the adjacent feature map number. The "
"default argument values are recommended."
msgstr ""
":math:`x_{c,i,j}` は第cチャンネルの(i, j)ピクセル値を表す.:math:`y_{c_{out},j,i}` "
"は局所正規化レイヤの出力を表す.:math:`N` は特徴マップ数. :math:`n` "
"正規化に使用される隣接する特徴マップ数.ハイパーパラメータにはデフォルト値を推奨している."

#: of renom.layers.function.lrn.Lrn:12
msgid "Number of images used to be normalized."
msgstr "正規化を行う際に使用される画像数"

#: of renom.layers.function.lrn.Lrn:14
msgid "Constant."
msgstr "定数"

#: of renom.layers.function.lrn.Lrn:16
msgid "Scale factor."
msgstr "係数"

#: of renom.layers.function.lrn.Lrn:18
msgid "Exponential factor."
msgstr "係数"

#: of renom.layers.function.lrn.Lrn:31
msgid ""
"Alex Krizhevsky Krizhevsky, , Ilya IlyaSutskever Sutskever, Geoff. "
"ImageNet Classification with Deep Convolutional Neural Networks"
msgstr ""

#: of renom.layers.function.lstm.Lstm:1
msgid ""
"Long short time memory[4]_ . Lstm object has 8 weights and 4 biases "
"parameters to learn."
msgstr "Lstmレイヤ.このレイヤは8個の重みと4つのバイアスを学習パラメータとして持つ."

#: of renom.layers.function.lstm.Lstm:4
msgid ""
"Weights applied to the input of the input gate, forget gate and output "
"gate. :math:`W_{ij}, Wgi_{ij}, Wgf_{ij}, Wgo_{ij}`"
msgstr "前の層から入力されるデータに対してかけられる重み. :math:`W_{ij}, Wgi_{ij}, Wgf_{ij}, Wgo_{ij}`"

#: of renom.layers.function.lstm.Lstm:7
msgid ""
"Weights applied to the recuurent input of the input gate, forget gate and"
" output gate. :math:`R_{ij}, Rgi_{ij}, Rgf_{ij}, Rgo_{ij}`"
msgstr "一時刻前から入力されるデータに対してかけられる重み. :math:`R_{ij}, Rgi_{ij}, Rgf_{ij}, Rgo_{ij}`"

#: of renom.layers.function.lstm.Lstm:22
msgid ""
"If the argument ``input_size`` is passed, this layers' weight is "
"initialized in the __init__ function. Otherwise, the weight is "
"initialized in its first forward calculation."
msgstr ""
"'input_size'が与えられた場合, このレイヤが持つ重みパラメータはレイヤのインスタン化時に初期化される.そうでない場合, "
"重みパラメータは順伝播計算が初めて実行された際にインスタンス化される."

#: of renom.layers.function.lstm.Lstm:51
msgid "Learning Precise Timing with LSTM Recurrent Networks"
msgstr ""

#: of renom.layers.function.lstm.Lstm.truncate:1
msgid "Truncates temporal connection."
msgstr "時系列方向の計算グラフのつながりを切る."

#: of renom.layers.function.parameterized.Model:1
msgid "Abstract class of neural network model."
msgstr "ニューラルネットワークモデルに関する抽象クラス."

#: of renom.layers.function.parameterized.Model.train:1
msgid ""
"Context manager to control whether a computational graph will be created "
"or not."
msgstr "計算グラフを作成するためのコンテキストを管理するコンテキストマネジャー."

#: of renom.layers.function.parameterized.Model.values:1
msgid "Generates nested tuple of underlying models and params of models."
msgstr "Modelオブジェクトが持つ重みパラメータをネストされたタプルとして返す."

#: of renom.layers.function.parameterized.Model.values:3
msgid ""
"Each model generates tuple of two dictionary. The first dictionary "
"contains child models, keyed by attribute name. The second dictionary "
"contains parameters of the model, keyed by attribute name."
msgstr ""
"Modelオブジェクトは属性としてModelオブジェクトを持つことがある.valuesメソッドを実行すると, "
"それぞれのModelオブジェクトは二つの辞書からなるタプルを返す. ひとつ目の辞書は子要素が持つ重みパラメータを持つ. "
"ふたつ目の辞書にはModel自身(self)が持つ重みパラメータが含まれる."

#: of renom.layers.function.parameterized.Model.join_grads:1
msgid ""
"Merge gradients of other models. Others is a list of tuple of (model, "
"grads) to be merged. Models listed in the others should have same "
"structure with self."
msgstr ""
"引数gradに与えられたGradsオブジェクトが持つ勾配データに対し,引数others(Model, "
"Gradsオブジェクトのタプル)が持つ勾配データを足し合わせる.引数に与えられるすべてのModelオブジェクトは等しい構造を持つ必要がある."

#: of renom.layers.function.parameterized.Model.save:1
msgid ""
"Save model attributes. For save attributes, please register attributes to"
" the dictionary which is named as 'SERIALIZED'."
msgstr ""
"Modelオブジェクトが持つ属性を保存する. 保存したい属性名を'SERIALIZED'という名前のタプルに登録することで, "
"saveメソッドによる保存対象に含むことができる.Modelオブジェクトが持つ重みパラメータはSERIALIZEDに登録せずとも保存される."

#: of renom.layers.function.parameterized.Model.save:5
msgid "Following example shows how to do it."
msgstr "以下にその例を示す."

#: of renom.layers.function.parameterized.Model.save:36
msgid "File name to save model."
msgstr "モデルを保存する際のパス."

#: of renom.layers.function.parameterized.Model.load:1
msgid "Load saved weights to model."
msgstr "保存した属性値をモデルにロードする."

#: of renom.layers.function.parameterized.Model.load:3
msgid "File name of saved model."
msgstr "ロードするモデルのパス"

#: of renom.layers.function.parameterized.Sequential:1
msgid "Sequential model."
msgstr ""

#: of renom.layers.function.parameterized.Sequential:3
msgid "A list of layer objects."
msgstr "レイヤオブジェクトのリスト"

#: of renom.layers.function.pool2d.MaxPool2d:1
msgid ""
"Max pooling function. In the case of int input, filter, padding, and "
"stride, the shape will be symmetric."
msgstr "Max poolingクラス."

#: of renom.layers.function.pool2d.AveragePool2d:1
msgid ""
"Average pooling function. In the case of int input, filter, padding, and "
"stride, the shape will be symmetric."
msgstr "Average poolingクラス."

