# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2017, grid
# This file is distributed under the same license as the ReNom package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2017.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ReNom 2.0\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2017-08-06 17:31+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.3.4\n"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:6
msgid "Tutorial 0.1 Auto Differentiation"
msgstr "チュートリアル 0.1 自動微分"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:8
msgid "This is an introduction of auto differentiation with ReNom."
msgstr "このチュートリアルではニューラルネットワークによる回帰を例にして自動微分の使い方を"
"説明します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:10
msgid ""
"As an example, we create dasets from sin function with small noises and "
"separate it into train dataset and test dataset. Then we define a 2-layer"
" neural network with most naive represantation."
msgstr "ここでは例として、sin関数にノイズを加えた分布から得られたデータを、"
"ニューラルネットワークを用いて回帰する問題を扱います。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:20
msgid "Requiremens"
msgstr "必要なライブラリ"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:22
msgid "In this tutorial, following modules are required."
msgstr "このチュートリアルでは以下のライブラリを必要とします。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:41
msgid "Data preparation"
msgstr "データの準備"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:45
msgid ""
"As stated above, we create an dataset from sin function. The populatoin "
"of our dataset ``population_distribution`` is defined as below."
msgstr "先に述べたとおり、個のチュートリアルではsin関数から得られたデータを使用します。"
"最初に、データを生成する分布である ``population_distribution`` を以下のように定義します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:47
msgid ""
"The train data and test data are generated with regard to "
"``population_distribution``."
msgstr "そして、学習データとテストデータをそれぞれ分布から生成します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:68
msgid ""
"The following graph is the population of generated dataset. The blue one "
"is train set, the orange one is test set."
msgstr "下のグラフは生成されたデータセットの分布を表しています。"
"青いドットは学習セット、オレンジのドットはテストセットを表します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:98
msgid "Neural network definition"
msgstr "ニューラルネットワークの定義"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:100
msgid ""
"We define a 2-layer neural network. It has 2 weight parameters and 2 bias"
" parameters. These parameters are updated with regard to their gradients."
" Thus these paramters are created as a Variable object."
msgstr "ここでは二層ニューラルネットワークを定義します。"
"二層ニューラルネットワークは2つの重みパラメータと2つのバイアスパラメータを持ちます。"
"これらのパラメータについて勾配を計算し、勾配降下法によって更新するために、"
"Variableオブジェクととしてパラメータを定義します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:136
msgid "Training loop"
msgstr "学習ループ"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:138
msgid "Training loop is described below."
msgstr "学習ループは以下の様になります。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:224
msgid "Prediction"
msgstr "予測"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:226
msgid ""
"At the last, we test our model with test dataset. Normally ReNom returns "
"Node object and it contiues to expand the computational graph. For that "
"reason, the method ``as_ndarray`` should be called."
msgstr "最後に学習済みモデルを用いて、テストデータに対する予測を実行します。"
"基本的にReNomの関数は計算の履歴(計算グラフ)を残すためにNodeオブジェクトを返します。"
"そのため計算グラフをこれ以上伸ばす必要がなければ ``as_ndarray`` を呼び出し、"
"Numpyの行列オブジェクトへ変換することを推奨します。"

#: ../../rsts/tutorial0.1-AutomaticDifferentiation.ipynb:243
msgid "We can confirm the model approximates the test dataset population."
msgstr "テストデータに対する予測と、正解データをグラフに重ねて表示し、その予測結果を"
"確認すると、以下のように正解データを回帰する曲線を見ることが出来ます。"

