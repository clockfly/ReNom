# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, grid
# This file is distributed under the same license as the ReNom package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ReNom 2.7\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-02-01 09:24+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../rsts/api/v2/autosum/renom.layers.activation.Selu.rst:2
msgid "renom.layers.activation.Selu"
msgstr ""

#: of renom.layers.activation.Selu:1
msgid ""
"The scaled exponential linear unit [selu]_ activation function is "
"described by the following formula:"
msgstr ""

#: of renom.layers.activation.Selu:4
msgid ""
":math:`a = 1.6732632423543772848170429916717` :math:`b = "
"1.0507009873554804934193349852946` :math:`f(x) = b*max(x, 0)+min(0, "
"exp(x) - a)`"
msgstr ""

#: of renom.layers.activation.Selu
msgid "Parameters"
msgstr ""

#: of renom.layers.activation.Selu:8
msgid "Input numpy array or Node instance."
msgstr ""

#: of renom.layers.activation.Selu:12
msgid "Example"
msgstr ""

#: of renom.layers.activation.Selu:25
msgid ""
"GÃ¼nter Klambauer, Thomas Unterthiner, Andreas Mayr, Sepp Hochreiter. "
"Self-Normalizing Neural Networks. Learning (cs.LG); Machine Learning"
msgstr ""

