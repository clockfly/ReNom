# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2019, grid
# This file is distributed under the same license as the ReNom package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2019.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: ReNom 2.7\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2019-02-01 09:24+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.6.0\n"

#: ../../rsts/api/v2/autosum/renom.optimizer.Adadelta.rst:2
msgid "renom.optimizer.Adadelta"
msgstr ""

#: of renom.optimizer.Adadelta:1
msgid "Adaptive gradient algorithm. [Adagrad]_"
msgstr ""

#: of renom.optimizer.Adadelta
msgid "Parameters"
msgstr ""

#: of renom.optimizer.Adadelta:3
msgid "Decay rate."
msgstr ""

#: of renom.optimizer.Adadelta:5
msgid "Small number in the equation for avoiding zero division."
msgstr ""

#: of renom.optimizer.Adadelta:8
msgid ""
"Duchi, J., Hazan, E., & Singer, Y. Adaptive Subgradient Methods for "
"Online Learning and Stochastic Optimization. Journal of Machine Learning "
"Research, 12, 2121â€“2159."
msgstr ""

