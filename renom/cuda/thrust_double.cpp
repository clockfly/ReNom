/* Generated by Cython 0.26 */

#define PY_SSIZE_T_CLEAN
#include "Python.h"
#ifndef Py_PYTHON_H
    #error Python headers needed to compile C extensions, please install development version of Python.
#elif PY_VERSION_HEX < 0x02060000 || (0x03000000 <= PY_VERSION_HEX && PY_VERSION_HEX < 0x03020000)
    #error Cython requires Python 2.6+ or Python 3.2+.
#else
#define CYTHON_ABI "0_26"
#include <stddef.h>
#ifndef offsetof
  #define offsetof(type, member) ( (size_t) & ((type*)0) -> member )
#endif
#if !defined(WIN32) && !defined(MS_WINDOWS)
  #ifndef __stdcall
    #define __stdcall
  #endif
  #ifndef __cdecl
    #define __cdecl
  #endif
  #ifndef __fastcall
    #define __fastcall
  #endif
#endif
#ifndef DL_IMPORT
  #define DL_IMPORT(t) t
#endif
#ifndef DL_EXPORT
  #define DL_EXPORT(t) t
#endif
#define __PYX_COMMA ,
#ifndef HAVE_LONG_LONG
  #if PY_VERSION_HEX >= 0x03030000 || (PY_MAJOR_VERSION == 2 && PY_VERSION_HEX >= 0x02070000)
    #define HAVE_LONG_LONG
  #endif
#endif
#ifndef PY_LONG_LONG
  #define PY_LONG_LONG LONG_LONG
#endif
#ifndef Py_HUGE_VAL
  #define Py_HUGE_VAL HUGE_VAL
#endif
#ifdef PYPY_VERSION
  #define CYTHON_COMPILING_IN_PYPY 1
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #undef CYTHON_USE_TYPE_SLOTS
  #define CYTHON_USE_TYPE_SLOTS 0
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #undef CYTHON_USE_UNICODE_INTERNALS
  #define CYTHON_USE_UNICODE_INTERNALS 0
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #undef CYTHON_AVOID_BORROWED_REFS
  #define CYTHON_AVOID_BORROWED_REFS 1
  #undef CYTHON_ASSUME_SAFE_MACROS
  #define CYTHON_ASSUME_SAFE_MACROS 0
  #undef CYTHON_UNPACK_METHODS
  #define CYTHON_UNPACK_METHODS 0
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
#elif defined(PYSTON_VERSION)
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 1
  #define CYTHON_COMPILING_IN_CPYTHON 0
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #undef CYTHON_USE_ASYNC_SLOTS
  #define CYTHON_USE_ASYNC_SLOTS 0
  #undef CYTHON_USE_PYLIST_INTERNALS
  #define CYTHON_USE_PYLIST_INTERNALS 0
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #undef CYTHON_USE_UNICODE_WRITER
  #define CYTHON_USE_UNICODE_WRITER 0
  #undef CYTHON_USE_PYLONG_INTERNALS
  #define CYTHON_USE_PYLONG_INTERNALS 0
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #undef CYTHON_FAST_THREAD_STATE
  #define CYTHON_FAST_THREAD_STATE 0
  #undef CYTHON_FAST_PYCALL
  #define CYTHON_FAST_PYCALL 0
#else
  #define CYTHON_COMPILING_IN_PYPY 0
  #define CYTHON_COMPILING_IN_PYSTON 0
  #define CYTHON_COMPILING_IN_CPYTHON 1
  #ifndef CYTHON_USE_TYPE_SLOTS
    #define CYTHON_USE_TYPE_SLOTS 1
  #endif
  #if PY_MAJOR_VERSION < 3
    #undef CYTHON_USE_ASYNC_SLOTS
    #define CYTHON_USE_ASYNC_SLOTS 0
  #elif !defined(CYTHON_USE_ASYNC_SLOTS)
    #define CYTHON_USE_ASYNC_SLOTS 1
  #endif
  #if PY_VERSION_HEX < 0x02070000
    #undef CYTHON_USE_PYLONG_INTERNALS
    #define CYTHON_USE_PYLONG_INTERNALS 0
  #elif !defined(CYTHON_USE_PYLONG_INTERNALS)
    #define CYTHON_USE_PYLONG_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_PYLIST_INTERNALS
    #define CYTHON_USE_PYLIST_INTERNALS 1
  #endif
  #ifndef CYTHON_USE_UNICODE_INTERNALS
    #define CYTHON_USE_UNICODE_INTERNALS 1
  #endif
  #if PY_VERSION_HEX < 0x030300F0
    #undef CYTHON_USE_UNICODE_WRITER
    #define CYTHON_USE_UNICODE_WRITER 0
  #elif !defined(CYTHON_USE_UNICODE_WRITER)
    #define CYTHON_USE_UNICODE_WRITER 1
  #endif
  #ifndef CYTHON_AVOID_BORROWED_REFS
    #define CYTHON_AVOID_BORROWED_REFS 0
  #endif
  #ifndef CYTHON_ASSUME_SAFE_MACROS
    #define CYTHON_ASSUME_SAFE_MACROS 1
  #endif
  #ifndef CYTHON_UNPACK_METHODS
    #define CYTHON_UNPACK_METHODS 1
  #endif
  #ifndef CYTHON_FAST_THREAD_STATE
    #define CYTHON_FAST_THREAD_STATE 1
  #endif
  #ifndef CYTHON_FAST_PYCALL
    #define CYTHON_FAST_PYCALL 1
  #endif
#endif
#if !defined(CYTHON_FAST_PYCCALL)
#define CYTHON_FAST_PYCCALL  (CYTHON_FAST_PYCALL && PY_VERSION_HEX >= 0x030600B1)
#endif
#if CYTHON_USE_PYLONG_INTERNALS
  #include "longintrepr.h"
  #undef SHIFT
  #undef BASE
  #undef MASK
#endif
#if CYTHON_COMPILING_IN_PYPY && PY_VERSION_HEX < 0x02070600 && !defined(Py_OptimizeFlag)
  #define Py_OptimizeFlag 0
#endif
#define __PYX_BUILD_PY_SSIZE_T "n"
#define CYTHON_FORMAT_SSIZE_T "z"
#if PY_MAJOR_VERSION < 3
  #define __Pyx_BUILTIN_MODULE_NAME "__builtin__"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a+k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyClass_Type
#else
  #define __Pyx_BUILTIN_MODULE_NAME "builtins"
  #define __Pyx_PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)\
          PyCode_New(a, k, l, s, f, code, c, n, v, fv, cell, fn, name, fline, lnos)
  #define __Pyx_DefaultClassType PyType_Type
#endif
#ifndef Py_TPFLAGS_CHECKTYPES
  #define Py_TPFLAGS_CHECKTYPES 0
#endif
#ifndef Py_TPFLAGS_HAVE_INDEX
  #define Py_TPFLAGS_HAVE_INDEX 0
#endif
#ifndef Py_TPFLAGS_HAVE_NEWBUFFER
  #define Py_TPFLAGS_HAVE_NEWBUFFER 0
#endif
#ifndef Py_TPFLAGS_HAVE_FINALIZE
  #define Py_TPFLAGS_HAVE_FINALIZE 0
#endif
#if PY_VERSION_HEX < 0x030700A0 || !defined(METH_FASTCALL)
  #ifndef METH_FASTCALL
     #define METH_FASTCALL 0x80
  #endif
  typedef PyObject *(*__Pyx_PyCFunctionFast) (PyObject *self, PyObject **args, Py_ssize_t nargs);
  typedef PyObject *(*__Pyx_PyCFunctionFastWithKeywords) (PyObject *self, PyObject **args,
                                                          Py_ssize_t nargs, PyObject *kwnames);
#else
  #define __Pyx_PyCFunctionFast _PyCFunctionFast
  #define __Pyx_PyCFunctionFastWithKeywords _PyCFunctionFastWithKeywords
#endif
#if CYTHON_FAST_PYCCALL
#define __Pyx_PyFastCFunction_Check(func)\
    ((PyCFunction_Check(func) && (METH_FASTCALL == (PyCFunction_GET_FLAGS(func) & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)))))
#else
#define __Pyx_PyFastCFunction_Check(func) 0
#endif
#if PY_VERSION_HEX > 0x03030000 && defined(PyUnicode_KIND)
  #define CYTHON_PEP393_ENABLED 1
  #define __Pyx_PyUnicode_READY(op)       (likely(PyUnicode_IS_READY(op)) ?\
                                              0 : _PyUnicode_Ready((PyObject *)(op)))
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_LENGTH(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) PyUnicode_READ_CHAR(u, i)
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   PyUnicode_MAX_CHAR_VALUE(u)
  #define __Pyx_PyUnicode_KIND(u)         PyUnicode_KIND(u)
  #define __Pyx_PyUnicode_DATA(u)         PyUnicode_DATA(u)
  #define __Pyx_PyUnicode_READ(k, d, i)   PyUnicode_READ(k, d, i)
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  PyUnicode_WRITE(k, d, i, ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != (likely(PyUnicode_IS_READY(u)) ? PyUnicode_GET_LENGTH(u) : PyUnicode_GET_SIZE(u)))
#else
  #define CYTHON_PEP393_ENABLED 0
  #define PyUnicode_1BYTE_KIND  1
  #define PyUnicode_2BYTE_KIND  2
  #define PyUnicode_4BYTE_KIND  4
  #define __Pyx_PyUnicode_READY(op)       (0)
  #define __Pyx_PyUnicode_GET_LENGTH(u)   PyUnicode_GET_SIZE(u)
  #define __Pyx_PyUnicode_READ_CHAR(u, i) ((Py_UCS4)(PyUnicode_AS_UNICODE(u)[i]))
  #define __Pyx_PyUnicode_MAX_CHAR_VALUE(u)   ((sizeof(Py_UNICODE) == 2) ? 65535 : 1114111)
  #define __Pyx_PyUnicode_KIND(u)         (sizeof(Py_UNICODE))
  #define __Pyx_PyUnicode_DATA(u)         ((void*)PyUnicode_AS_UNICODE(u))
  #define __Pyx_PyUnicode_READ(k, d, i)   ((void)(k), (Py_UCS4)(((Py_UNICODE*)d)[i]))
  #define __Pyx_PyUnicode_WRITE(k, d, i, ch)  (((void)(k)), ((Py_UNICODE*)d)[i] = ch)
  #define __Pyx_PyUnicode_IS_TRUE(u)      (0 != PyUnicode_GET_SIZE(u))
#endif
#if CYTHON_COMPILING_IN_PYPY
  #define __Pyx_PyUnicode_Concat(a, b)      PyNumber_Add(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  PyNumber_Add(a, b)
#else
  #define __Pyx_PyUnicode_Concat(a, b)      PyUnicode_Concat(a, b)
  #define __Pyx_PyUnicode_ConcatSafe(a, b)  ((unlikely((a) == Py_None) || unlikely((b) == Py_None)) ?\
      PyNumber_Add(a, b) : __Pyx_PyUnicode_Concat(a, b))
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyUnicode_Contains)
  #define PyUnicode_Contains(u, s)  PySequence_Contains(u, s)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyByteArray_Check)
  #define PyByteArray_Check(obj)  PyObject_TypeCheck(obj, &PyByteArray_Type)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Format)
  #define PyObject_Format(obj, fmt)  PyObject_CallMethod(obj, "__format__", "O", fmt)
#endif
#if CYTHON_COMPILING_IN_PYPY && !defined(PyObject_Malloc)
  #define PyObject_Malloc(s)   PyMem_Malloc(s)
  #define PyObject_Free(p)     PyMem_Free(p)
  #define PyObject_Realloc(p)  PyMem_Realloc(p)
#endif
#if CYTHON_COMPILING_IN_PYSTON
  #define __Pyx_PyCode_HasFreeVars(co)  PyCode_HasFreeVars(co)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno) PyFrame_SetLineNumber(frame, lineno)
#else
  #define __Pyx_PyCode_HasFreeVars(co)  (PyCode_GetNumFree(co) > 0)
  #define __Pyx_PyFrame_SetLineNumber(frame, lineno)  (frame)->f_lineno = (lineno)
#endif
#define __Pyx_PyString_FormatSafe(a, b)   ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : __Pyx_PyString_Format(a, b))
#define __Pyx_PyUnicode_FormatSafe(a, b)  ((unlikely((a) == Py_None)) ? PyNumber_Remainder(a, b) : PyUnicode_Format(a, b))
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyString_Format(a, b)  PyUnicode_Format(a, b)
#else
  #define __Pyx_PyString_Format(a, b)  PyString_Format(a, b)
#endif
#if PY_MAJOR_VERSION < 3 && !defined(PyObject_ASCII)
  #define PyObject_ASCII(o)            PyObject_Repr(o)
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBaseString_Type            PyUnicode_Type
  #define PyStringObject               PyUnicodeObject
  #define PyString_Type                PyUnicode_Type
  #define PyString_Check               PyUnicode_Check
  #define PyString_CheckExact          PyUnicode_CheckExact
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyBaseString_Check(obj) PyUnicode_Check(obj)
  #define __Pyx_PyBaseString_CheckExact(obj) PyUnicode_CheckExact(obj)
#else
  #define __Pyx_PyBaseString_Check(obj) (PyString_Check(obj) || PyUnicode_Check(obj))
  #define __Pyx_PyBaseString_CheckExact(obj) (PyString_CheckExact(obj) || PyUnicode_CheckExact(obj))
#endif
#ifndef PySet_CheckExact
  #define PySet_CheckExact(obj)        (Py_TYPE(obj) == &PySet_Type)
#endif
#define __Pyx_TypeCheck(obj, type) PyObject_TypeCheck(obj, (PyTypeObject *)type)
#define __Pyx_PyException_Check(obj) __Pyx_TypeCheck(obj, PyExc_Exception)
#if PY_MAJOR_VERSION >= 3
  #define PyIntObject                  PyLongObject
  #define PyInt_Type                   PyLong_Type
  #define PyInt_Check(op)              PyLong_Check(op)
  #define PyInt_CheckExact(op)         PyLong_CheckExact(op)
  #define PyInt_FromString             PyLong_FromString
  #define PyInt_FromUnicode            PyLong_FromUnicode
  #define PyInt_FromLong               PyLong_FromLong
  #define PyInt_FromSize_t             PyLong_FromSize_t
  #define PyInt_FromSsize_t            PyLong_FromSsize_t
  #define PyInt_AsLong                 PyLong_AsLong
  #define PyInt_AS_LONG                PyLong_AS_LONG
  #define PyInt_AsSsize_t              PyLong_AsSsize_t
  #define PyInt_AsUnsignedLongMask     PyLong_AsUnsignedLongMask
  #define PyInt_AsUnsignedLongLongMask PyLong_AsUnsignedLongLongMask
  #define PyNumber_Int                 PyNumber_Long
#endif
#if PY_MAJOR_VERSION >= 3
  #define PyBoolObject                 PyLongObject
#endif
#if PY_MAJOR_VERSION >= 3 && CYTHON_COMPILING_IN_PYPY
  #ifndef PyUnicode_InternFromString
    #define PyUnicode_InternFromString(s) PyUnicode_FromString(s)
  #endif
#endif
#if PY_VERSION_HEX < 0x030200A4
  typedef long Py_hash_t;
  #define __Pyx_PyInt_FromHash_t PyInt_FromLong
  #define __Pyx_PyInt_AsHash_t   PyInt_AsLong
#else
  #define __Pyx_PyInt_FromHash_t PyInt_FromSsize_t
  #define __Pyx_PyInt_AsHash_t   PyInt_AsSsize_t
#endif
#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyMethod_New(func, self, klass) ((self) ? PyMethod_New(func, self) : PyInstanceMethod_New(func))
#else
  #define __Pyx_PyMethod_New(func, self, klass) PyMethod_New(func, self, klass)
#endif
#ifndef __has_attribute
  #define __has_attribute(x) 0
#endif
#ifndef __has_cpp_attribute
  #define __has_cpp_attribute(x) 0
#endif
#if CYTHON_USE_ASYNC_SLOTS
  #if PY_VERSION_HEX >= 0x030500B1
    #define __Pyx_PyAsyncMethodsStruct PyAsyncMethods
    #define __Pyx_PyType_AsAsync(obj) (Py_TYPE(obj)->tp_as_async)
  #else
    typedef struct {
        unaryfunc am_await;
        unaryfunc am_aiter;
        unaryfunc am_anext;
    } __Pyx_PyAsyncMethodsStruct;
    #define __Pyx_PyType_AsAsync(obj) ((__Pyx_PyAsyncMethodsStruct*) (Py_TYPE(obj)->tp_reserved))
  #endif
#else
  #define __Pyx_PyType_AsAsync(obj) NULL
#endif
#ifndef CYTHON_RESTRICT
  #if defined(__GNUC__)
    #define CYTHON_RESTRICT __restrict__
  #elif defined(_MSC_VER) && _MSC_VER >= 1400
    #define CYTHON_RESTRICT __restrict
  #elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define CYTHON_RESTRICT restrict
  #else
    #define CYTHON_RESTRICT
  #endif
#endif
#ifndef CYTHON_UNUSED
# if defined(__GNUC__)
#   if !(defined(__cplusplus)) || (__GNUC__ > 3 || (__GNUC__ == 3 && __GNUC_MINOR__ >= 4))
#     define CYTHON_UNUSED __attribute__ ((__unused__))
#   else
#     define CYTHON_UNUSED
#   endif
# elif defined(__ICC) || (defined(__INTEL_COMPILER) && !defined(_MSC_VER))
#   define CYTHON_UNUSED __attribute__ ((__unused__))
# else
#   define CYTHON_UNUSED
# endif
#endif
#ifndef CYTHON_MAYBE_UNUSED_VAR
#  if defined(__cplusplus)
     template<class T> void CYTHON_MAYBE_UNUSED_VAR( const T& ) { }
#  else
#    define CYTHON_MAYBE_UNUSED_VAR(x) (void)(x)
#  endif
#endif
#ifndef CYTHON_NCP_UNUSED
# if CYTHON_COMPILING_IN_CPYTHON
#  define CYTHON_NCP_UNUSED
# else
#  define CYTHON_NCP_UNUSED CYTHON_UNUSED
# endif
#endif
#define __Pyx_void_to_None(void_result) ((void)(void_result), Py_INCREF(Py_None), Py_None)
#ifdef _MSC_VER
    #ifndef _MSC_STDINT_H_
        #if _MSC_VER < 1300
           typedef unsigned char     uint8_t;
           typedef unsigned int      uint32_t;
        #else
           typedef unsigned __int8   uint8_t;
           typedef unsigned __int32  uint32_t;
        #endif
    #endif
#else
   #include <stdint.h>
#endif
#ifndef CYTHON_FALLTHROUGH
  #ifdef __cplusplus
    #if __has_cpp_attribute(fallthrough)
      #define CYTHON_FALLTHROUGH [[fallthrough]]
    #elif __has_cpp_attribute(clang::fallthrough)
      #define CYTHON_FALLTHROUGH [[clang::fallthrough]]
    #endif
  #endif
  #ifndef CYTHON_FALLTHROUGH
    #if __has_attribute(fallthrough) || (defined(__GNUC__) && defined(__attribute__))
      #define CYTHON_FALLTHROUGH __attribute__((fallthrough))
    #else
      #define CYTHON_FALLTHROUGH
    #endif
  #endif
#endif

#ifndef __cplusplus
  #error "Cython files generated with the C++ option must be compiled with a C++ compiler."
#endif
#ifndef CYTHON_INLINE
  #if defined(__clang__)
    #define CYTHON_INLINE __inline__ __attribute__ ((__unused__))
  #else
    #define CYTHON_INLINE inline
  #endif
#endif
template<typename T>
void __Pyx_call_destructor(T& x) {
    x.~T();
}
template<typename T>
class __Pyx_FakeReference {
  public:
    __Pyx_FakeReference() : ptr(NULL) { }
    __Pyx_FakeReference(const T& ref) : ptr(const_cast<T*>(&ref)) { }
    T *operator->() { return ptr; }
    T *operator&() { return ptr; }
    operator T&() { return *ptr; }
    template<typename U> bool operator ==(U other) { return *ptr == other; }
    template<typename U> bool operator !=(U other) { return *ptr != other; }
  private:
    T *ptr;
};

#if defined(WIN32) || defined(MS_WINDOWS)
  #define _USE_MATH_DEFINES
#endif
#include <math.h>
#ifdef NAN
#define __PYX_NAN() ((float) NAN)
#else
static CYTHON_INLINE float __PYX_NAN() {
  float value;
  memset(&value, 0xFF, sizeof(value));
  return value;
}
#endif
#if defined(__CYGWIN__) && defined(_LDBL_EQ_DBL)
#define __Pyx_truncl trunc
#else
#define __Pyx_truncl truncl
#endif


#define __PYX_ERR(f_index, lineno, Ln_error) \
{ \
  __pyx_filename = __pyx_f[f_index]; __pyx_lineno = lineno; __pyx_clineno = __LINE__; goto Ln_error; \
}

#if PY_MAJOR_VERSION >= 3
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_TrueDivide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceTrueDivide(x,y)
#else
  #define __Pyx_PyNumber_Divide(x,y)         PyNumber_Divide(x,y)
  #define __Pyx_PyNumber_InPlaceDivide(x,y)  PyNumber_InPlaceDivide(x,y)
#endif

#ifndef __PYX_EXTERN_C
  #ifdef __cplusplus
    #define __PYX_EXTERN_C extern "C"
  #else
    #define __PYX_EXTERN_C extern
  #endif
#endif

#define __PYX_HAVE__renom__cuda__thrust_double
#define __PYX_HAVE_API__renom__cuda__thrust_double
#include "thrust_funcs_double.h"
#include <stdint.h>
#ifdef _OPENMP
#include <omp.h>
#endif /* _OPENMP */

#ifdef PYREX_WITHOUT_ASSERTIONS
#define CYTHON_WITHOUT_ASSERTIONS
#endif

typedef struct {PyObject **p; const char *s; const Py_ssize_t n; const char* encoding;
                const char is_unicode; const char is_str; const char intern; } __Pyx_StringTabEntry;

#define __PYX_DEFAULT_STRING_ENCODING_IS_ASCII 0
#define __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT 0
#define __PYX_DEFAULT_STRING_ENCODING ""
#define __Pyx_PyObject_FromString __Pyx_PyBytes_FromString
#define __Pyx_PyObject_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#define __Pyx_uchar_cast(c) ((unsigned char)c)
#define __Pyx_long_cast(x) ((long)x)
#define __Pyx_fits_Py_ssize_t(v, type, is_signed)  (\
    (sizeof(type) < sizeof(Py_ssize_t))  ||\
    (sizeof(type) > sizeof(Py_ssize_t) &&\
          likely(v < (type)PY_SSIZE_T_MAX ||\
                 v == (type)PY_SSIZE_T_MAX)  &&\
          (!is_signed || likely(v > (type)PY_SSIZE_T_MIN ||\
                                v == (type)PY_SSIZE_T_MIN)))  ||\
    (sizeof(type) == sizeof(Py_ssize_t) &&\
          (is_signed || likely(v < (type)PY_SSIZE_T_MAX ||\
                               v == (type)PY_SSIZE_T_MAX)))  )
#if defined (__cplusplus) && __cplusplus >= 201103L
    #include <cstdlib>
    #define __Pyx_sst_abs(value) std::abs(value)
#elif SIZEOF_INT >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) abs(value)
#elif SIZEOF_LONG >= SIZEOF_SIZE_T
    #define __Pyx_sst_abs(value) labs(value)
#elif defined (_MSC_VER) && defined (_M_X64)
    #define __Pyx_sst_abs(value) _abs64(value)
#elif defined (__STDC_VERSION__) && __STDC_VERSION__ >= 199901L
    #define __Pyx_sst_abs(value) llabs(value)
#elif defined (__GNUC__)
    #define __Pyx_sst_abs(value) __builtin_llabs(value)
#else
    #define __Pyx_sst_abs(value) ((value<0) ? -value : value)
#endif
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject*);
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject*, Py_ssize_t* length);
#define __Pyx_PyByteArray_FromString(s) PyByteArray_FromStringAndSize((const char*)s, strlen((const char*)s))
#define __Pyx_PyByteArray_FromStringAndSize(s, l) PyByteArray_FromStringAndSize((const char*)s, l)
#define __Pyx_PyBytes_FromString        PyBytes_FromString
#define __Pyx_PyBytes_FromStringAndSize PyBytes_FromStringAndSize
static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char*);
#if PY_MAJOR_VERSION < 3
    #define __Pyx_PyStr_FromString        __Pyx_PyBytes_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyBytes_FromStringAndSize
#else
    #define __Pyx_PyStr_FromString        __Pyx_PyUnicode_FromString
    #define __Pyx_PyStr_FromStringAndSize __Pyx_PyUnicode_FromStringAndSize
#endif
#define __Pyx_PyObject_AsWritableString(s)    ((char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableSString(s)    ((signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsWritableUString(s)    ((unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsSString(s)    ((const signed char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_AsUString(s)    ((const unsigned char*) __Pyx_PyObject_AsString(s))
#define __Pyx_PyObject_FromCString(s)  __Pyx_PyObject_FromString((const char*)s)
#define __Pyx_PyBytes_FromCString(s)   __Pyx_PyBytes_FromString((const char*)s)
#define __Pyx_PyByteArray_FromCString(s)   __Pyx_PyByteArray_FromString((const char*)s)
#define __Pyx_PyStr_FromCString(s)     __Pyx_PyStr_FromString((const char*)s)
#define __Pyx_PyUnicode_FromCString(s) __Pyx_PyUnicode_FromString((const char*)s)
#if PY_MAJOR_VERSION < 3
static CYTHON_INLINE size_t __Pyx_Py_UNICODE_strlen(const Py_UNICODE *u)
{
    const Py_UNICODE *u_end = u;
    while (*u_end++) ;
    return (size_t)(u_end - u - 1);
}
#else
#define __Pyx_Py_UNICODE_strlen Py_UNICODE_strlen
#endif
#define __Pyx_PyUnicode_FromUnicode(u)       PyUnicode_FromUnicode(u, __Pyx_Py_UNICODE_strlen(u))
#define __Pyx_PyUnicode_FromUnicodeAndLength PyUnicode_FromUnicode
#define __Pyx_PyUnicode_AsUnicode            PyUnicode_AsUnicode
#define __Pyx_NewRef(obj) (Py_INCREF(obj), obj)
#define __Pyx_Owned_Py_None(b) __Pyx_NewRef(Py_None)
#define __Pyx_PyBool_FromLong(b) ((b) ? __Pyx_NewRef(Py_True) : __Pyx_NewRef(Py_False))
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject*);
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x);
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject*);
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t);
#if CYTHON_ASSUME_SAFE_MACROS
#define __pyx_PyFloat_AsDouble(x) (PyFloat_CheckExact(x) ? PyFloat_AS_DOUBLE(x) : PyFloat_AsDouble(x))
#else
#define __pyx_PyFloat_AsDouble(x) PyFloat_AsDouble(x)
#endif
#define __pyx_PyFloat_AsFloat(x) ((float) __pyx_PyFloat_AsDouble(x))
#if PY_MAJOR_VERSION >= 3
#define __Pyx_PyNumber_Int(x) (PyLong_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Long(x))
#else
#define __Pyx_PyNumber_Int(x) (PyInt_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Int(x))
#endif
#define __Pyx_PyNumber_Float(x) (PyFloat_CheckExact(x) ? __Pyx_NewRef(x) : PyNumber_Float(x))
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
static int __Pyx_sys_getdefaultencoding_not_ascii;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    PyObject* ascii_chars_u = NULL;
    PyObject* ascii_chars_b = NULL;
    const char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    if (strcmp(default_encoding_c, "ascii") == 0) {
        __Pyx_sys_getdefaultencoding_not_ascii = 0;
    } else {
        char ascii_chars[128];
        int c;
        for (c = 0; c < 128; c++) {
            ascii_chars[c] = c;
        }
        __Pyx_sys_getdefaultencoding_not_ascii = 1;
        ascii_chars_u = PyUnicode_DecodeASCII(ascii_chars, 128, NULL);
        if (!ascii_chars_u) goto bad;
        ascii_chars_b = PyUnicode_AsEncodedString(ascii_chars_u, default_encoding_c, NULL);
        if (!ascii_chars_b || !PyBytes_Check(ascii_chars_b) || memcmp(ascii_chars, PyBytes_AS_STRING(ascii_chars_b), 128) != 0) {
            PyErr_Format(
                PyExc_ValueError,
                "This module compiled with c_string_encoding=ascii, but default encoding '%.200s' is not a superset of ascii.",
                default_encoding_c);
            goto bad;
        }
        Py_DECREF(ascii_chars_u);
        Py_DECREF(ascii_chars_b);
    }
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    Py_XDECREF(ascii_chars_u);
    Py_XDECREF(ascii_chars_b);
    return -1;
}
#endif
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT && PY_MAJOR_VERSION >= 3
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_DecodeUTF8(c_str, size, NULL)
#else
#define __Pyx_PyUnicode_FromStringAndSize(c_str, size) PyUnicode_Decode(c_str, size, __PYX_DEFAULT_STRING_ENCODING, NULL)
#if __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT
static char* __PYX_DEFAULT_STRING_ENCODING;
static int __Pyx_init_sys_getdefaultencoding_params(void) {
    PyObject* sys;
    PyObject* default_encoding = NULL;
    char* default_encoding_c;
    sys = PyImport_ImportModule("sys");
    if (!sys) goto bad;
    default_encoding = PyObject_CallMethod(sys, (char*) (const char*) "getdefaultencoding", NULL);
    Py_DECREF(sys);
    if (!default_encoding) goto bad;
    default_encoding_c = PyBytes_AsString(default_encoding);
    if (!default_encoding_c) goto bad;
    __PYX_DEFAULT_STRING_ENCODING = (char*) malloc(strlen(default_encoding_c));
    if (!__PYX_DEFAULT_STRING_ENCODING) goto bad;
    strcpy(__PYX_DEFAULT_STRING_ENCODING, default_encoding_c);
    Py_DECREF(default_encoding);
    return 0;
bad:
    Py_XDECREF(default_encoding);
    return -1;
}
#endif
#endif


/* Test for GCC > 2.95 */
#if defined(__GNUC__)     && (__GNUC__ > 2 || (__GNUC__ == 2 && (__GNUC_MINOR__ > 95)))
  #define likely(x)   __builtin_expect(!!(x), 1)
  #define unlikely(x) __builtin_expect(!!(x), 0)
#else /* !__GNUC__ or GCC < 2.95 */
  #define likely(x)   (x)
  #define unlikely(x) (x)
#endif /* __GNUC__ */
static CYTHON_INLINE void __Pyx_pretend_to_initialize(void* ptr) { (void)ptr; }

static PyObject *__pyx_m;
static PyObject *__pyx_d;
static PyObject *__pyx_b;
static PyObject *__pyx_cython_runtime;
static PyObject *__pyx_empty_tuple;
static PyObject *__pyx_empty_bytes;
static PyObject *__pyx_empty_unicode;
static int __pyx_lineno;
static int __pyx_clineno = 0;
static const char * __pyx_cfilenm= __FILE__;
static const char *__pyx_filename;


static const char *__pyx_f[] = {
  "renom/cuda/thrust_funcs.pxi",
  "renom/cuda/thrust_double.pyx",
};

/*--- Type declarations ---*/

/* "renom/cuda/thrust_funcs.pxi":402
 * 
 * 
 * ctypedef void(*REDUCE_FUNC)(VALUE_TYPE * a, const size_t nsize,             # <<<<<<<<<<<<<<
 *                             const size_t axis_size, const size_t elem_size,
 *                             const size_t child_size, VALUE_TYPE * b,
 */
typedef void (*__pyx_t_5renom_4cuda_13thrust_double_REDUCE_FUNC)(VALUE_TYPE *, size_t const , size_t const , size_t const , size_t const , VALUE_TYPE *, size_t const );

/* --- Runtime support code (head) --- */
/* Refnanny.proto */
#ifndef CYTHON_REFNANNY
  #define CYTHON_REFNANNY 0
#endif
#if CYTHON_REFNANNY
  typedef struct {
    void (*INCREF)(void*, PyObject*, int);
    void (*DECREF)(void*, PyObject*, int);
    void (*GOTREF)(void*, PyObject*, int);
    void (*GIVEREF)(void*, PyObject*, int);
    void* (*SetupContext)(const char*, int, const char*);
    void (*FinishContext)(void**);
  } __Pyx_RefNannyAPIStruct;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNanny = NULL;
  static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname);
  #define __Pyx_RefNannyDeclarations void *__pyx_refnanny = NULL;
#ifdef WITH_THREAD
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          if (acquire_gil) {\
              PyGILState_STATE __pyx_gilstate_save = PyGILState_Ensure();\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
              PyGILState_Release(__pyx_gilstate_save);\
          } else {\
              __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__);\
          }
#else
  #define __Pyx_RefNannySetupContext(name, acquire_gil)\
          __pyx_refnanny = __Pyx_RefNanny->SetupContext((name), __LINE__, __FILE__)
#endif
  #define __Pyx_RefNannyFinishContext()\
          __Pyx_RefNanny->FinishContext(&__pyx_refnanny)
  #define __Pyx_INCREF(r)  __Pyx_RefNanny->INCREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_DECREF(r)  __Pyx_RefNanny->DECREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GOTREF(r)  __Pyx_RefNanny->GOTREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_GIVEREF(r) __Pyx_RefNanny->GIVEREF(__pyx_refnanny, (PyObject *)(r), __LINE__)
  #define __Pyx_XINCREF(r)  do { if((r) != NULL) {__Pyx_INCREF(r); }} while(0)
  #define __Pyx_XDECREF(r)  do { if((r) != NULL) {__Pyx_DECREF(r); }} while(0)
  #define __Pyx_XGOTREF(r)  do { if((r) != NULL) {__Pyx_GOTREF(r); }} while(0)
  #define __Pyx_XGIVEREF(r) do { if((r) != NULL) {__Pyx_GIVEREF(r);}} while(0)
#else
  #define __Pyx_RefNannyDeclarations
  #define __Pyx_RefNannySetupContext(name, acquire_gil)
  #define __Pyx_RefNannyFinishContext()
  #define __Pyx_INCREF(r) Py_INCREF(r)
  #define __Pyx_DECREF(r) Py_DECREF(r)
  #define __Pyx_GOTREF(r)
  #define __Pyx_GIVEREF(r)
  #define __Pyx_XINCREF(r) Py_XINCREF(r)
  #define __Pyx_XDECREF(r) Py_XDECREF(r)
  #define __Pyx_XGOTREF(r)
  #define __Pyx_XGIVEREF(r)
#endif
#define __Pyx_XDECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_XDECREF(tmp);\
    } while (0)
#define __Pyx_DECREF_SET(r, v) do {\
        PyObject *tmp = (PyObject *) r;\
        r = v; __Pyx_DECREF(tmp);\
    } while (0)
#define __Pyx_CLEAR(r)    do { PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);} while(0)
#define __Pyx_XCLEAR(r)   do { if((r) != NULL) {PyObject* tmp = ((PyObject*)(r)); r = NULL; __Pyx_DECREF(tmp);}} while(0)

/* PyObjectGetAttrStr.proto */
#if CYTHON_USE_TYPE_SLOTS
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetAttrStr(PyObject* obj, PyObject* attr_name) {
    PyTypeObject* tp = Py_TYPE(obj);
    if (likely(tp->tp_getattro))
        return tp->tp_getattro(obj, attr_name);
#if PY_MAJOR_VERSION < 3
    if (likely(tp->tp_getattr))
        return tp->tp_getattr(obj, PyString_AS_STRING(attr_name));
#endif
    return PyObject_GetAttr(obj, attr_name);
}
#else
#define __Pyx_PyObject_GetAttrStr(o,n) PyObject_GetAttr(o,n)
#endif

/* GetBuiltinName.proto */
static PyObject *__Pyx_GetBuiltinName(PyObject *name);

/* RaiseArgTupleInvalid.proto */
static void __Pyx_RaiseArgtupleInvalid(const char* func_name, int exact,
    Py_ssize_t num_min, Py_ssize_t num_max, Py_ssize_t num_found);

/* RaiseDoubleKeywords.proto */
static void __Pyx_RaiseDoubleKeywordsError(const char* func_name, PyObject* kw_name);

/* ParseKeywords.proto */
static int __Pyx_ParseOptionalKeywords(PyObject *kwds, PyObject **argnames[],\
    PyObject *kwds2, PyObject *values[], Py_ssize_t num_pos_args,\
    const char* function_name);

/* GetModuleGlobalName.proto */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name);

/* PyFunctionFastCall.proto */
#if CYTHON_FAST_PYCALL
#define __Pyx_PyFunction_FastCall(func, args, nargs)\
    __Pyx_PyFunction_FastCallDict((func), (args), (nargs), NULL)
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs);
#else
#define __Pyx_PyFunction_FastCallDict(func, args, nargs, kwargs) _PyFunction_FastCallDict(func, args, nargs, kwargs)
#endif
#endif

/* PyCFunctionFastCall.proto */
#if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject *__Pyx_PyCFunction_FastCall(PyObject *func, PyObject **args, Py_ssize_t nargs);
#else
#define __Pyx_PyCFunction_FastCall(func, args, nargs)  (assert(0), NULL)
#endif

/* PyObjectCall.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw);
#else
#define __Pyx_PyObject_Call(func, arg, kw) PyObject_Call(func, arg, kw)
#endif

/* GetAttr.proto */
static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *, PyObject *);

/* HasAttr.proto */
static CYTHON_INLINE int __Pyx_HasAttr(PyObject *, PyObject *);

/* PyObjectCallMethO.proto */
#if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg);
#endif

/* PyObjectCallOneArg.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg);

/* GetItemInt.proto */
#define __Pyx_GetItemInt(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Fast(o, (Py_ssize_t)i, is_list, wraparound, boundscheck) :\
    (is_list ? (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL) :\
               __Pyx_GetItemInt_Generic(o, to_py_func(i))))
#define __Pyx_GetItemInt_List(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_List_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "list index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
#define __Pyx_GetItemInt_Tuple(o, i, type, is_signed, to_py_func, is_list, wraparound, boundscheck)\
    (__Pyx_fits_Py_ssize_t(i, type, is_signed) ?\
    __Pyx_GetItemInt_Tuple_Fast(o, (Py_ssize_t)i, wraparound, boundscheck) :\
    (PyErr_SetString(PyExc_IndexError, "tuple index out of range"), (PyObject*)NULL))
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              int wraparound, int boundscheck);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j);
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i,
                                                     int is_list, int wraparound, int boundscheck);

/* PyThreadStateGet.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_PyThreadState_declare  PyThreadState *__pyx_tstate;
#define __Pyx_PyThreadState_assign  __pyx_tstate = PyThreadState_GET();
#else
#define __Pyx_PyThreadState_declare
#define __Pyx_PyThreadState_assign
#endif

/* PyErrFetchRestore.proto */
#if CYTHON_FAST_THREAD_STATE
#define __Pyx_ErrRestoreWithState(type, value, tb)  __Pyx_ErrRestoreInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)    __Pyx_ErrFetchInState(PyThreadState_GET(), type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  __Pyx_ErrRestoreInState(__pyx_tstate, type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)    __Pyx_ErrFetchInState(__pyx_tstate, type, value, tb)
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb);
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb);
#else
#define __Pyx_ErrRestoreWithState(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetchWithState(type, value, tb)  PyErr_Fetch(type, value, tb)
#define __Pyx_ErrRestore(type, value, tb)  PyErr_Restore(type, value, tb)
#define __Pyx_ErrFetch(type, value, tb)  PyErr_Fetch(type, value, tb)
#endif

/* RaiseException.proto */
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause);

/* SliceObject.proto */
static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(
        PyObject* obj, Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** py_start, PyObject** py_stop, PyObject** py_slice,
        int has_cstart, int has_cstop, int wraparound);

/* PyIntBinop.proto */
#if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, long intval, int inplace);
#else
#define __Pyx_PyInt_AddObjC(op1, op2, intval, inplace)\
    (inplace ? PyNumber_InPlaceAdd(op1, op2) : PyNumber_Add(op1, op2))
#endif

/* Import.proto */
static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level);

/* RaiseTooManyValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected);

/* RaiseNeedMoreValuesToUnpack.proto */
static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index);

/* IterFinish.proto */
static CYTHON_INLINE int __Pyx_IterFinish(void);

/* UnpackItemEndCheck.proto */
static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected);

/* CLineInTraceback.proto */
static int __Pyx_CLineForTraceback(int c_line);

/* CodeObjectCache.proto */
typedef struct {
    PyCodeObject* code_object;
    int code_line;
} __Pyx_CodeObjectCacheEntry;
struct __Pyx_CodeObjectCache {
    int count;
    int max_count;
    __Pyx_CodeObjectCacheEntry* entries;
};
static struct __Pyx_CodeObjectCache __pyx_code_cache = {0,0,NULL};
static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line);
static PyCodeObject *__pyx_find_code_object(int code_line);
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object);

/* AddTraceback.proto */
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename);

/* CIntToPy.proto */
static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value);

/* CIntFromPy.proto */
static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *);

/* CIntFromPy.proto */
static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *);

/* CheckBinaryVersion.proto */
static int __Pyx_check_binary_version(void);

/* InitStrings.proto */
static int __Pyx_InitStrings(__Pyx_StringTabEntry *t);


/* Module declarations from 'libcpp' */

/* Module declarations from 'libc.stdint' */

/* Module declarations from 'renom.cuda.thrust_double' */
static PyObject *__pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::Operation, PyObject *, PyObject *, PyObject *); /*proto*/
static PyObject *__pyx_f_5renom_4cuda_13thrust_double__reduce_array(PyObject *, PyObject *, __pyx_t_5renom_4cuda_13thrust_double_REDUCE_FUNC); /*proto*/
#define __Pyx_MODULE_NAME "renom.cuda.thrust_double"
int __pyx_module_is_main_renom__cuda__thrust_double = 0;

/* Implementation of 'renom.cuda.thrust_double' */
static PyObject *__pyx_builtin_ValueError;
static const char __pyx_k_A[] = "A";
static const char __pyx_k_K[] = "K";
static const char __pyx_k_M[] = "M";
static const char __pyx_k_N[] = "N";
static const char __pyx_k_e[] = "e";
static const char __pyx_k_h[] = "h";
static const char __pyx_k_i[] = "i";
static const char __pyx_k_j[] = "j";
static const char __pyx_k_n[] = "n";
static const char __pyx_k_s[] = "s";
static const char __pyx_k_u[] = "u";
static const char __pyx_k_v[] = "v";
static const char __pyx_k_w[] = "w";
static const char __pyx_k_x[] = "x";
static const char __pyx_k_y[] = "y";
static const char __pyx_k_z[] = "z";
static const char __pyx_k_ch[] = "ch";
static const char __pyx_k_dr[] = "dr";
static const char __pyx_k_du[] = "du";
static const char __pyx_k_dx[] = "dx";
static const char __pyx_k_dy[] = "dy";
static const char __pyx_k_np[] = "np";
static const char __pyx_k_ps[] = "ps";
static const char __pyx_k_s1[] = "s1";
static const char __pyx_k_s2[] = "s2";
static const char __pyx_k_th[] = "th";
static const char __pyx_k_wc[] = "wc";
static const char __pyx_k_wh[] = "wh";
static const char __pyx_k_arg[] = "arg";
static const char __pyx_k_ary[] = "ary";
static const char __pyx_k_ctr[] = "ctr";
static const char __pyx_k_dot[] = "dot";
static const char __pyx_k_dou[] = "dou";
static const char __pyx_k_drt[] = "drt";
static const char __pyx_k_dwc[] = "dwc";
static const char __pyx_k_end[] = "end";
static const char __pyx_k_mul[] = "__mul__";
static const char __pyx_k_pgf[] = "pgf";
static const char __pyx_k_ptr[] = "_ptr";
static const char __pyx_k_roi[] = "roi";
static const char __pyx_k_ary1[] = "ary1";
static const char __pyx_k_ary2[] = "ary2";
static const char __pyx_k_axis[] = "axis";
static const char __pyx_k_bbox[] = "bbox";
static const char __pyx_k_bias[] = "bias";
static const char __pyx_k_core[] = "core";
static const char __pyx_k_last[] = "last";
static const char __pyx_k_main[] = "__main__";
static const char __pyx_k_outh[] = "outh";
static const char __pyx_k_outw[] = "outw";
static const char __pyx_k_ptr1[] = "ptr1";
static const char __pyx_k_ptr2[] = "ptr2";
static const char __pyx_k_ptr3[] = "ptr3";
static const char __pyx_k_rois[] = "rois";
static const char __pyx_k_size[] = "size";
static const char __pyx_k_step[] = "step";
static const char __pyx_k_temp[] = "temp";
static const char __pyx_k_test[] = "__test__";
static const char __pyx_k_zero[] = "zero";
static const char __pyx_k_cuadd[] = "cuadd";
static const char __pyx_k_cudiv[] = "cudiv";
static const char __pyx_k_cuexp[] = "cuexp";
static const char __pyx_k_cumax[] = "cumax";
static const char __pyx_k_cumin[] = "cumin";
static const char __pyx_k_cumul[] = "cumul";
static const char __pyx_k_cupow[] = "cupow";
static const char __pyx_k_cusub[] = "cusub";
static const char __pyx_k_cusum[] = "cusum";
static const char __pyx_k_dou_n[] = "dou_n";
static const char __pyx_k_dtype[] = "dtype";
static const char __pyx_k_first[] = "first";
static const char __pyx_k_h_ptr[] = "h_ptr";
static const char __pyx_k_input[] = "input";
static const char __pyx_k_max_v[] = "max_v";
static const char __pyx_k_min_v[] = "min_v";
static const char __pyx_k_numpy[] = "numpy";
static const char __pyx_k_prefg[] = "prefg";
static const char __pyx_k_ptr_2[] = "ptr";
static const char __pyx_k_ptr_e[] = "ptr_e";
static const char __pyx_k_ptr_s[] = "ptr_s";
static const char __pyx_k_ptr_u[] = "ptr_u";
static const char __pyx_k_ptr_x[] = "ptr_x";
static const char __pyx_k_ptr_z[] = "ptr_z";
static const char __pyx_k_renom[] = "renom";
static const char __pyx_k_shape[] = "shape";
static const char __pyx_k_size1[] = "size1";
static const char __pyx_k_size2[] = "size2";
static const char __pyx_k_start[] = "start";
static const char __pyx_k_state[] = "state";
static const char __pyx_k_value[] = "value";
static const char __pyx_k_w_ptr[] = "w_ptr";
static const char __pyx_k_width[] = "width";
static const char __pyx_k_x_ptr[] = "x_ptr";
static const char __pyx_k_y_ptr[] = "y_ptr";
static const char __pyx_k_argmax[] = "argmax";
static const char __pyx_k_cufill[] = "cufill";
static const char __pyx_k_culoge[] = "culoge";
static const char __pyx_k_curdiv[] = "curdiv";
static const char __pyx_k_curpow[] = "curpow";
static const char __pyx_k_cusign[] = "cusign";
static const char __pyx_k_cusqrt[] = "cusqrt";
static const char __pyx_k_cutanh[] = "cutanh";
static const char __pyx_k_dx_ptr[] = "dx_ptr";
static const char __pyx_k_dy_ptr[] = "dy_ptr";
static const char __pyx_k_fg_ary[] = "fg_ary";
static const char __pyx_k_gpu_dx[] = "gpu_dx";
static const char __pyx_k_gpu_dy[] = "gpu_dy";
static const char __pyx_k_height[] = "height";
static const char __pyx_k_import[] = "__import__";
static const char __pyx_k_length[] = "length";
static const char __pyx_k_nbytes[] = "nbytes";
static const char __pyx_k_output[] = "output";
static const char __pyx_k_ptr_dr[] = "ptr_dr";
static const char __pyx_k_ptr_du[] = "ptr_du";
static const char __pyx_k_ptr_dx[] = "ptr_dx";
static const char __pyx_k_ptr_dy[] = "ptr_dy";
static const char __pyx_k_ptr_ps[] = "ptr_ps";
static const char __pyx_k_ptr_wc[] = "ptr_wc";
static const char __pyx_k_ratios[] = "ratios";
static const char __pyx_k_reduce[] = "reduce";
static const char __pyx_k_result[] = "result";
static const char __pyx_k_scales[] = "scales";
static const char __pyx_k_shifts[] = "shifts";
static const char __pyx_k_size_1[] = "size_1";
static const char __pyx_k_size_2[] = "size_2";
static const char __pyx_k_weight[] = "weight";
static const char __pyx_k_anchors[] = "anchors";
static const char __pyx_k_arg_ptr[] = "arg_ptr";
static const char __pyx_k_ary_ptr[] = "ary_ptr";
static const char __pyx_k_ctr_ptr[] = "ctr_ptr";
static const char __pyx_k_ith_ary[] = "ith_ary";
static const char __pyx_k_product[] = "product";
static const char __pyx_k_ptr_dot[] = "ptr_dot";
static const char __pyx_k_ptr_dou[] = "ptr_dou";
static const char __pyx_k_ptr_drt[] = "ptr_drt";
static const char __pyx_k_ptr_dwc[] = "ptr_dwc";
static const char __pyx_k_ptr_pfg[] = "ptr_pfg";
static const char __pyx_k_ptr_pgf[] = "ptr_pgf";
static const char __pyx_k_roi_ptr[] = "roi_ptr";
static const char __pyx_k_GPUValue[] = "GPUValue";
static const char __pyx_k_bbox_ptr[] = "bbox_ptr";
static const char __pyx_k_channels[] = "channels";
static const char __pyx_k_cuconcat[] = "cuconcat";
static const char __pyx_k_cunegate[] = "cunegate";
static const char __pyx_k_gpu_ptr1[] = "gpu_ptr1";
static const char __pyx_k_gpu_ptr2[] = "gpu_ptr2";
static const char __pyx_k_operator[] = "operator";
static const char __pyx_k_prestate[] = "prestate";
static const char __pyx_k_ptr_rois[] = "ptr_rois";
static const char __pyx_k_rec_size[] = "rec_size";
static const char __pyx_k_temporal[] = "temporal";
static const char __pyx_k_base_size[] = "base_size";
static const char __pyx_k_cuda_base[] = "cuda_base";
static const char __pyx_k_cusigmoid[] = "cusigmoid";
static const char __pyx_k_functools[] = "functools";
static const char __pyx_k_gpu_index[] = "gpu_index";
static const char __pyx_k_gpu_value[] = "gpu_value";
static const char __pyx_k_index_ptr[] = "index_ptr";
static const char __pyx_k_ptr_dou_n[] = "ptr_dou_n";
static const char __pyx_k_ValueError[] = "ValueError";
static const char __pyx_k_cubinarize[] = "cubinarize";
static const char __pyx_k_gpu_value1[] = "gpu_value1";
static const char __pyx_k_gpu_value2[] = "gpu_value2";
static const char __pyx_k_gpu_value3[] = "gpu_value3";
static const char __pyx_k_length_ptr[] = "length_ptr";
static const char __pyx_k_ptr_argmax[] = "ptr_argmax";
static const char __pyx_k_ratio_size[] = "ratio_size";
static const char __pyx_k_ratios_ptr[] = "ratios_ptr";
static const char __pyx_k_renom_core[] = "renom.core";
static const char __pyx_k_renom_cuda[] = "renom.cuda";
static const char __pyx_k_scale_size[] = "scale_size";
static const char __pyx_k_scales_ptr[] = "scales_ptr";
static const char __pyx_k_shifts_ptr[] = "shifts_ptr";
static const char __pyx_k_threathold[] = "threathold";
static const char __pyx_k_weight_ptr[] = "weight_ptr";
static const char __pyx_k_anchors_ptr[] = "anchors_ptr";
static const char __pyx_k_augmax_data[] = "augmax_data";
static const char __pyx_k_cu_add_bias[] = "cu_add_bias";
static const char __pyx_k_cu_clip_roi[] = "cu_clip_roi";
static const char __pyx_k_cu_pred_ctr[] = "cu_pred_ctr";
static const char __pyx_k_cubroadcast[] = "cubroadcast";
static const char __pyx_k_feat_stride[] = "feat_stride";
static const char __pyx_k_cu_reduce_max[] = "cu_reduce_max";
static const char __pyx_k_cu_reduce_min[] = "cu_reduce_min";
static const char __pyx_k_cuabs_forward[] = "cuabs_forward";
static const char __pyx_k_cueru_forward[] = "cueru_forward";
static const char __pyx_k_curelu_foward[] = "curelu_foward";
static const char __pyx_k_spatial_scale[] = "spatial_scale";
static const char __pyx_k_cuabs_backward[] = "cuabs_backward";
static const char __pyx_k_cueru_backward[] = "cueru_backward";
static const char __pyx_k_culstm_forward[] = "culstm_forward";
static const char __pyx_k_curelu_backard[] = "curelu_backard";
static const char __pyx_k_cu_get_ith_bbox[] = "cu_get_ith_bbox";
static const char __pyx_k_cucross_entropy[] = "cucross_entropy";
static const char __pyx_k_culstm_backward[] = "culstm_backward";
static const char __pyx_k_ptr_augmax_data[] = "ptr_augmax_data";
static const char __pyx_k_check_heap_device[] = "check_heap_device";
static const char __pyx_k_cline_in_traceback[] = "cline_in_traceback";
static const char __pyx_k_cu_assign_pred_box[] = "cu_assign_pred_box";
static const char __pyx_k_cu_generate_anchors[] = "cu_generate_anchors";
static const char __pyx_k_cuembedding_forward[] = "cuembedding_forward";
static const char __pyx_k_cu_get_every_nth_ary[] = "cu_get_every_nth_ary";
static const char __pyx_k_cuembedding_backward[] = "cuembedding_backward";
static const char __pyx_k_culeaky_leru_forward[] = "culeaky_leru_forward";
static const char __pyx_k_curoi_pool2d_forward[] = "curoi_pool2d_forward";
static const char __pyx_k_cu_get_fg_ary_forward[] = "cu_get_fg_ary_forward";
static const char __pyx_k_culeaky_leru_backward[] = "culeaky_leru_backward";
static const char __pyx_k_curoi_pool2d_backward[] = "curoi_pool2d_backward";
static const char __pyx_k_cu_get_fg_ary_backward[] = "cu_get_fg_ary_backward";
static const char __pyx_k_cu_get_ith_ary_forward[] = "cu_get_ith_ary_forward";
static const char __pyx_k_cupeepholelstm_forward[] = "cupeepholelstm_forward";
static const char __pyx_k_cu_get_ith_ary_backward[] = "cu_get_ith_ary_backward";
static const char __pyx_k_culstm_forward_activate[] = "culstm_forward_activate";
static const char __pyx_k_cupeepholelstm_backward[] = "cupeepholelstm_backward";
static const char __pyx_k_renom_cuda_thrust_double[] = "renom.cuda.thrust_double";
static const char __pyx_k_renom_cuda_thrust_funcs_pxi[] = "renom/cuda/thrust_funcs.pxi";
static const char __pyx_k_Insufficient_destination_buffer[] = "Insufficient destination buffer size";
static const char __pyx_k_all_the_input_array_dimensions_e[] = "all the input array dimensions except for the concatenation axis must match exactly";
static const char __pyx_k_zero_dimensional_arrays_cannot_b[] = "zero-dimensional arrays cannot be concatenated";
static PyObject *__pyx_n_s_A;
static PyObject *__pyx_n_s_GPUValue;
static PyObject *__pyx_kp_s_Insufficient_destination_buffer;
static PyObject *__pyx_n_s_K;
static PyObject *__pyx_n_s_M;
static PyObject *__pyx_n_s_N;
static PyObject *__pyx_n_s_ValueError;
static PyObject *__pyx_kp_s_all_the_input_array_dimensions_e;
static PyObject *__pyx_n_s_anchors;
static PyObject *__pyx_n_s_anchors_ptr;
static PyObject *__pyx_n_s_arg;
static PyObject *__pyx_n_s_arg_ptr;
static PyObject *__pyx_n_s_argmax;
static PyObject *__pyx_n_s_ary;
static PyObject *__pyx_n_s_ary1;
static PyObject *__pyx_n_s_ary2;
static PyObject *__pyx_n_s_ary_ptr;
static PyObject *__pyx_n_s_augmax_data;
static PyObject *__pyx_n_s_axis;
static PyObject *__pyx_n_s_base_size;
static PyObject *__pyx_n_s_bbox;
static PyObject *__pyx_n_s_bbox_ptr;
static PyObject *__pyx_n_s_bias;
static PyObject *__pyx_n_s_ch;
static PyObject *__pyx_n_s_channels;
static PyObject *__pyx_n_s_check_heap_device;
static PyObject *__pyx_n_s_cline_in_traceback;
static PyObject *__pyx_n_s_core;
static PyObject *__pyx_n_s_ctr;
static PyObject *__pyx_n_s_ctr_ptr;
static PyObject *__pyx_n_s_cu_add_bias;
static PyObject *__pyx_n_s_cu_assign_pred_box;
static PyObject *__pyx_n_s_cu_clip_roi;
static PyObject *__pyx_n_s_cu_generate_anchors;
static PyObject *__pyx_n_s_cu_get_every_nth_ary;
static PyObject *__pyx_n_s_cu_get_fg_ary_backward;
static PyObject *__pyx_n_s_cu_get_fg_ary_forward;
static PyObject *__pyx_n_s_cu_get_ith_ary_backward;
static PyObject *__pyx_n_s_cu_get_ith_ary_forward;
static PyObject *__pyx_n_s_cu_get_ith_bbox;
static PyObject *__pyx_n_s_cu_pred_ctr;
static PyObject *__pyx_n_s_cu_reduce_max;
static PyObject *__pyx_n_s_cu_reduce_min;
static PyObject *__pyx_n_s_cuabs_backward;
static PyObject *__pyx_n_s_cuabs_forward;
static PyObject *__pyx_n_s_cuadd;
static PyObject *__pyx_n_s_cubinarize;
static PyObject *__pyx_n_s_cubroadcast;
static PyObject *__pyx_n_s_cuconcat;
static PyObject *__pyx_n_s_cucross_entropy;
static PyObject *__pyx_n_s_cuda_base;
static PyObject *__pyx_n_s_cudiv;
static PyObject *__pyx_n_s_cuembedding_backward;
static PyObject *__pyx_n_s_cuembedding_forward;
static PyObject *__pyx_n_s_cueru_backward;
static PyObject *__pyx_n_s_cueru_forward;
static PyObject *__pyx_n_s_cuexp;
static PyObject *__pyx_n_s_cufill;
static PyObject *__pyx_n_s_culeaky_leru_backward;
static PyObject *__pyx_n_s_culeaky_leru_forward;
static PyObject *__pyx_n_s_culoge;
static PyObject *__pyx_n_s_culstm_backward;
static PyObject *__pyx_n_s_culstm_forward;
static PyObject *__pyx_n_s_culstm_forward_activate;
static PyObject *__pyx_n_s_cumax;
static PyObject *__pyx_n_s_cumin;
static PyObject *__pyx_n_s_cumul;
static PyObject *__pyx_n_s_cunegate;
static PyObject *__pyx_n_s_cupeepholelstm_backward;
static PyObject *__pyx_n_s_cupeepholelstm_forward;
static PyObject *__pyx_n_s_cupow;
static PyObject *__pyx_n_s_curdiv;
static PyObject *__pyx_n_s_curelu_backard;
static PyObject *__pyx_n_s_curelu_foward;
static PyObject *__pyx_n_s_curoi_pool2d_backward;
static PyObject *__pyx_n_s_curoi_pool2d_forward;
static PyObject *__pyx_n_s_curpow;
static PyObject *__pyx_n_s_cusigmoid;
static PyObject *__pyx_n_s_cusign;
static PyObject *__pyx_n_s_cusqrt;
static PyObject *__pyx_n_s_cusub;
static PyObject *__pyx_n_s_cusum;
static PyObject *__pyx_n_s_cutanh;
static PyObject *__pyx_n_s_dot;
static PyObject *__pyx_n_s_dou;
static PyObject *__pyx_n_s_dou_n;
static PyObject *__pyx_n_s_dr;
static PyObject *__pyx_n_s_drt;
static PyObject *__pyx_n_s_dtype;
static PyObject *__pyx_n_s_du;
static PyObject *__pyx_n_s_dwc;
static PyObject *__pyx_n_s_dx;
static PyObject *__pyx_n_s_dx_ptr;
static PyObject *__pyx_n_s_dy;
static PyObject *__pyx_n_s_dy_ptr;
static PyObject *__pyx_n_s_e;
static PyObject *__pyx_n_s_end;
static PyObject *__pyx_n_s_feat_stride;
static PyObject *__pyx_n_s_fg_ary;
static PyObject *__pyx_n_s_first;
static PyObject *__pyx_n_s_functools;
static PyObject *__pyx_n_s_gpu_dx;
static PyObject *__pyx_n_s_gpu_dy;
static PyObject *__pyx_n_s_gpu_index;
static PyObject *__pyx_n_s_gpu_ptr1;
static PyObject *__pyx_n_s_gpu_ptr2;
static PyObject *__pyx_n_s_gpu_value;
static PyObject *__pyx_n_s_gpu_value1;
static PyObject *__pyx_n_s_gpu_value2;
static PyObject *__pyx_n_s_gpu_value3;
static PyObject *__pyx_n_s_h;
static PyObject *__pyx_n_s_h_ptr;
static PyObject *__pyx_n_s_height;
static PyObject *__pyx_n_s_i;
static PyObject *__pyx_n_s_import;
static PyObject *__pyx_n_s_index_ptr;
static PyObject *__pyx_n_s_input;
static PyObject *__pyx_n_s_ith_ary;
static PyObject *__pyx_n_s_j;
static PyObject *__pyx_n_s_last;
static PyObject *__pyx_n_s_length;
static PyObject *__pyx_n_s_length_ptr;
static PyObject *__pyx_n_s_main;
static PyObject *__pyx_n_s_max_v;
static PyObject *__pyx_n_s_min_v;
static PyObject *__pyx_n_s_mul;
static PyObject *__pyx_n_s_n;
static PyObject *__pyx_n_s_nbytes;
static PyObject *__pyx_n_s_np;
static PyObject *__pyx_n_s_numpy;
static PyObject *__pyx_n_s_operator;
static PyObject *__pyx_n_s_outh;
static PyObject *__pyx_n_s_output;
static PyObject *__pyx_n_s_outw;
static PyObject *__pyx_n_s_pgf;
static PyObject *__pyx_n_s_prefg;
static PyObject *__pyx_n_s_prestate;
static PyObject *__pyx_n_s_product;
static PyObject *__pyx_n_s_ps;
static PyObject *__pyx_n_s_ptr;
static PyObject *__pyx_n_s_ptr1;
static PyObject *__pyx_n_s_ptr2;
static PyObject *__pyx_n_s_ptr3;
static PyObject *__pyx_n_s_ptr_2;
static PyObject *__pyx_n_s_ptr_argmax;
static PyObject *__pyx_n_s_ptr_augmax_data;
static PyObject *__pyx_n_s_ptr_dot;
static PyObject *__pyx_n_s_ptr_dou;
static PyObject *__pyx_n_s_ptr_dou_n;
static PyObject *__pyx_n_s_ptr_dr;
static PyObject *__pyx_n_s_ptr_drt;
static PyObject *__pyx_n_s_ptr_du;
static PyObject *__pyx_n_s_ptr_dwc;
static PyObject *__pyx_n_s_ptr_dx;
static PyObject *__pyx_n_s_ptr_dy;
static PyObject *__pyx_n_s_ptr_e;
static PyObject *__pyx_n_s_ptr_pfg;
static PyObject *__pyx_n_s_ptr_pgf;
static PyObject *__pyx_n_s_ptr_ps;
static PyObject *__pyx_n_s_ptr_rois;
static PyObject *__pyx_n_s_ptr_s;
static PyObject *__pyx_n_s_ptr_u;
static PyObject *__pyx_n_s_ptr_wc;
static PyObject *__pyx_n_s_ptr_x;
static PyObject *__pyx_n_s_ptr_z;
static PyObject *__pyx_n_s_ratio_size;
static PyObject *__pyx_n_s_ratios;
static PyObject *__pyx_n_s_ratios_ptr;
static PyObject *__pyx_n_s_rec_size;
static PyObject *__pyx_n_s_reduce;
static PyObject *__pyx_n_s_renom;
static PyObject *__pyx_n_s_renom_core;
static PyObject *__pyx_n_s_renom_cuda;
static PyObject *__pyx_n_s_renom_cuda_thrust_double;
static PyObject *__pyx_kp_s_renom_cuda_thrust_funcs_pxi;
static PyObject *__pyx_n_s_result;
static PyObject *__pyx_n_s_roi;
static PyObject *__pyx_n_s_roi_ptr;
static PyObject *__pyx_n_s_rois;
static PyObject *__pyx_n_s_s;
static PyObject *__pyx_n_s_s1;
static PyObject *__pyx_n_s_s2;
static PyObject *__pyx_n_s_scale_size;
static PyObject *__pyx_n_s_scales;
static PyObject *__pyx_n_s_scales_ptr;
static PyObject *__pyx_n_s_shape;
static PyObject *__pyx_n_s_shifts;
static PyObject *__pyx_n_s_shifts_ptr;
static PyObject *__pyx_n_s_size;
static PyObject *__pyx_n_s_size1;
static PyObject *__pyx_n_s_size2;
static PyObject *__pyx_n_s_size_1;
static PyObject *__pyx_n_s_size_2;
static PyObject *__pyx_n_s_spatial_scale;
static PyObject *__pyx_n_s_start;
static PyObject *__pyx_n_s_state;
static PyObject *__pyx_n_s_step;
static PyObject *__pyx_n_s_temp;
static PyObject *__pyx_n_s_temporal;
static PyObject *__pyx_n_s_test;
static PyObject *__pyx_n_s_th;
static PyObject *__pyx_n_s_threathold;
static PyObject *__pyx_n_s_u;
static PyObject *__pyx_n_s_v;
static PyObject *__pyx_n_s_value;
static PyObject *__pyx_n_s_w;
static PyObject *__pyx_n_s_w_ptr;
static PyObject *__pyx_n_s_wc;
static PyObject *__pyx_n_s_weight;
static PyObject *__pyx_n_s_weight_ptr;
static PyObject *__pyx_n_s_wh;
static PyObject *__pyx_n_s_width;
static PyObject *__pyx_n_s_x;
static PyObject *__pyx_n_s_x_ptr;
static PyObject *__pyx_n_s_y;
static PyObject *__pyx_n_s_y_ptr;
static PyObject *__pyx_n_s_z;
static PyObject *__pyx_n_s_zero;
static PyObject *__pyx_kp_s_zero_dimensional_arrays_cannot_b;
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_cunegate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_result); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_2curelu_foward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_4curelu_backard(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_6culeaky_leru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_8culeaky_leru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_10cueru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_12cueru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_14cusigmoid(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_16cutanh(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_18cumul(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_20cuadd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_22cusub(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_24cudiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_26curdiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_28cupow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_30curpow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_32cufill(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_34culoge(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_36cuexp(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_38cusqrt(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_40cusign(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_42cucross_entropy(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_44cubroadcast(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_46cuabs_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_48cuabs_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_50cumin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_52cumax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_54curoi_pool2d_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_rois, PyObject *__pyx_v_x, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_channels, PyObject *__pyx_v_height, PyObject *__pyx_v_width, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_z, PyObject *__pyx_v_augmax_data); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_56curoi_pool2d_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_argmax, PyObject *__pyx_v_rois, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_ch, PyObject *__pyx_v_h, PyObject *__pyx_v_w, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_dx); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_58culstm_forward_activate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_60culstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_z); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_62culstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_du, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_e, PyObject *__pyx_v_pgf, PyObject *__pyx_v_dou, PyObject *__pyx_v_dou_n, PyObject *__pyx_v_temporal); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_64cupeepholelstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_wc, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_z); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_66cupeepholelstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_prefg, PyObject *__pyx_v_wc, PyObject *__pyx_v_dy, PyObject *__pyx_v_drt, PyObject *__pyx_v_dot, PyObject *__pyx_v_dr, PyObject *__pyx_v_dou, PyObject *__pyx_v_dwc, PyObject *__pyx_v_temporal); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_68cubinarize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_th, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_70cuembedding_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_weight, PyObject *__pyx_v_gpu_value2); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_72cuembedding_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_index, PyObject *__pyx_v_gpu_dy, PyObject *__pyx_v_gpu_dx); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_74cuconcat(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_76cusum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_78cu_reduce_min(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_80cu_reduce_max(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_82cu_add_bias(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bias, PyObject *__pyx_v_gpu_value); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_84cu_get_fg_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_fg_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_86cu_get_fg_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_88cu_get_ith_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_ith_ary, PyObject *__pyx_v_i); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_90cu_get_ith_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero, PyObject *__pyx_v_i); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_92cu_get_every_nth_ary(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary1, PyObject *__pyx_v_ary2, PyObject *__pyx_v_i, PyObject *__pyx_v_j); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_94cu_assign_pred_box(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_y, PyObject *__pyx_v_w, PyObject *__pyx_v_h, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_96cu_pred_ctr(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arg, PyObject *__pyx_v_length, PyObject *__pyx_v_ctr, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_98cu_generate_anchors(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shifts, PyObject *__pyx_v_base_size, PyObject *__pyx_v_ratios, PyObject *__pyx_v_scales, PyObject *__pyx_v_feat_stride, PyObject *__pyx_v_anchors); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_100cu_get_ith_bbox(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bbox, PyObject *__pyx_v_i, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_102cu_clip_roi(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_roi, PyObject *__pyx_v_start, PyObject *__pyx_v_end, PyObject *__pyx_v_step, PyObject *__pyx_v_min_v, PyObject *__pyx_v_max_v, PyObject *__pyx_v_ary); /* proto */
static PyObject *__pyx_int_0;
static PyObject *__pyx_int_1;
static PyObject *__pyx_tuple_;
static PyObject *__pyx_tuple__2;
static PyObject *__pyx_tuple__3;
static PyObject *__pyx_tuple__4;
static PyObject *__pyx_tuple__6;
static PyObject *__pyx_tuple__8;
static PyObject *__pyx_tuple__10;
static PyObject *__pyx_tuple__12;
static PyObject *__pyx_tuple__14;
static PyObject *__pyx_tuple__16;
static PyObject *__pyx_tuple__18;
static PyObject *__pyx_tuple__20;
static PyObject *__pyx_tuple__22;
static PyObject *__pyx_tuple__24;
static PyObject *__pyx_tuple__26;
static PyObject *__pyx_tuple__28;
static PyObject *__pyx_tuple__30;
static PyObject *__pyx_tuple__32;
static PyObject *__pyx_tuple__34;
static PyObject *__pyx_tuple__36;
static PyObject *__pyx_tuple__38;
static PyObject *__pyx_tuple__40;
static PyObject *__pyx_tuple__42;
static PyObject *__pyx_tuple__44;
static PyObject *__pyx_tuple__46;
static PyObject *__pyx_tuple__48;
static PyObject *__pyx_tuple__50;
static PyObject *__pyx_tuple__52;
static PyObject *__pyx_tuple__54;
static PyObject *__pyx_tuple__56;
static PyObject *__pyx_tuple__58;
static PyObject *__pyx_tuple__60;
static PyObject *__pyx_tuple__62;
static PyObject *__pyx_tuple__64;
static PyObject *__pyx_tuple__66;
static PyObject *__pyx_tuple__68;
static PyObject *__pyx_tuple__70;
static PyObject *__pyx_tuple__72;
static PyObject *__pyx_tuple__74;
static PyObject *__pyx_tuple__76;
static PyObject *__pyx_tuple__78;
static PyObject *__pyx_tuple__80;
static PyObject *__pyx_tuple__82;
static PyObject *__pyx_tuple__84;
static PyObject *__pyx_tuple__86;
static PyObject *__pyx_tuple__88;
static PyObject *__pyx_tuple__90;
static PyObject *__pyx_tuple__92;
static PyObject *__pyx_tuple__94;
static PyObject *__pyx_tuple__96;
static PyObject *__pyx_tuple__98;
static PyObject *__pyx_codeobj__5;
static PyObject *__pyx_codeobj__7;
static PyObject *__pyx_codeobj__9;
static PyObject *__pyx_tuple__100;
static PyObject *__pyx_tuple__102;
static PyObject *__pyx_tuple__104;
static PyObject *__pyx_tuple__106;
static PyObject *__pyx_codeobj__11;
static PyObject *__pyx_codeobj__13;
static PyObject *__pyx_codeobj__15;
static PyObject *__pyx_codeobj__17;
static PyObject *__pyx_codeobj__19;
static PyObject *__pyx_codeobj__21;
static PyObject *__pyx_codeobj__23;
static PyObject *__pyx_codeobj__25;
static PyObject *__pyx_codeobj__27;
static PyObject *__pyx_codeobj__29;
static PyObject *__pyx_codeobj__31;
static PyObject *__pyx_codeobj__33;
static PyObject *__pyx_codeobj__35;
static PyObject *__pyx_codeobj__37;
static PyObject *__pyx_codeobj__39;
static PyObject *__pyx_codeobj__41;
static PyObject *__pyx_codeobj__43;
static PyObject *__pyx_codeobj__45;
static PyObject *__pyx_codeobj__47;
static PyObject *__pyx_codeobj__49;
static PyObject *__pyx_codeobj__51;
static PyObject *__pyx_codeobj__53;
static PyObject *__pyx_codeobj__55;
static PyObject *__pyx_codeobj__57;
static PyObject *__pyx_codeobj__59;
static PyObject *__pyx_codeobj__61;
static PyObject *__pyx_codeobj__63;
static PyObject *__pyx_codeobj__65;
static PyObject *__pyx_codeobj__67;
static PyObject *__pyx_codeobj__69;
static PyObject *__pyx_codeobj__71;
static PyObject *__pyx_codeobj__73;
static PyObject *__pyx_codeobj__75;
static PyObject *__pyx_codeobj__77;
static PyObject *__pyx_codeobj__79;
static PyObject *__pyx_codeobj__81;
static PyObject *__pyx_codeobj__83;
static PyObject *__pyx_codeobj__85;
static PyObject *__pyx_codeobj__87;
static PyObject *__pyx_codeobj__89;
static PyObject *__pyx_codeobj__91;
static PyObject *__pyx_codeobj__93;
static PyObject *__pyx_codeobj__95;
static PyObject *__pyx_codeobj__97;
static PyObject *__pyx_codeobj__99;
static PyObject *__pyx_codeobj__101;
static PyObject *__pyx_codeobj__103;
static PyObject *__pyx_codeobj__105;
static PyObject *__pyx_codeobj__107;

/* "renom/cuda/thrust_funcs.pxi":19
 * 
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_1cunegate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_1cunegate = {"cunegate", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_1cunegate, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_1cunegate(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_input = 0;
  PyObject *__pyx_v_result = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cunegate (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_input,&__pyx_n_s_result,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_input)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_result)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cunegate", 1, 2, 2, 1); __PYX_ERR(0, 19, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cunegate") < 0)) __PYX_ERR(0, 19, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_input = values[0];
    __pyx_v_result = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cunegate", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 19, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cunegate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_cunegate(__pyx_self, __pyx_v_input, __pyx_v_result);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_cunegate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_input, PyObject *__pyx_v_result) {
  VALUE_TYPE *__pyx_v_first;
  VALUE_TYPE *__pyx_v_last;
  VALUE_TYPE *__pyx_v_output;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  size_t __pyx_t_7;
  __Pyx_RefNannySetupContext("cunegate", 0);

  /* "renom/cuda/thrust_funcs.pxi":20
 * 
 * def cunegate(input, result):
 *     cuda_base.check_heap_device(input, result)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 20, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_input, __pyx_v_result};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_input, __pyx_v_result};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 20, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_input);
    __Pyx_GIVEREF(__pyx_v_input);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_input);
    __Pyx_INCREF(__pyx_v_result);
    __Pyx_GIVEREF(__pyx_v_result);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_result);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 20, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":22
 *     cuda_base.check_heap_device(input, result)
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 22, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_first = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":23
 * 
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * last = first + <size_t > input.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 *     thrust_negate(first, last, output)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_input, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 23, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_last = (__pyx_v_first + ((size_t)__pyx_t_7));

  /* "renom/cuda/thrust_funcs.pxi":24
 *     cdef VALUE_TYPE * first = <VALUE_TYPE * > < uintptr_t > input._ptr
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 *     thrust_negate(first, last, output)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 24, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_output = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":25
 *     cdef VALUE_TYPE * last = first + <size_t > input.size
 *     cdef VALUE_TYPE * output = <VALUE_TYPE * > < uintptr_t > result._ptr
 *     thrust_negate(first, last, output)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_negate(__pyx_v_first, __pyx_v_last, __pyx_v_output);

  /* "renom/cuda/thrust_funcs.pxi":19
 * 
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cunegate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":28
 * 
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_3curelu_foward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_3curelu_foward = {"curelu_foward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_3curelu_foward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_3curelu_foward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curelu_foward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curelu_foward", 1, 2, 2, 1); __PYX_ERR(0, 28, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curelu_foward") < 0)) __PYX_ERR(0, 28, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curelu_foward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 28, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curelu_foward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_2curelu_foward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_2curelu_foward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("curelu_foward", 0);

  /* "renom/cuda/thrust_funcs.pxi":29
 * 
 * def curelu_foward(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 29, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 29, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 29, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 29, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 29, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":31
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 31, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":32
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_forward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 32, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":33
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_relu_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 33, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":34
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_relu_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":28
 * 
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curelu_foward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":37
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_5curelu_backard(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_5curelu_backard = {"curelu_backard", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_5curelu_backard, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_5curelu_backard(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curelu_backard (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curelu_backard", 1, 2, 2, 1); __PYX_ERR(0, 37, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curelu_backard") < 0)) __PYX_ERR(0, 37, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curelu_backard", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 37, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curelu_backard", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_4curelu_backard(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_4curelu_backard(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("curelu_backard", 0);

  /* "renom/cuda/thrust_funcs.pxi":38
 * 
 * def curelu_backard(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 38, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 38, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 38, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":40
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 40, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":41
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_backward(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 41, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":42
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_relu_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 42, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":43
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_relu_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_relu_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":37
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curelu_backard", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":46
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_7culeaky_leru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_7culeaky_leru_forward = {"culeaky_leru_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_7culeaky_leru_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_7culeaky_leru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culeaky_leru_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, 1); __PYX_ERR(0, 46, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, 2); __PYX_ERR(0, 46, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culeaky_leru_forward") < 0)) __PYX_ERR(0, 46, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culeaky_leru_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 46, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.culeaky_leru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_6culeaky_leru_forward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_6culeaky_leru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("culeaky_leru_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":47
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 47, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 47, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 47, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 47, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 47, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":49
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 49, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":50
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 50, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":51
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 51, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":52
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsDouble(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 52, __pyx_L1_error)
  renom::thrust_leaky_relu_forward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":46
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culeaky_leru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":55
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_9culeaky_leru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_9culeaky_leru_backward = {"culeaky_leru_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_9culeaky_leru_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_9culeaky_leru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culeaky_leru_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, 1); __PYX_ERR(0, 55, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, 2); __PYX_ERR(0, 55, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culeaky_leru_backward") < 0)) __PYX_ERR(0, 55, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culeaky_leru_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 55, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.culeaky_leru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_8culeaky_leru_backward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_8culeaky_leru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("culeaky_leru_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":56
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 56, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 56, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 56, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 56, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 56, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":58
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 58, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":59
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 59, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":60
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 60, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":61
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_leaky_relu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsDouble(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 61, __pyx_L1_error)
  renom::thrust_leaky_relu_backward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":55
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culeaky_leru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":64
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_11cueru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_11cueru_forward = {"cueru_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_11cueru_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_11cueru_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cueru_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, 1); __PYX_ERR(0, 64, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, 2); __PYX_ERR(0, 64, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cueru_forward") < 0)) __PYX_ERR(0, 64, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cueru_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 64, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cueru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_10cueru_forward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_10cueru_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cueru_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":65
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 65, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 65, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 65, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 65, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 65, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":67
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 67, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 67, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":68
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 68, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":69
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 69, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":70
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_forward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsDouble(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 70, __pyx_L1_error)
  renom::thrust_elu_forward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":64
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cueru_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":73
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_13cueru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_13cueru_backward = {"cueru_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_13cueru_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_13cueru_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cueru_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_s,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, 1); __PYX_ERR(0, 73, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, 2); __PYX_ERR(0, 73, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cueru_backward") < 0)) __PYX_ERR(0, 73, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_s = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cueru_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 73, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cueru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_12cueru_backward(__pyx_self, __pyx_v_s, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_12cueru_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_s, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  VALUE_TYPE __pyx_t_7;
  __Pyx_RefNannySetupContext("cueru_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":74
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 74, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 74, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 74, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 74, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 74, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":76
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 76, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 76, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":77
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 77, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 77, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":78
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 78, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":79
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_elu_backward(< VALUE_TYPE > s, ptr1, ptr2, size);             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_7 = __pyx_PyFloat_AsDouble(__pyx_v_s); if (unlikely((__pyx_t_7 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 79, __pyx_L1_error)
  renom::thrust_elu_backward(((VALUE_TYPE)__pyx_t_7), __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":73
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cueru_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":82
 * 
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_15cusigmoid(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_15cusigmoid = {"cusigmoid", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_15cusigmoid, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_15cusigmoid(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusigmoid (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusigmoid", 1, 2, 2, 1); __PYX_ERR(0, 82, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusigmoid") < 0)) __PYX_ERR(0, 82, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusigmoid", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 82, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_14cusigmoid(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_14cusigmoid(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cusigmoid", 0);

  /* "renom/cuda/thrust_funcs.pxi":83
 * 
 * def cusigmoid(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 83, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 83, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 83, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 83, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 83, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":85
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 85, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 85, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":86
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_sigmoid(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 86, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 86, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":87
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_sigmoid(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 87, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 87, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":88
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_sigmoid(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_sigmoid(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":82
 * 
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusigmoid", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":91
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_17cutanh(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_17cutanh = {"cutanh", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_17cutanh, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_17cutanh(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cutanh (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cutanh", 1, 2, 2, 1); __PYX_ERR(0, 91, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cutanh") < 0)) __PYX_ERR(0, 91, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cutanh", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 91, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cutanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_16cutanh(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_16cutanh(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cutanh", 0);

  /* "renom/cuda/thrust_funcs.pxi":92
 * 
 * def cutanh(gpu_value1, gpu_value2):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 * 
 *     cdef int size = <int > gpu_value1.size
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 92, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 92, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[3] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 2+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 92, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(2+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 92, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 92, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":94
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 94, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 94, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":95
 * 
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_tanh(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 95, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 95, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":96
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_tanh(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 96, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 96, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":97
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_tanh(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_tanh(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":91
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cutanh", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":100
 * 
 * 
 * cdef basic_operation(Operation op, gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

static PyObject *__pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::Operation __pyx_v_op, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  int __pyx_v_elem_size_a;
  int __pyx_v_elem_size_b;
  PyObject *__pyx_v_value = NULL;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  VALUE_TYPE __pyx_t_9;
  __Pyx_RefNannySetupContext("basic_operation", 0);

  /* "renom/cuda/thrust_funcs.pxi":101
 * 
 * cdef basic_operation(Operation op, gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 101, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 101, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 101, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":103
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 103, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":105
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr             # <<<<<<<<<<<<<<
 *     cdef int elem_size_a = gpu_value1.size
 *     cdef int elem_size_b
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 105, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":106
 *     cdef VALUE_TYPE * ptr2
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 *     cdef int elem_size_a = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef int elem_size_b
 *     if hasattr(gpu_value2, "_ptr"):
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 106, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_elem_size_a = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":108
 *     cdef int elem_size_a = gpu_value1.size
 *     cdef int elem_size_b
 *     if hasattr(gpu_value2, "_ptr"):             # <<<<<<<<<<<<<<
 *         ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *         value = 0
 */
  __pyx_t_7 = __Pyx_HasAttr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(__pyx_t_7 == -1)) __PYX_ERR(0, 108, __pyx_L1_error)
  __pyx_t_8 = (__pyx_t_7 != 0);
  if (__pyx_t_8) {

    /* "renom/cuda/thrust_funcs.pxi":109
 *     cdef int elem_size_b
 *     if hasattr(gpu_value2, "_ptr"):
 *         ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *         value = 0
 *         elem_size_b = gpu_value2.size
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 109, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 109, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

    /* "renom/cuda/thrust_funcs.pxi":110
 *     if hasattr(gpu_value2, "_ptr"):
 *         ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *         value = 0             # <<<<<<<<<<<<<<
 *         elem_size_b = gpu_value2.size
 *     else:
 */
    __Pyx_INCREF(__pyx_int_0);
    __pyx_v_value = __pyx_int_0;

    /* "renom/cuda/thrust_funcs.pxi":111
 *         ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *         value = 0
 *         elem_size_b = gpu_value2.size             # <<<<<<<<<<<<<<
 *     else:
 *         ptr2 = <VALUE_TYPE * >0
 */
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 111, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 111, __pyx_L1_error)
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_elem_size_b = __pyx_t_4;

    /* "renom/cuda/thrust_funcs.pxi":108
 *     cdef int elem_size_a = gpu_value1.size
 *     cdef int elem_size_b
 *     if hasattr(gpu_value2, "_ptr"):             # <<<<<<<<<<<<<<
 *         ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *         value = 0
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust_funcs.pxi":113
 *         elem_size_b = gpu_value2.size
 *     else:
 *         ptr2 = <VALUE_TYPE * >0             # <<<<<<<<<<<<<<
 *         value = gpu_value2
 *         elem_size_b = 1
 */
  /*else*/ {
    __pyx_v_ptr2 = ((VALUE_TYPE *)0);

    /* "renom/cuda/thrust_funcs.pxi":114
 *     else:
 *         ptr2 = <VALUE_TYPE * >0
 *         value = gpu_value2             # <<<<<<<<<<<<<<
 *         elem_size_b = 1
 *     thrust_operation(op, < VALUE_TYPE > value, elem_size_a, ptr1, elem_size_b, ptr2, ptr3)
 */
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __pyx_v_value = __pyx_v_gpu_value2;

    /* "renom/cuda/thrust_funcs.pxi":115
 *         ptr2 = <VALUE_TYPE * >0
 *         value = gpu_value2
 *         elem_size_b = 1             # <<<<<<<<<<<<<<
 *     thrust_operation(op, < VALUE_TYPE > value, elem_size_a, ptr1, elem_size_b, ptr2, ptr3)
 * 
 */
    __pyx_v_elem_size_b = 1;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust_funcs.pxi":116
 *         value = gpu_value2
 *         elem_size_b = 1
 *     thrust_operation(op, < VALUE_TYPE > value, elem_size_a, ptr1, elem_size_b, ptr2, ptr3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_9 = __pyx_PyFloat_AsDouble(__pyx_v_value); if (unlikely((__pyx_t_9 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 116, __pyx_L1_error)
  renom::thrust_operation(__pyx_v_op, ((VALUE_TYPE)__pyx_t_9), __pyx_v_elem_size_a, __pyx_v_ptr1, __pyx_v_elem_size_b, __pyx_v_ptr2, __pyx_v_ptr3);

  /* "renom/cuda/thrust_funcs.pxi":100
 * 
 * 
 * cdef basic_operation(Operation op, gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.basic_operation", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_value);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":119
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_19cumul(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_19cumul = {"cumul", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_19cumul, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_19cumul(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumul (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, 1); __PYX_ERR(0, 119, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, 2); __PYX_ERR(0, 119, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumul") < 0)) __PYX_ERR(0, 119, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumul", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 119, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_18cumul(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_18cumul(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cumul", 0);

  /* "renom/cuda/thrust_funcs.pxi":120
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 120, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 120, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":121
 * def cumul(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::MUL, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 121, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":119
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumul", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":124
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_21cuadd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_21cuadd = {"cuadd", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_21cuadd, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_21cuadd(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuadd (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, 1); __PYX_ERR(0, 124, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, 2); __PYX_ERR(0, 124, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuadd") < 0)) __PYX_ERR(0, 124, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuadd", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 124, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuadd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_20cuadd(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_20cuadd(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cuadd", 0);

  /* "renom/cuda/thrust_funcs.pxi":125
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 125, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 125, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 125, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":126
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::ADD, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 126, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":124
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuadd", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":129
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_23cusub(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_23cusub = {"cusub", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_23cusub, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_23cusub(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusub (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, 1); __PYX_ERR(0, 129, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, 2); __PYX_ERR(0, 129, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusub") < 0)) __PYX_ERR(0, 129, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusub", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 129, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusub", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_22cusub(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_22cusub(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cusub", 0);

  /* "renom/cuda/thrust_funcs.pxi":130
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 130, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 130, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 130, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 130, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 130, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":131
 * def cusub(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::SUB, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 131, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":129
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusub", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":134
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_25cudiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_25cudiv = {"cudiv", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_25cudiv, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_25cudiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cudiv (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, 1); __PYX_ERR(0, 134, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, 2); __PYX_ERR(0, 134, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cudiv") < 0)) __PYX_ERR(0, 134, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cudiv", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 134, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cudiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_24cudiv(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_24cudiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cudiv", 0);

  /* "renom/cuda/thrust_funcs.pxi":135
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 135, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 135, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 135, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 135, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 135, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":136
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::DIV, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 136, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":134
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cudiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":139
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_27curdiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_27curdiv = {"curdiv", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_27curdiv, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_27curdiv(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curdiv (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, 1); __PYX_ERR(0, 139, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, 2); __PYX_ERR(0, 139, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curdiv") < 0)) __PYX_ERR(0, 139, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curdiv", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 139, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curdiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_26curdiv(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_26curdiv(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("curdiv", 0);

  /* "renom/cuda/thrust_funcs.pxi":140
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 140, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 140, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 140, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":141
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::RDIV, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 141, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":139
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curdiv", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":144
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_29cupow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_29cupow = {"cupow", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_29cupow, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_29cupow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, 1); __PYX_ERR(0, 144, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, 2); __PYX_ERR(0, 144, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupow") < 0)) __PYX_ERR(0, 144, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 144, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_28cupow(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_28cupow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cupow", 0);

  /* "renom/cuda/thrust_funcs.pxi":145
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 145, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 145, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 145, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 145, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 145, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":146
 * def cupow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::POW, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 146, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":144
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":149
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_31curpow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_31curpow = {"curpow", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_31curpow, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_31curpow(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curpow (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, 1); __PYX_ERR(0, 149, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, 2); __PYX_ERR(0, 149, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curpow") < 0)) __PYX_ERR(0, 149, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curpow", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 149, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curpow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_30curpow(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_30curpow(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("curpow", 0);

  /* "renom/cuda/thrust_funcs.pxi":150
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 150, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 150, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":151
 * def curpow(gpu_value1, gpu_value2, gpu_value3):
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double_basic_operation(renom::RPOW, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 151, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":149
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curpow", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":154
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_33cufill(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_33cufill = {"cufill", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_33cufill, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_33cufill(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cufill (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cufill", 1, 2, 2, 1); __PYX_ERR(0, 154, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cufill") < 0)) __PYX_ERR(0, 154, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cufill", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 154, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cufill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_32cufill(__pyx_self, __pyx_v_value, __pyx_v_gpu_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_32cufill(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value) {
  int __pyx_v_size;
  VALUE_TYPE __pyx_v_v;
  VALUE_TYPE *__pyx_v_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  VALUE_TYPE __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cufill", 0);

  /* "renom/cuda/thrust_funcs.pxi":155
 * 
 * def cufill(value, gpu_value):
 *     cdef int size = <int > gpu_value.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 155, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 155, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":156
 * def cufill(value, gpu_value):
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 * 
 */
  __pyx_t_3 = __pyx_PyFloat_AsDouble(__pyx_v_value); if (unlikely((__pyx_t_3 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 156, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_3);

  /* "renom/cuda/thrust_funcs.pxi":157
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 157, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":159
 *     cdef VALUE_TYPE * ptr = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value)             # <<<<<<<<<<<<<<
 *     thrust_fill(v, ptr, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 159, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
    }
  }
  if (!__pyx_t_5) {
    __pyx_t_1 = __Pyx_PyObject_CallOneArg(__pyx_t_6, __pyx_v_gpu_value); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
  } else {
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_gpu_value};
      __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
      PyObject *__pyx_temp[2] = {__pyx_t_5, __pyx_v_gpu_value};
      __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-1, 1+1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
      __Pyx_GOTREF(__pyx_t_1);
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(1+1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 159, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
      __Pyx_INCREF(__pyx_v_gpu_value);
      __Pyx_GIVEREF(__pyx_v_gpu_value);
      PyTuple_SET_ITEM(__pyx_t_7, 0+1, __pyx_v_gpu_value);
      __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 159, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_1);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":160
 * 
 *     cuda_base.check_heap_device(gpu_value)
 *     thrust_fill(v, ptr, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_fill(__pyx_v_v, __pyx_v_ptr, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":154
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cufill", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":163
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_35culoge(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_35culoge = {"culoge", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_35culoge, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_35culoge(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culoge (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culoge", 1, 2, 2, 1); __PYX_ERR(0, 163, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culoge") < 0)) __PYX_ERR(0, 163, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culoge", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 163, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.culoge", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_34culoge(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_34culoge(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("culoge", 0);

  /* "renom/cuda/thrust_funcs.pxi":164
 * 
 * def culoge(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 164, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 164, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":165
 * def culoge(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 165, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 165, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":166
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 166, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 166, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":168
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_loge(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 168, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 168, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 168, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 168, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 168, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":169
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_loge(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_loge(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":163
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culoge", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":172
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_37cuexp(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_37cuexp = {"cuexp", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_37cuexp, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_37cuexp(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuexp (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuexp", 1, 2, 2, 1); __PYX_ERR(0, 172, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuexp") < 0)) __PYX_ERR(0, 172, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuexp", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 172, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuexp", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_36cuexp(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_36cuexp(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  __Pyx_RefNannySetupContext("cuexp", 0);

  /* "renom/cuda/thrust_funcs.pxi":173
 * 
 * def cuexp(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 173, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 173, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":174
 * def cuexp(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_exp(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 174, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 174, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":175
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     thrust_exp(ptr1, ptr2, size)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 175, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 175, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":176
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     thrust_exp(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_exp(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":172
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuexp", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":179
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_39cusqrt(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_39cusqrt = {"cusqrt", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_39cusqrt, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_39cusqrt(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusqrt (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusqrt", 1, 2, 2, 1); __PYX_ERR(0, 179, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusqrt") < 0)) __PYX_ERR(0, 179, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusqrt", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 179, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusqrt", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_38cusqrt(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_38cusqrt(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cusqrt", 0);

  /* "renom/cuda/thrust_funcs.pxi":180
 * 
 * def cusqrt(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 180, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 180, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":181
 * def cusqrt(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 181, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":182
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 182, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 182, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":184
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 184, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 184, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 184, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":185
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sqrt(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * def cusign(gpu_value1, gpu_value2):
 */
  renom::thrust_sqrt(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":179
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusqrt", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":187
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_41cusign(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_41cusign = {"cusign", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_41cusign, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_41cusign(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusign (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cusign", 1, 2, 2, 1); __PYX_ERR(0, 187, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusign") < 0)) __PYX_ERR(0, 187, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusign", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 187, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusign", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_40cusign(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_40cusign(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cusign", 0);

  /* "renom/cuda/thrust_funcs.pxi":188
 * 
 * def cusign(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 188, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 188, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":189
 * def cusign(gpu_value1, gpu_value2):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 189, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 189, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":190
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sign(ptr1, ptr2, size)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 190, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 190, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":191
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_sign(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 191, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 191, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":192
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > gpu_value2._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_sign(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):
 */
  renom::thrust_sign(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":187
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusign", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":194
 *     thrust_sign(ptr1, ptr2, size)
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_43cucross_entropy(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_43cucross_entropy = {"cucross_entropy", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_43cucross_entropy, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_43cucross_entropy(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cucross_entropy (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, 1); __PYX_ERR(0, 194, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, 2); __PYX_ERR(0, 194, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cucross_entropy") < 0)) __PYX_ERR(0, 194, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cucross_entropy", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 194, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cucross_entropy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_42cucross_entropy(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_42cucross_entropy(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cucross_entropy", 0);

  /* "renom/cuda/thrust_funcs.pxi":195
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):
 *     cdef int size = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 195, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":196
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 196, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 196, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":197
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 197, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 197, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":198
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 198, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 198, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":200
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 *     thrust_cross_entropy(ptr1, ptr2, ptr3, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 200, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 3+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 3+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_2, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 200, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":201
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     thrust_cross_entropy(ptr1, ptr2, ptr3, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_cross_entropy(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_ptr3, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":194
 *     thrust_sign(ptr1, ptr2, size)
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cucross_entropy", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":204
 * 
 * 
 * def cubroadcast(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_45cubroadcast(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_45cubroadcast = {"cubroadcast", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_45cubroadcast, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_45cubroadcast(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cubroadcast (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cubroadcast", 1, 2, 2, 1); __PYX_ERR(0, 204, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cubroadcast") < 0)) __PYX_ERR(0, 204, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cubroadcast", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 204, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cubroadcast", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_44cubroadcast(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_44cubroadcast(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size_1;
  int __pyx_v_size_2;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cubroadcast", 0);

  /* "renom/cuda/thrust_funcs.pxi":205
 * 
 * def cubroadcast(gpu_value1, gpu_value2):
 *     cdef int size_1 = <int > gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef int size_2 = <int > gpu_value2.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 205, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 205, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size_1 = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":206
 * def cubroadcast(gpu_value1, gpu_value2):
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 206, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 206, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size_2 = ((int)__pyx_t_2);

  /* "renom/cuda/thrust_funcs.pxi":207
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 207, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":208
 *     cdef int size_2 = <int > gpu_value2.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 208, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 208, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":210
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_broad_cast(size_1, ptr1, size_2, ptr2)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 210, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 210, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 210, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 210, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":211
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_broad_cast(size_1, ptr1, size_2, ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_broad_cast(__pyx_v_size_1, __pyx_v_ptr1, __pyx_v_size_2, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":204
 * 
 * 
 * def cubroadcast(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cubroadcast", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":214
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_47cuabs_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_47cuabs_forward = {"cuabs_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_47cuabs_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_47cuabs_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuabs_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuabs_forward", 1, 2, 2, 1); __PYX_ERR(0, 214, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuabs_forward") < 0)) __PYX_ERR(0, 214, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuabs_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 214, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuabs_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_46cuabs_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_46cuabs_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuabs_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":215
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 215, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 215, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust_funcs.pxi":216
 * def cuabs_forward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 216, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 216, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":217
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 217, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 217, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":219
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_abs_forward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 219, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 219, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":220
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_abs_forward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_abs_forward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":214
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuabs_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":223
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_49cuabs_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_49cuabs_backward = {"cuabs_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_49cuabs_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_49cuabs_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuabs_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuabs_backward", 1, 2, 2, 1); __PYX_ERR(0, 223, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuabs_backward") < 0)) __PYX_ERR(0, 223, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuabs_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 223, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuabs_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_48cuabs_backward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_48cuabs_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuabs_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":224
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 224, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust_funcs.pxi":225
 * def cuabs_backward(gpu_value1, gpu_value2):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 225, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 225, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":226
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 226, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 226, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":228
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_abs_backward(ptr1, ptr2, size)
 * 
 */
  __pyx_t_4 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 228, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_4, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 228, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_t_4 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_4 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_4)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_4);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[3] = {__pyx_t_4, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_4) {
      __Pyx_GIVEREF(__pyx_t_4); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_4); __pyx_t_4 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 228, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":229
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_abs_backward(ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_abs_backward(__pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":223
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuabs_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":232
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_51cumin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_51cumin = {"cumin", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_51cumin, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_51cumin(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumin (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumin", 0, 2, 3, 1); __PYX_ERR(0, 232, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumin") < 0)) __PYX_ERR(0, 232, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumin", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 232, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_50cumin(__pyx_self, __pyx_v_value, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_50cumin(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE __pyx_v_v;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cumin", 0);

  /* "renom/cuda/thrust_funcs.pxi":233
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 233, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 233, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust_funcs.pxi":234
 * def cumin(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 234, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":235
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 235, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 235, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":236
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsDouble(__pyx_v_value); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 236, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":238
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_min(v, ptr1, ptr2, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 238, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 238, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 238, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 238, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 238, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":239
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_min(v, ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_min(__pyx_v_v, __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":232
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumin", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":242
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_53cumax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_53cumax = {"cumax", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_53cumax, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_53cumax(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_value = 0;
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cumax (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_value,&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    values[2] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_value)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cumax", 0, 2, 3, 1); __PYX_ERR(0, 242, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2);
          if (value) { values[2] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cumax") < 0)) __PYX_ERR(0, 242, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_value = values[0];
    __pyx_v_gpu_value1 = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cumax", 0, 2, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 242, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_52cumax(__pyx_self, __pyx_v_value, __pyx_v_gpu_value1, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_52cumax(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_value, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE __pyx_v_v;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cumax", 0);

  /* "renom/cuda/thrust_funcs.pxi":243
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 243, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 243, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = __pyx_t_2;

  /* "renom/cuda/thrust_funcs.pxi":244
 * def cumax(value, gpu_value1, gpu_value2=None):
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 244, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 244, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":245
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 245, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 245, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":246
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = < VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsDouble(__pyx_v_value); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 246, __pyx_L1_error)
  __pyx_v_v = ((VALUE_TYPE)__pyx_t_4);

  /* "renom/cuda/thrust_funcs.pxi":248
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_max(v, ptr1, ptr2, size)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 248, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 248, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 248, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 248, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 248, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":249
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_max(v, ptr1, ptr2, size)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_max(__pyx_v_v, __pyx_v_ptr1, __pyx_v_ptr2, __pyx_v_size);

  /* "renom/cuda/thrust_funcs.pxi":242
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cumax", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":252
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                         width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_55curoi_pool2d_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_55curoi_pool2d_forward = {"curoi_pool2d_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_55curoi_pool2d_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_55curoi_pool2d_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_rois = 0;
  PyObject *__pyx_v_x = 0;
  PyObject *__pyx_v_spatial_scale = 0;
  PyObject *__pyx_v_channels = 0;
  PyObject *__pyx_v_height = 0;
  PyObject *__pyx_v_width = 0;
  PyObject *__pyx_v_outh = 0;
  PyObject *__pyx_v_outw = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_v_augmax_data = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curoi_pool2d_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_rois,&__pyx_n_s_x,&__pyx_n_s_spatial_scale,&__pyx_n_s_channels,&__pyx_n_s_height,&__pyx_n_s_width,&__pyx_n_s_outh,&__pyx_n_s_outw,&__pyx_n_s_z,&__pyx_n_s_augmax_data,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_rois)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 1); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_spatial_scale)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 2); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_channels)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 3); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_height)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 4); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_width)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 5); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outh)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 6); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outw)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 7); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 8); __PYX_ERR(0, 252, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_augmax_data)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, 9); __PYX_ERR(0, 252, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curoi_pool2d_forward") < 0)) __PYX_ERR(0, 252, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_rois = values[0];
    __pyx_v_x = values[1];
    __pyx_v_spatial_scale = values[2];
    __pyx_v_channels = values[3];
    __pyx_v_height = values[4];
    __pyx_v_width = values[5];
    __pyx_v_outh = values[6];
    __pyx_v_outw = values[7];
    __pyx_v_z = values[8];
    __pyx_v_augmax_data = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curoi_pool2d_forward", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 252, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curoi_pool2d_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_54curoi_pool2d_forward(__pyx_self, __pyx_v_rois, __pyx_v_x, __pyx_v_spatial_scale, __pyx_v_channels, __pyx_v_height, __pyx_v_width, __pyx_v_outh, __pyx_v_outw, __pyx_v_z, __pyx_v_augmax_data);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_54curoi_pool2d_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_rois, PyObject *__pyx_v_x, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_channels, PyObject *__pyx_v_height, PyObject *__pyx_v_width, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_z, PyObject *__pyx_v_augmax_data) {
  int __pyx_v_N;
  VALUE_TYPE *__pyx_v_ptr_x;
  VALUE_TYPE *__pyx_v_ptr_rois;
  VALUE_TYPE *__pyx_v_ptr_z;
  VALUE_TYPE *__pyx_v_ptr_augmax_data;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  float __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("curoi_pool2d_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":254
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,
 *                         width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t> x._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 254, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 254, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 254, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":256
 *     cdef int N = rois.shape[0]
 * 
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t> x._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t> z._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_x, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 256, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 256, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_x = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":257
 * 
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t> x._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t> z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t> augmax_data._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 257, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 257, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_rois = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":258
 *     cdef VALUE_TYPE * ptr_x = <VALUE_TYPE * > < uintptr_t> x._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t> z._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t> augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 258, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 258, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":259
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t> z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t> augmax_data._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_augmax_data, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 259, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 259, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_augmax_data = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":260
 *     cdef VALUE_TYPE * ptr_z = <VALUE_TYPE * > < uintptr_t> z._ptr
 *     cdef VALUE_TYPE * ptr_augmax_data = <VALUE_TYPE * > < uintptr_t> augmax_data._ptr
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)             # <<<<<<<<<<<<<<
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):
 */
  __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_spatial_scale); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_channels); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_height); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_width); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_outh); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_outw); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 260, __pyx_L1_error)
  renom::thrust_forward_roi_pool2d(__pyx_v_N, __pyx_v_ptr_x, __pyx_t_5, __pyx_t_3, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9, __pyx_v_ptr_rois, __pyx_v_ptr_z, __pyx_v_ptr_augmax_data);

  /* "renom/cuda/thrust_funcs.pxi":252
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                         width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curoi_pool2d_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":262
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int N = rois.shape[0]
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_57curoi_pool2d_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_57curoi_pool2d_backward = {"curoi_pool2d_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_57curoi_pool2d_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_57curoi_pool2d_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_argmax = 0;
  PyObject *__pyx_v_rois = 0;
  PyObject *__pyx_v_spatial_scale = 0;
  PyObject *__pyx_v_ch = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_v_w = 0;
  PyObject *__pyx_v_outh = 0;
  PyObject *__pyx_v_outw = 0;
  PyObject *__pyx_v_dx = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("curoi_pool2d_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_argmax,&__pyx_n_s_rois,&__pyx_n_s_spatial_scale,&__pyx_n_s_ch,&__pyx_n_s_h,&__pyx_n_s_w,&__pyx_n_s_outh,&__pyx_n_s_outw,&__pyx_n_s_dx,0};
    PyObject* values[10] = {0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_argmax)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 1); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_rois)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 2); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_spatial_scale)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 3); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ch)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 4); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 5); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_w)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 6); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outh)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 7); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_outw)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 8); __PYX_ERR(0, 262, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dx)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, 9); __PYX_ERR(0, 262, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "curoi_pool2d_backward") < 0)) __PYX_ERR(0, 262, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 10) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
    }
    __pyx_v_du = values[0];
    __pyx_v_argmax = values[1];
    __pyx_v_rois = values[2];
    __pyx_v_spatial_scale = values[3];
    __pyx_v_ch = values[4];
    __pyx_v_h = values[5];
    __pyx_v_w = values[6];
    __pyx_v_outh = values[7];
    __pyx_v_outw = values[8];
    __pyx_v_dx = values[9];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("curoi_pool2d_backward", 1, 10, 10, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 262, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.curoi_pool2d_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_56curoi_pool2d_backward(__pyx_self, __pyx_v_du, __pyx_v_argmax, __pyx_v_rois, __pyx_v_spatial_scale, __pyx_v_ch, __pyx_v_h, __pyx_v_w, __pyx_v_outh, __pyx_v_outw, __pyx_v_dx);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_56curoi_pool2d_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_argmax, PyObject *__pyx_v_rois, PyObject *__pyx_v_spatial_scale, PyObject *__pyx_v_ch, PyObject *__pyx_v_h, PyObject *__pyx_v_w, PyObject *__pyx_v_outh, PyObject *__pyx_v_outw, PyObject *__pyx_v_dx) {
  int __pyx_v_N;
  VALUE_TYPE *__pyx_v_ptr_du;
  VALUE_TYPE *__pyx_v_ptr_argmax;
  VALUE_TYPE *__pyx_v_ptr_rois;
  VALUE_TYPE *__pyx_v_ptr_dx;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  float __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("curoi_pool2d_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":263
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):
 *     cdef int N = rois.shape[0]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE *> < uintptr_t> du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 263, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 263, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 263, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":265
 *     cdef int N = rois.shape[0]
 * 
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE *> < uintptr_t> du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t> argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 265, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 265, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_du = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":266
 * 
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE *> < uintptr_t> du._ptr
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t> argmax._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t> dx._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_argmax, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 266, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 266, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_argmax = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":267
 *     cdef VALUE_TYPE * ptr_du = <VALUE_TYPE *> < uintptr_t> du._ptr
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t> argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t> dx._ptr
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_rois, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 267, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_rois = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":268
 *     cdef VALUE_TYPE * ptr_argmax = <VALUE_TYPE * > < uintptr_t> argmax._ptr
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t> dx._ptr             # <<<<<<<<<<<<<<
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_dx, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 268, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr_dx = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":269
 *     cdef VALUE_TYPE * ptr_rois = <VALUE_TYPE  *> < uintptr_t> rois._ptr
 *     cdef VALUE_TYPE * ptr_dx = <VALUE_TYPE * > < uintptr_t> dx._ptr
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)             # <<<<<<<<<<<<<<
 * 
 * def culstm_forward_activate(u):
 */
  __pyx_t_5 = __pyx_PyFloat_AsFloat(__pyx_v_spatial_scale); if (unlikely((__pyx_t_5 == (float)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_v_ch); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_h); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_w); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_outh); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_outw); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 269, __pyx_L1_error)
  renom::thrust_backward_roi_pool2d(__pyx_v_N, __pyx_v_ptr_du, __pyx_v_ptr_argmax, __pyx_v_ptr_rois, __pyx_t_5, __pyx_t_3, __pyx_t_6, __pyx_t_7, __pyx_t_8, __pyx_t_9, __pyx_v_ptr_dx);

  /* "renom/cuda/thrust_funcs.pxi":262
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int N = rois.shape[0]
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.curoi_pool2d_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":271
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_59culstm_forward_activate(PyObject *__pyx_self, PyObject *__pyx_v_u); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_59culstm_forward_activate = {"culstm_forward_activate", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_59culstm_forward_activate, METH_O, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_59culstm_forward_activate(PyObject *__pyx_self, PyObject *__pyx_v_u) {
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_forward_activate (wrapper)", 0);
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_58culstm_forward_activate(__pyx_self, ((PyObject *)__pyx_v_u));

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_58culstm_forward_activate(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("culstm_forward_activate", 0);

  /* "renom/cuda/thrust_funcs.pxi":272
 * 
 * def culstm_forward_activate(u):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 272, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 272, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 272, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":273
 * def culstm_forward_activate(u):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 273, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":275
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_lstm_activate(N, M, ptr_u)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 275, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":276
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     thrust_forward_lstm_activate(N, M, ptr_u)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_lstm_activate(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u);

  /* "renom/cuda/thrust_funcs.pxi":271
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culstm_forward_activate", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":279
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_61culstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_61culstm_forward = {"culstm_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_61culstm_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_61culstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_ps = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_s,&__pyx_n_s_ps,&__pyx_n_s_z,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 1); __PYX_ERR(0, 279, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ps)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 2); __PYX_ERR(0, 279, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, 3); __PYX_ERR(0, 279, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culstm_forward") < 0)) __PYX_ERR(0, 279, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_u = values[0];
    __pyx_v_s = values[1];
    __pyx_v_ps = values[2];
    __pyx_v_z = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culstm_forward", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 279, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.culstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_60culstm_forward(__pyx_self, __pyx_v_u, __pyx_v_s, __pyx_v_ps, __pyx_v_z);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_60culstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_z) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_z;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  __Pyx_RefNannySetupContext("culstm_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":280
 * 
 * def culstm_forward(u, s, ps, z):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 280, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 280, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":281
 * def culstm_forward(u, s, ps, z):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 281, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":283
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 283, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 283, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":284
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_s, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 284, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 284, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":285
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ps, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 285, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":286
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 286, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":287
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     thrust_forward_lstm(N, M, ptr_u, ptr_s, ptr_ps, ptr_z)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_s, __pyx_v_ptr_ps, __pyx_v_ptr_z);

  /* "renom/cuda/thrust_funcs.pxi":279
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":290
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_63culstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_63culstm_backward = {"culstm_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_63culstm_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_63culstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_s = 0;
  PyObject *__pyx_v_ps = 0;
  PyObject *__pyx_v_e = 0;
  PyObject *__pyx_v_pgf = 0;
  PyObject *__pyx_v_dou = 0;
  PyObject *__pyx_v_dou_n = 0;
  PyObject *__pyx_v_temporal = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("culstm_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_du,&__pyx_n_s_s,&__pyx_n_s_ps,&__pyx_n_s_e,&__pyx_n_s_pgf,&__pyx_n_s_dou,&__pyx_n_s_dou_n,&__pyx_n_s_temporal,0};
    PyObject* values[9] = {0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 1); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_s)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 2); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ps)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 3); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_e)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 4); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_pgf)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 5); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 6); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou_n)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 7); __PYX_ERR(0, 290, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_temporal)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, 8); __PYX_ERR(0, 290, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "culstm_backward") < 0)) __PYX_ERR(0, 290, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 9) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
    }
    __pyx_v_u = values[0];
    __pyx_v_du = values[1];
    __pyx_v_s = values[2];
    __pyx_v_ps = values[3];
    __pyx_v_e = values[4];
    __pyx_v_pgf = values[5];
    __pyx_v_dou = values[6];
    __pyx_v_dou_n = values[7];
    __pyx_v_temporal = values[8];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("culstm_backward", 1, 9, 9, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 290, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.culstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_62culstm_backward(__pyx_self, __pyx_v_u, __pyx_v_du, __pyx_v_s, __pyx_v_ps, __pyx_v_e, __pyx_v_pgf, __pyx_v_dou, __pyx_v_dou_n, __pyx_v_temporal);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_62culstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_du, PyObject *__pyx_v_s, PyObject *__pyx_v_ps, PyObject *__pyx_v_e, PyObject *__pyx_v_pgf, PyObject *__pyx_v_dou, PyObject *__pyx_v_dou_n, PyObject *__pyx_v_temporal) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_du;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_e;
  VALUE_TYPE *__pyx_v_ptr_pgf;
  VALUE_TYPE *__pyx_v_ptr_dou;
  VALUE_TYPE *__pyx_v_ptr_dou_n;
  bool __pyx_v_temp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  bool __pyx_t_5;
  __Pyx_RefNannySetupContext("culstm_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":291
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 291, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":292
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 292, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 292, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":293
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 293, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 293, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":294
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 294, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_du = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":295
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_s, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 295, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 295, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":296
 *     cdef VALUE_TYPE * ptr_du = < VALUE_TYPE * > < uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ps, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 296, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 296, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":297
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > s._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_e, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 297, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 297, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_e = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":298
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > ps._ptr
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_pgf, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 298, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_pgf = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":299
 *     cdef VALUE_TYPE * ptr_e = < VALUE_TYPE * > < uintptr_t > e._ptr
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 *     cdef bool temp = temporal
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 299, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":300
 *     cdef VALUE_TYPE * ptr_pgf = < VALUE_TYPE * > < uintptr_t > pgf._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr             # <<<<<<<<<<<<<<
 *     cdef bool temp = temporal
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou_n, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 300, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou_n = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":301
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 *     cdef bool temp = temporal             # <<<<<<<<<<<<<<
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,
 *                          ptr_e, ptr_pgf, ptr_dou, ptr_dou_n, temp)
 */
  __pyx_t_5 = __Pyx_PyObject_IsTrue(__pyx_v_temporal); if (unlikely((__pyx_t_5 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 301, __pyx_L1_error)
  __pyx_v_temp = __pyx_t_5;

  /* "renom/cuda/thrust_funcs.pxi":302
 *     cdef VALUE_TYPE * ptr_dou_n = < VALUE_TYPE * > < uintptr_t > dou_n._ptr
 *     cdef bool temp = temporal
 *     thrust_backward_lstm(N, M, ptr_u, ptr_du, ptr_s, ptr_ps,             # <<<<<<<<<<<<<<
 *                          ptr_e, ptr_pgf, ptr_dou, ptr_dou_n, temp)
 * 
 */
  renom::thrust_backward_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_du, __pyx_v_ptr_s, __pyx_v_ptr_ps, __pyx_v_ptr_e, __pyx_v_ptr_pgf, __pyx_v_ptr_dou, __pyx_v_ptr_dou_n, __pyx_v_temp);

  /* "renom/cuda/thrust_funcs.pxi":290
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.culstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":306
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_65cupeepholelstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_65cupeepholelstm_forward = {"cupeepholelstm_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_65cupeepholelstm_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_65cupeepholelstm_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_wc = 0;
  PyObject *__pyx_v_prestate = 0;
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v_z = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupeepholelstm_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_wc,&__pyx_n_s_prestate,&__pyx_n_s_state,&__pyx_n_s_z,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_wc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 1); __PYX_ERR(0, 306, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prestate)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 2); __PYX_ERR(0, 306, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 3); __PYX_ERR(0, 306, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_z)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, 4); __PYX_ERR(0, 306, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupeepholelstm_forward") < 0)) __PYX_ERR(0, 306, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_u = values[0];
    __pyx_v_wc = values[1];
    __pyx_v_prestate = values[2];
    __pyx_v_state = values[3];
    __pyx_v_z = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupeepholelstm_forward", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 306, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupeepholelstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_64cupeepholelstm_forward(__pyx_self, __pyx_v_u, __pyx_v_wc, __pyx_v_prestate, __pyx_v_state, __pyx_v_z);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_64cupeepholelstm_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_wc, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_z) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_z;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_wc;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  __Pyx_RefNannySetupContext("cupeepholelstm_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":307
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)             # <<<<<<<<<<<<<<
 * 
 *     cdef int N = u.shape[0]
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 307, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[6] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_wc, __pyx_v_z};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 5+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[6] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_wc, __pyx_v_z};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 5+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(5+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_u);
    __Pyx_GIVEREF(__pyx_v_u);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_u);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_state);
    __Pyx_INCREF(__pyx_v_wc);
    __Pyx_GIVEREF(__pyx_v_wc);
    PyTuple_SET_ITEM(__pyx_t_5, 3+__pyx_t_4, __pyx_v_wc);
    __Pyx_INCREF(__pyx_v_z);
    __Pyx_GIVEREF(__pyx_v_z);
    PyTuple_SET_ITEM(__pyx_t_5, 4+__pyx_t_4, __pyx_v_z);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 307, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":309
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 309, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":310
 * 
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 310, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":311
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 311, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":312
 *     cdef int M = u.shape[1]
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_z, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 312, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_z = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":313
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prestate, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 313, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 313, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":314
 *     cdef VALUE_TYPE * ptr_z = < VALUE_TYPE * > < uintptr_t > z._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_state, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 314, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 314, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":315
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr             # <<<<<<<<<<<<<<
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_wc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 315, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 315, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_wc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":316
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     thrust_forward_peephole_lstm(N, M, ptr_u, ptr_wc, ptr_ps, ptr_s, ptr_z)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_forward_peephole_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_wc, __pyx_v_ptr_ps, __pyx_v_ptr_s, __pyx_v_ptr_z);

  /* "renom/cuda/thrust_funcs.pxi":306
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupeepholelstm_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":319
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_67cupeepholelstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_67cupeepholelstm_backward = {"cupeepholelstm_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_67cupeepholelstm_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_67cupeepholelstm_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_u = 0;
  PyObject *__pyx_v_prestate = 0;
  PyObject *__pyx_v_state = 0;
  PyObject *__pyx_v_prefg = 0;
  PyObject *__pyx_v_wc = 0;
  PyObject *__pyx_v_dy = 0;
  PyObject *__pyx_v_drt = 0;
  PyObject *__pyx_v_dot = 0;
  PyObject *__pyx_v_dr = 0;
  PyObject *__pyx_v_dou = 0;
  PyObject *__pyx_v_dwc = 0;
  PyObject *__pyx_v_temporal = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cupeepholelstm_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_u,&__pyx_n_s_prestate,&__pyx_n_s_state,&__pyx_n_s_prefg,&__pyx_n_s_wc,&__pyx_n_s_dy,&__pyx_n_s_drt,&__pyx_n_s_dot,&__pyx_n_s_dr,&__pyx_n_s_dou,&__pyx_n_s_dwc,&__pyx_n_s_temporal,0};
    PyObject* values[12] = {0,0,0,0,0,0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case 12: values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
        CYTHON_FALLTHROUGH;
        case 11: values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
        CYTHON_FALLTHROUGH;
        case 10: values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
        CYTHON_FALLTHROUGH;
        case  9: values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
        CYTHON_FALLTHROUGH;
        case  8: values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
        CYTHON_FALLTHROUGH;
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_u)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prestate)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 1); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_state)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 2); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_prefg)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 3); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_wc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 4); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 5); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_drt)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 6); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  7:
        if (likely((values[7] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dot)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 7); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  8:
        if (likely((values[8] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dr)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 8); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  9:
        if (likely((values[9] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dou)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 9); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case 10:
        if (likely((values[10] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_dwc)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 10); __PYX_ERR(0, 319, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case 11:
        if (likely((values[11] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_temporal)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, 11); __PYX_ERR(0, 319, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cupeepholelstm_backward") < 0)) __PYX_ERR(0, 319, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 12) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
      values[7] = PyTuple_GET_ITEM(__pyx_args, 7);
      values[8] = PyTuple_GET_ITEM(__pyx_args, 8);
      values[9] = PyTuple_GET_ITEM(__pyx_args, 9);
      values[10] = PyTuple_GET_ITEM(__pyx_args, 10);
      values[11] = PyTuple_GET_ITEM(__pyx_args, 11);
    }
    __pyx_v_u = values[0];
    __pyx_v_prestate = values[1];
    __pyx_v_state = values[2];
    __pyx_v_prefg = values[3];
    __pyx_v_wc = values[4];
    __pyx_v_dy = values[5];
    __pyx_v_drt = values[6];
    __pyx_v_dot = values[7];
    __pyx_v_dr = values[8];
    __pyx_v_dou = values[9];
    __pyx_v_dwc = values[10];
    __pyx_v_temporal = values[11];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cupeepholelstm_backward", 1, 12, 12, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 319, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupeepholelstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_66cupeepholelstm_backward(__pyx_self, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prefg, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dr, __pyx_v_dou, __pyx_v_dwc, __pyx_v_temporal);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_66cupeepholelstm_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_u, PyObject *__pyx_v_prestate, PyObject *__pyx_v_state, PyObject *__pyx_v_prefg, PyObject *__pyx_v_wc, PyObject *__pyx_v_dy, PyObject *__pyx_v_drt, PyObject *__pyx_v_dot, PyObject *__pyx_v_dr, PyObject *__pyx_v_dou, PyObject *__pyx_v_dwc, PyObject *__pyx_v_temporal) {
  int __pyx_v_N;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_ptr_u;
  VALUE_TYPE *__pyx_v_ptr_ps;
  VALUE_TYPE *__pyx_v_ptr_s;
  VALUE_TYPE *__pyx_v_ptr_pfg;
  VALUE_TYPE *__pyx_v_ptr_wc;
  VALUE_TYPE *__pyx_v_ptr_dy;
  VALUE_TYPE *__pyx_v_ptr_drt;
  VALUE_TYPE *__pyx_v_ptr_dot;
  VALUE_TYPE *__pyx_v_ptr_dr;
  VALUE_TYPE *__pyx_v_ptr_dou;
  VALUE_TYPE *__pyx_v_ptr_dwc;
  bool __pyx_v_temp;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  uintptr_t __pyx_t_6;
  bool __pyx_t_7;
  __Pyx_RefNannySetupContext("cupeepholelstm_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":320
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,             # <<<<<<<<<<<<<<
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 *     cdef int N = u.shape[0]
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 320, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 320, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":321
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[13] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prestate, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dou, __pyx_v_dr, __pyx_v_dwc, __pyx_v_temporal};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 12+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 320, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[13] = {__pyx_t_2, __pyx_v_u, __pyx_v_prestate, __pyx_v_state, __pyx_v_prestate, __pyx_v_wc, __pyx_v_dy, __pyx_v_drt, __pyx_v_dot, __pyx_v_dou, __pyx_v_dr, __pyx_v_dwc, __pyx_v_temporal};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 12+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 320, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(12+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 320, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_u);
    __Pyx_GIVEREF(__pyx_v_u);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_u);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_state);
    __Pyx_GIVEREF(__pyx_v_state);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_state);
    __Pyx_INCREF(__pyx_v_prestate);
    __Pyx_GIVEREF(__pyx_v_prestate);
    PyTuple_SET_ITEM(__pyx_t_5, 3+__pyx_t_4, __pyx_v_prestate);
    __Pyx_INCREF(__pyx_v_wc);
    __Pyx_GIVEREF(__pyx_v_wc);
    PyTuple_SET_ITEM(__pyx_t_5, 4+__pyx_t_4, __pyx_v_wc);
    __Pyx_INCREF(__pyx_v_dy);
    __Pyx_GIVEREF(__pyx_v_dy);
    PyTuple_SET_ITEM(__pyx_t_5, 5+__pyx_t_4, __pyx_v_dy);
    __Pyx_INCREF(__pyx_v_drt);
    __Pyx_GIVEREF(__pyx_v_drt);
    PyTuple_SET_ITEM(__pyx_t_5, 6+__pyx_t_4, __pyx_v_drt);
    __Pyx_INCREF(__pyx_v_dot);
    __Pyx_GIVEREF(__pyx_v_dot);
    PyTuple_SET_ITEM(__pyx_t_5, 7+__pyx_t_4, __pyx_v_dot);
    __Pyx_INCREF(__pyx_v_dou);
    __Pyx_GIVEREF(__pyx_v_dou);
    PyTuple_SET_ITEM(__pyx_t_5, 8+__pyx_t_4, __pyx_v_dou);
    __Pyx_INCREF(__pyx_v_dr);
    __Pyx_GIVEREF(__pyx_v_dr);
    PyTuple_SET_ITEM(__pyx_t_5, 9+__pyx_t_4, __pyx_v_dr);
    __Pyx_INCREF(__pyx_v_dwc);
    __Pyx_GIVEREF(__pyx_v_dwc);
    PyTuple_SET_ITEM(__pyx_t_5, 10+__pyx_t_4, __pyx_v_dwc);
    __Pyx_INCREF(__pyx_v_temporal);
    __Pyx_GIVEREF(__pyx_v_temporal);
    PyTuple_SET_ITEM(__pyx_t_5, 11+__pyx_t_4, __pyx_v_temporal);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 320, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":322
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 *     cdef int N = u.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = u.shape[1]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 322, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_3); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 322, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":323
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_3, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 323, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 323, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_M = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":325
 *     cdef int M = u.shape[1]
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_u, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 325, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 325, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_u = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":326
 * 
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prestate, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 326, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 326, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_ps = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":327
 *     cdef VALUE_TYPE * ptr_u = < VALUE_TYPE * > < uintptr_t > u._ptr
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_state, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 327, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 327, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_s = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":328
 *     cdef VALUE_TYPE * ptr_ps = < VALUE_TYPE * > < uintptr_t > prestate._ptr
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_prefg, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 328, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 328, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_pfg = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":329
 *     cdef VALUE_TYPE * ptr_s = < VALUE_TYPE * > < uintptr_t > state._ptr
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_wc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 329, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 329, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_wc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":330
 *     cdef VALUE_TYPE * ptr_pfg = < VALUE_TYPE * > < uintptr_t > prefg._ptr
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 330, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 330, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dy = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":331
 *     cdef VALUE_TYPE * ptr_wc = < VALUE_TYPE * > < uintptr_t > wc._ptr
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_drt, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 331, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 331, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_drt = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":332
 *     cdef VALUE_TYPE * ptr_dy = < VALUE_TYPE * > < uintptr_t > dy._ptr
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dot, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 332, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 332, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dot = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":333
 *     cdef VALUE_TYPE * ptr_drt = < VALUE_TYPE * > < uintptr_t > drt._ptr
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dr, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 333, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 333, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":334
 *     cdef VALUE_TYPE * ptr_dot = < VALUE_TYPE * > < uintptr_t > dot._ptr
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 *     cdef bool temp = temporal
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dou, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 334, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 334, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dou = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":335
 *     cdef VALUE_TYPE * ptr_dr = < VALUE_TYPE * > < uintptr_t > dr._ptr
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr             # <<<<<<<<<<<<<<
 *     cdef bool temp = temporal
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_dwc, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 335, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 335, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr_dwc = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":336
 *     cdef VALUE_TYPE * ptr_dou = < VALUE_TYPE * > < uintptr_t > dou._ptr
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 *     cdef bool temp = temporal             # <<<<<<<<<<<<<<
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,
 *                                   ptr_dy, ptr_drt, ptr_dot, ptr_dr, ptr_dou, ptr_dwc, temp)
 */
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_v_temporal); if (unlikely((__pyx_t_7 == ((bool)-1)) && PyErr_Occurred())) __PYX_ERR(0, 336, __pyx_L1_error)
  __pyx_v_temp = __pyx_t_7;

  /* "renom/cuda/thrust_funcs.pxi":337
 *     cdef VALUE_TYPE * ptr_dwc = < VALUE_TYPE * > < uintptr_t > dwc._ptr
 *     cdef bool temp = temporal
 *     thrust_backward_peephole_lstm(N, M, ptr_u, ptr_ps, ptr_s, ptr_pfg, ptr_wc,             # <<<<<<<<<<<<<<
 *                                   ptr_dy, ptr_drt, ptr_dot, ptr_dr, ptr_dou, ptr_dwc, temp)
 * 
 */
  renom::thrust_backward_peephole_lstm(__pyx_v_N, __pyx_v_M, __pyx_v_ptr_u, __pyx_v_ptr_ps, __pyx_v_ptr_s, __pyx_v_ptr_pfg, __pyx_v_ptr_wc, __pyx_v_ptr_dy, __pyx_v_ptr_drt, __pyx_v_ptr_dot, __pyx_v_ptr_dr, __pyx_v_ptr_dou, __pyx_v_ptr_dwc, __pyx_v_temp);

  /* "renom/cuda/thrust_funcs.pxi":319
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cupeepholelstm_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":341
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_69cubinarize(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_69cubinarize = {"cubinarize", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_69cubinarize, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_69cubinarize(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_th = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cubinarize (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_th,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_th)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, 1); __PYX_ERR(0, 341, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, 2); __PYX_ERR(0, 341, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cubinarize") < 0)) __PYX_ERR(0, 341, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_th = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cubinarize", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 341, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cubinarize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_68cubinarize(__pyx_self, __pyx_v_gpu_value1, __pyx_v_th, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_68cubinarize(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_th, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_N;
  VALUE_TYPE *__pyx_v_gpu_ptr1;
  VALUE_TYPE *__pyx_v_gpu_ptr2;
  VALUE_TYPE __pyx_v_threathold;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  int __pyx_t_2;
  uintptr_t __pyx_t_3;
  VALUE_TYPE __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  PyObject *__pyx_t_7 = NULL;
  __Pyx_RefNannySetupContext("cubinarize", 0);

  /* "renom/cuda/thrust_funcs.pxi":342
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):
 *     cdef int N = gpu_value1.size             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 342, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_2 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 342, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_N = __pyx_t_2;

  /* "renom/cuda/thrust_funcs.pxi":343
 * def cubinarize(gpu_value1, th, gpu_value2):
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 343, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 343, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gpu_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":344
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 344, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 344, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_gpu_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":345
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)
 */
  __pyx_t_4 = __pyx_PyFloat_AsDouble(__pyx_v_th); if (unlikely((__pyx_t_4 == ((VALUE_TYPE)-1)) && PyErr_Occurred())) __PYX_ERR(0, 345, __pyx_L1_error)
  __pyx_v_threathold = __pyx_t_4;

  /* "renom/cuda/thrust_funcs.pxi":346
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)             # <<<<<<<<<<<<<<
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)
 * 
 */
  __pyx_t_5 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 346, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_6 = __Pyx_PyObject_GetAttrStr(__pyx_t_5, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 346, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_6);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = NULL;
  __pyx_t_2 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_6))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_6);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_6);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_6, function);
      __pyx_t_2 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_6)) {
    PyObject *__pyx_temp[3] = {__pyx_t_5, __pyx_v_gpu_value1, __pyx_v_gpu_value2};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_6, __pyx_temp+1-__pyx_t_2, 2+__pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(2+__pyx_t_2); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_2, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_2, __pyx_v_gpu_value2);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_6, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 346, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":347
 *     cdef VALUE_TYPE threathold = th
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 *     thrust_binarize(gpu_ptr1, threathold, N, gpu_ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_binarize(__pyx_v_gpu_ptr1, __pyx_v_threathold, __pyx_v_N, __pyx_v_gpu_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":341
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cubinarize", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":350
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_71cuembedding_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_71cuembedding_forward = {"cuembedding_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_71cuembedding_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_71cuembedding_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_weight = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuembedding_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_weight,&__pyx_n_s_gpu_value2,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_weight)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, 1); __PYX_ERR(0, 350, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, 2); __PYX_ERR(0, 350, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuembedding_forward") < 0)) __PYX_ERR(0, 350, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_weight = values[1];
    __pyx_v_gpu_value2 = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuembedding_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 350, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuembedding_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_70cuembedding_forward(__pyx_self, __pyx_v_gpu_value1, __pyx_v_weight, __pyx_v_gpu_value2);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_70cuembedding_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_weight, PyObject *__pyx_v_gpu_value2) {
  int __pyx_v_N;
  int __pyx_v_K;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_gpu_ptr1;
  VALUE_TYPE *__pyx_v_gpu_ptr2;
  VALUE_TYPE *__pyx_v_weight_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuembedding_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":351
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):
 *     cdef int N = gpu_value1.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 351, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 351, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 351, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":352
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 352, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_K = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":353
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 353, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":354
 *     cdef int K = weight.shape[0]
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 354, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gpu_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":355
 *     cdef int M = weight.shape[1]
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 355, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_gpu_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":356
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_weight, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 356, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_weight_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":357
 *     cdef VALUE_TYPE * gpu_ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)             # <<<<<<<<<<<<<<
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 357, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 357, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_3 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_3 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_weight};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_weight};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_3, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_3, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_weight);
    __Pyx_GIVEREF(__pyx_v_weight);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_3, __pyx_v_weight);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 357, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":358
 *     cdef VALUE_TYPE * weight_ptr = <VALUE_TYPE * > < uintptr_t > weight._ptr
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, weight)
 *     thrust_embedding_forward(N, K, M, gpu_ptr1, weight_ptr, gpu_ptr2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_embedding_forward(__pyx_v_N, __pyx_v_K, __pyx_v_M, __pyx_v_gpu_ptr1, __pyx_v_weight_ptr, __pyx_v_gpu_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":350
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuembedding_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":361
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_73cuembedding_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_73cuembedding_backward = {"cuembedding_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_73cuembedding_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_73cuembedding_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_index = 0;
  PyObject *__pyx_v_gpu_dy = 0;
  PyObject *__pyx_v_gpu_dx = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuembedding_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_index,&__pyx_n_s_gpu_dy,&__pyx_n_s_gpu_dx,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_index)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_dy)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, 1); __PYX_ERR(0, 361, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_dx)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, 2); __PYX_ERR(0, 361, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuembedding_backward") < 0)) __PYX_ERR(0, 361, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_gpu_index = values[0];
    __pyx_v_gpu_dy = values[1];
    __pyx_v_gpu_dx = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuembedding_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 361, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuembedding_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_72cuembedding_backward(__pyx_self, __pyx_v_gpu_index, __pyx_v_gpu_dy, __pyx_v_gpu_dx);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_72cuembedding_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_index, PyObject *__pyx_v_gpu_dy, PyObject *__pyx_v_gpu_dx) {
  int __pyx_v_N;
  int __pyx_v_K;
  int __pyx_v_M;
  VALUE_TYPE *__pyx_v_index_ptr;
  VALUE_TYPE *__pyx_v_dy_ptr;
  VALUE_TYPE *__pyx_v_dx_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  int __pyx_t_3;
  uintptr_t __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  PyObject *__pyx_t_6 = NULL;
  __Pyx_RefNannySetupContext("cuembedding_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":362
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):
 *     cdef int N = gpu_index.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_index, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 362, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_N = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":363
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]             # <<<<<<<<<<<<<<
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 363, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 363, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 363, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_K = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":364
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_2); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 364, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;

  /* "renom/cuda/thrust_funcs.pxi":365
 *     cdef int K = gpu_dx.shape[0]
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_index, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 365, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_index_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":366
 *     cdef int M = gpu_dx.shape[1]
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dy, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 366, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 366, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_dy_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":367
 *     cdef VALUE_TYPE * index_ptr = <VALUE_TYPE * > < uintptr_t > gpu_index._ptr
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_dx, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 367, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 367, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_dx_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":368
 *     cdef VALUE_TYPE * dy_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dy._ptr
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)             # <<<<<<<<<<<<<<
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 368, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 368, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_3 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_5);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_5, function);
      __pyx_t_3 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_dy, __pyx_v_gpu_index, __pyx_v_gpu_dx};
    __pyx_t_2 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 368, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_v_gpu_dy, __pyx_v_gpu_index, __pyx_v_gpu_dx};
    __pyx_t_2 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_3, 3+__pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 368, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_2);
  } else
  #endif
  {
    __pyx_t_6 = PyTuple_New(3+__pyx_t_3); if (unlikely(!__pyx_t_6)) __PYX_ERR(0, 368, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_6);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_6, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_dy);
    __Pyx_GIVEREF(__pyx_v_gpu_dy);
    PyTuple_SET_ITEM(__pyx_t_6, 0+__pyx_t_3, __pyx_v_gpu_dy);
    __Pyx_INCREF(__pyx_v_gpu_index);
    __Pyx_GIVEREF(__pyx_v_gpu_index);
    PyTuple_SET_ITEM(__pyx_t_6, 1+__pyx_t_3, __pyx_v_gpu_index);
    __Pyx_INCREF(__pyx_v_gpu_dx);
    __Pyx_GIVEREF(__pyx_v_gpu_dx);
    PyTuple_SET_ITEM(__pyx_t_6, 2+__pyx_t_3, __pyx_v_gpu_dx);
    __pyx_t_2 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_6, NULL); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 368, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_6); __pyx_t_6 = 0;
  }
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":369
 *     cdef VALUE_TYPE * dx_ptr = <VALUE_TYPE * > < uintptr_t > gpu_dx._ptr
 *     cuda_base.check_heap_device(gpu_dy, gpu_index, gpu_dx)
 *     thrust_embedding_backward(N, K, M, index_ptr, dy_ptr, dx_ptr)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  renom::thrust_embedding_backward(__pyx_v_N, __pyx_v_K, __pyx_v_M, __pyx_v_index_ptr, __pyx_v_dy_ptr, __pyx_v_dx_ptr);

  /* "renom/cuda/thrust_funcs.pxi":361
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_6);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuembedding_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":372
 * 
 * 
 * def cuconcat(gpu_value1, gpu_value2, gpu_value3, axis):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_75cuconcat(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_75cuconcat = {"cuconcat", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_75cuconcat, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_75cuconcat(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_gpu_value2 = 0;
  PyObject *__pyx_v_gpu_value3 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cuconcat (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_gpu_value2,&__pyx_n_s_gpu_value3,&__pyx_n_s_axis,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 4, 4, 1); __PYX_ERR(0, 372, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value3)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 4, 4, 2); __PYX_ERR(0, 372, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 4, 4, 3); __PYX_ERR(0, 372, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cuconcat") < 0)) __PYX_ERR(0, 372, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_gpu_value2 = values[1];
    __pyx_v_gpu_value3 = values[2];
    __pyx_v_axis = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cuconcat", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 372, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuconcat", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_74cuconcat(__pyx_self, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_74cuconcat(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_gpu_value2, PyObject *__pyx_v_gpu_value3, PyObject *__pyx_v_axis) {
  size_t __pyx_v_size;
  PyObject *__pyx_v_s1 = NULL;
  PyObject *__pyx_v_s2 = NULL;
  size_t __pyx_v_size1;
  size_t __pyx_v_size2;
  size_t __pyx_v_rec_size;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  VALUE_TYPE *__pyx_v_ptr3;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  int __pyx_t_4;
  PyObject *__pyx_t_5 = NULL;
  size_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  PyObject *__pyx_t_10 = NULL;
  PyObject *__pyx_t_11 = NULL;
  uintptr_t __pyx_t_12;
  __Pyx_RefNannySetupContext("cuconcat", 0);

  /* "renom/cuda/thrust_funcs.pxi":374
 * def cuconcat(gpu_value1, gpu_value2, gpu_value3, axis):
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)             # <<<<<<<<<<<<<<
 * 
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_cuda_base); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 374, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_check_heap_device); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 374, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 374, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_v_gpu_value1, __pyx_v_gpu_value2, __pyx_v_gpu_value3};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 374, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_1);
  } else
  #endif
  {
    __pyx_t_5 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 374, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_INCREF(__pyx_v_gpu_value1);
    __Pyx_GIVEREF(__pyx_v_gpu_value1);
    PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_4, __pyx_v_gpu_value1);
    __Pyx_INCREF(__pyx_v_gpu_value2);
    __Pyx_GIVEREF(__pyx_v_gpu_value2);
    PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_4, __pyx_v_gpu_value2);
    __Pyx_INCREF(__pyx_v_gpu_value3);
    __Pyx_GIVEREF(__pyx_v_gpu_value3);
    PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_4, __pyx_v_gpu_value3);
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_5, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 374, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":376
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 * 
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes             # <<<<<<<<<<<<<<
 *     if gpu_value3.nbytes < size:
 *         raise ValueError("Insufficient destination buffer size")
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 376, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 376, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = PyNumber_Add(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 376, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_5); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 376, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_size = __pyx_t_6;

  /* "renom/cuda/thrust_funcs.pxi":377
 * 
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes
 *     if gpu_value3.nbytes < size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Insufficient destination buffer size")
 * 
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_nbytes); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 377, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyInt_FromSize_t(__pyx_v_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 377, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = PyObject_RichCompare(__pyx_t_5, __pyx_t_3, Py_LT); __Pyx_XGOTREF(__pyx_t_1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 377, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 377, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  if (__pyx_t_7) {

    /* "renom/cuda/thrust_funcs.pxi":378
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes
 *     if gpu_value3.nbytes < size:
 *         raise ValueError("Insufficient destination buffer size")             # <<<<<<<<<<<<<<
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple_, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 378, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 378, __pyx_L1_error)

    /* "renom/cuda/thrust_funcs.pxi":377
 * 
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes
 *     if gpu_value3.nbytes < size:             # <<<<<<<<<<<<<<
 *         raise ValueError("Insufficient destination buffer size")
 * 
 */
  }

  /* "renom/cuda/thrust_funcs.pxi":380
 *         raise ValueError("Insufficient destination buffer size")
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):             # <<<<<<<<<<<<<<
 *         raise ValueError("zero-dimensional arrays cannot be concatenated")
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_8 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_8 < 0)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_9 = ((!__pyx_t_8) != 0);
  if (!__pyx_t_9) {
  } else {
    __pyx_t_7 = __pyx_t_9;
    goto __pyx_L5_bool_binop_done;
  }
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_9 = __Pyx_PyObject_IsTrue(__pyx_t_1); if (unlikely(__pyx_t_9 < 0)) __PYX_ERR(0, 380, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_8 = ((!__pyx_t_9) != 0);
  __pyx_t_7 = __pyx_t_8;
  __pyx_L5_bool_binop_done:;
  if (__pyx_t_7) {

    /* "renom/cuda/thrust_funcs.pxi":381
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):
 *         raise ValueError("zero-dimensional arrays cannot be concatenated")             # <<<<<<<<<<<<<<
 * 
 *     s1 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 */
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__2, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 381, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_Raise(__pyx_t_1, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __PYX_ERR(0, 381, __pyx_L1_error)

    /* "renom/cuda/thrust_funcs.pxi":380
 *         raise ValueError("Insufficient destination buffer size")
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):             # <<<<<<<<<<<<<<
 *         raise ValueError("zero-dimensional arrays cannot be concatenated")
 * 
 */
  }

  /* "renom/cuda/thrust_funcs.pxi":383
 *         raise ValueError("zero-dimensional arrays cannot be concatenated")
 * 
 *     s1 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]             # <<<<<<<<<<<<<<
 *     s2 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyObject_GetSlice(__pyx_t_1, 0, 0, NULL, &__pyx_v_axis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_PyObject_GetSlice(__pyx_t_1, 0, 0, &__pyx_t_5, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = PyNumber_Add(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 383, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_s1 = __pyx_t_5;
  __pyx_t_5 = 0;

  /* "renom/cuda/thrust_funcs.pxi":384
 * 
 *     s1 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 *     s2 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]             # <<<<<<<<<<<<<<
 * 
 *     if s1 != s2:
 */
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_2 = __Pyx_PyObject_GetSlice(__pyx_t_5, 0, 0, NULL, &__pyx_v_axis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __pyx_t_3 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_t_5, 0, 0, &__pyx_t_3, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Add(__pyx_t_2, __pyx_t_1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 384, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_s2 = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust_funcs.pxi":386
 *     s2 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 * 
 *     if s1 != s2:             # <<<<<<<<<<<<<<
 *         raise ValueError("all the input array dimensions except"
 *                          " for the concatenation axis must match exactly")
 */
  __pyx_t_3 = PyObject_RichCompare(__pyx_v_s1, __pyx_v_s2, Py_NE); __Pyx_XGOTREF(__pyx_t_3); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 386, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyObject_IsTrue(__pyx_t_3); if (unlikely(__pyx_t_7 < 0)) __PYX_ERR(0, 386, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  if (__pyx_t_7) {

    /* "renom/cuda/thrust_funcs.pxi":387
 * 
 *     if s1 != s2:
 *         raise ValueError("all the input array dimensions except"             # <<<<<<<<<<<<<<
 *                          " for the concatenation axis must match exactly")
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_builtin_ValueError, __pyx_tuple__3, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 387, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_Raise(__pyx_t_3, 0, 0, 0);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __PYX_ERR(0, 387, __pyx_L1_error)

    /* "renom/cuda/thrust_funcs.pxi":386
 *     s2 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 * 
 *     if s1 != s2:             # <<<<<<<<<<<<<<
 *         raise ValueError("all the input array dimensions except"
 *                          " for the concatenation axis must match exactly")
 */
  }

  /* "renom/cuda/thrust_funcs.pxi":390
 *                          " for the concatenation axis must match exactly")
 * 
 *     cdef size_t size1 = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *     cdef size_t size2 = functools.reduce(operator.__mul__, gpu_value2.shape[axis:], 1)
 *     cdef size_t rec_size = size1 + size2
 */
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_reduce); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_mul); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_10 = __Pyx_PyObject_GetSlice(__pyx_t_1, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_2))) {
    __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_2);
    if (likely(__pyx_t_1)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_2);
      __Pyx_INCREF(__pyx_t_1);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_2, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_t_10, __pyx_int_1};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_2)) {
    PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_5, __pyx_t_10, __pyx_int_1};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_2, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
  } else
  #endif
  {
    __pyx_t_11 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_11);
    if (__pyx_t_1) {
      __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_11, 0, __pyx_t_1); __pyx_t_1 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_11, 0+__pyx_t_4, __pyx_t_5);
    __Pyx_GIVEREF(__pyx_t_10);
    PyTuple_SET_ITEM(__pyx_t_11, 1+__pyx_t_4, __pyx_t_10);
    __Pyx_INCREF(__pyx_int_1);
    __Pyx_GIVEREF(__pyx_int_1);
    PyTuple_SET_ITEM(__pyx_t_11, 2+__pyx_t_4, __pyx_int_1);
    __pyx_t_5 = 0;
    __pyx_t_10 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_2, __pyx_t_11, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 390, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  }
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 390, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_size1 = __pyx_t_6;

  /* "renom/cuda/thrust_funcs.pxi":391
 * 
 *     cdef size_t size1 = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *     cdef size_t size2 = functools.reduce(operator.__mul__, gpu_value2.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *     cdef size_t rec_size = size1 + size2
 * 
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_11 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_reduce); if (unlikely(!__pyx_t_11)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_11);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_10 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_mul); if (unlikely(!__pyx_t_10)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_10);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = __Pyx_PyObject_GetSlice(__pyx_t_2, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = NULL;
  __pyx_t_4 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_11))) {
    __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_11);
    if (likely(__pyx_t_2)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_11);
      __Pyx_INCREF(__pyx_t_2);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_11, function);
      __pyx_t_4 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_11)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_t_10, __pyx_t_5, __pyx_int_1};
    __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_11)) {
    PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_t_10, __pyx_t_5, __pyx_int_1};
    __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_11, __pyx_temp+1-__pyx_t_4, 3+__pyx_t_4); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_10); __pyx_t_10 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  } else
  #endif
  {
    __pyx_t_1 = PyTuple_New(3+__pyx_t_4); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    if (__pyx_t_2) {
      __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_1, 0, __pyx_t_2); __pyx_t_2 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_10);
    PyTuple_SET_ITEM(__pyx_t_1, 0+__pyx_t_4, __pyx_t_10);
    __Pyx_GIVEREF(__pyx_t_5);
    PyTuple_SET_ITEM(__pyx_t_1, 1+__pyx_t_4, __pyx_t_5);
    __Pyx_INCREF(__pyx_int_1);
    __Pyx_GIVEREF(__pyx_int_1);
    PyTuple_SET_ITEM(__pyx_t_1, 2+__pyx_t_4, __pyx_int_1);
    __pyx_t_10 = 0;
    __pyx_t_5 = 0;
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_11, __pyx_t_1, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 391, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  }
  __Pyx_DECREF(__pyx_t_11); __pyx_t_11 = 0;
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 391, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_size2 = __pyx_t_6;

  /* "renom/cuda/thrust_funcs.pxi":392
 *     cdef size_t size1 = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *     cdef size_t size2 = functools.reduce(operator.__mul__, gpu_value2.shape[axis:], 1)
 *     cdef size_t rec_size = size1 + size2             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_v_rec_size = (__pyx_v_size1 + __pyx_v_size2);

  /* "renom/cuda/thrust_funcs.pxi":394
 *     cdef size_t rec_size = size1 + size2
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 394, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 394, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_12));

  /* "renom/cuda/thrust_funcs.pxi":395
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 395, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 395, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_12));

  /* "renom/cuda/thrust_funcs.pxi":396
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value2._ptr
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr             # <<<<<<<<<<<<<<
 * 
 *     thrust_copy_memory_stride(ptr3, ptr1, gpu_value1.size, rec_size, size1)
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value3, __pyx_n_s_ptr); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 396, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_12 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 396, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_ptr3 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_12));

  /* "renom/cuda/thrust_funcs.pxi":398
 *     cdef VALUE_TYPE * ptr3 = <VALUE_TYPE * > < uintptr_t > gpu_value3._ptr
 * 
 *     thrust_copy_memory_stride(ptr3, ptr1, gpu_value1.size, rec_size, size1)             # <<<<<<<<<<<<<<
 *     thrust_copy_memory_stride(ptr3 + size1, ptr2, gpu_value2.size, rec_size, size2)
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 398, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 398, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  renom::thrust_copy_memory_stride(__pyx_v_ptr3, __pyx_v_ptr1, __pyx_t_6, __pyx_v_rec_size, __pyx_v_size1);

  /* "renom/cuda/thrust_funcs.pxi":399
 * 
 *     thrust_copy_memory_stride(ptr3, ptr1, gpu_value1.size, rec_size, size1)
 *     thrust_copy_memory_stride(ptr3 + size1, ptr2, gpu_value2.size, rec_size, size2)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value2, __pyx_n_s_size); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 399, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_3); if (unlikely((__pyx_t_6 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 399, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  renom::thrust_copy_memory_stride((__pyx_v_ptr3 + __pyx_v_size1), __pyx_v_ptr2, __pyx_t_6, __pyx_v_rec_size, __pyx_v_size2);

  /* "renom/cuda/thrust_funcs.pxi":372
 * 
 * 
 * def cuconcat(gpu_value1, gpu_value2, gpu_value3, axis):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_10);
  __Pyx_XDECREF(__pyx_t_11);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cuconcat", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_s1);
  __Pyx_XDECREF(__pyx_v_s2);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":407
 *                             const size_t result_size)
 * 
 * cdef _reduce_array(gpu_value1, axis, REDUCE_FUNC f):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE xxx
 *     import renom.cuda
 */

static PyObject *__pyx_f_5renom_4cuda_13thrust_double__reduce_array(PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis, __pyx_t_5renom_4cuda_13thrust_double_REDUCE_FUNC __pyx_v_f) {
  PyObject *__pyx_v_renom = NULL;
  PyObject *__pyx_v_nsize = NULL;
  PyObject *__pyx_v_axis_size = NULL;
  PyObject *__pyx_v_elem_size = NULL;
  PyObject *__pyx_v_child_size = NULL;
  PyObject *__pyx_v_result_shape = NULL;
  PyObject *__pyx_v_result_size = NULL;
  PyObject *__pyx_v_result = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  int __pyx_t_6;
  PyObject *__pyx_t_7 = NULL;
  int __pyx_t_8;
  int __pyx_t_9;
  uintptr_t __pyx_t_10;
  size_t __pyx_t_11;
  size_t __pyx_t_12;
  size_t __pyx_t_13;
  size_t __pyx_t_14;
  size_t __pyx_t_15;
  __Pyx_RefNannySetupContext("_reduce_array", 0);

  /* "renom/cuda/thrust_funcs.pxi":409
 * cdef _reduce_array(gpu_value1, axis, REDUCE_FUNC f):
 *     cdef VALUE_TYPE xxx
 *     import renom.cuda             # <<<<<<<<<<<<<<
 *     nsize = functools.reduce(operator.__mul__, gpu_value1.shape, 1)
 * 
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_renom_cuda, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 409, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_renom = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":410
 *     cdef VALUE_TYPE xxx
 *     import renom.cuda
 *     nsize = functools.reduce(operator.__mul__, gpu_value1.shape, 1)             # <<<<<<<<<<<<<<
 * 
 *     if axis is None:
 */
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_reduce); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_2, __pyx_n_s_mul); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 410, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_5 = NULL;
  __pyx_t_6 = 0;
  if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_3))) {
    __pyx_t_5 = PyMethod_GET_SELF(__pyx_t_3);
    if (likely(__pyx_t_5)) {
      PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_3);
      __Pyx_INCREF(__pyx_t_5);
      __Pyx_INCREF(function);
      __Pyx_DECREF_SET(__pyx_t_3, function);
      __pyx_t_6 = 1;
    }
  }
  #if CYTHON_FAST_PYCALL
  if (PyFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_t_4, __pyx_t_2, __pyx_int_1};
    __pyx_t_1 = __Pyx_PyFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 410, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  #if CYTHON_FAST_PYCCALL
  if (__Pyx_PyFastCFunction_Check(__pyx_t_3)) {
    PyObject *__pyx_temp[4] = {__pyx_t_5, __pyx_t_4, __pyx_t_2, __pyx_int_1};
    __pyx_t_1 = __Pyx_PyCFunction_FastCall(__pyx_t_3, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 410, __pyx_L1_error)
    __Pyx_XDECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  } else
  #endif
  {
    __pyx_t_7 = PyTuple_New(3+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 410, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    if (__pyx_t_5) {
      __Pyx_GIVEREF(__pyx_t_5); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_5); __pyx_t_5 = NULL;
    }
    __Pyx_GIVEREF(__pyx_t_4);
    PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_4);
    __Pyx_GIVEREF(__pyx_t_2);
    PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_2);
    __Pyx_INCREF(__pyx_int_1);
    __Pyx_GIVEREF(__pyx_int_1);
    PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_6, __pyx_int_1);
    __pyx_t_4 = 0;
    __pyx_t_2 = 0;
    __pyx_t_1 = __Pyx_PyObject_Call(__pyx_t_3, __pyx_t_7, NULL); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 410, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  }
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_nsize = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":412
 *     nsize = functools.reduce(operator.__mul__, gpu_value1.shape, 1)
 * 
 *     if axis is None:             # <<<<<<<<<<<<<<
 *         axis_size = nsize
 *         elem_size = nsize
 */
  __pyx_t_8 = (__pyx_v_axis == Py_None);
  __pyx_t_9 = (__pyx_t_8 != 0);
  if (__pyx_t_9) {

    /* "renom/cuda/thrust_funcs.pxi":413
 * 
 *     if axis is None:
 *         axis_size = nsize             # <<<<<<<<<<<<<<
 *         elem_size = nsize
 *         child_size = 1
 */
    __Pyx_INCREF(__pyx_v_nsize);
    __pyx_v_axis_size = __pyx_v_nsize;

    /* "renom/cuda/thrust_funcs.pxi":414
 *     if axis is None:
 *         axis_size = nsize
 *         elem_size = nsize             # <<<<<<<<<<<<<<
 *         child_size = 1
 *         result_shape = ()
 */
    __Pyx_INCREF(__pyx_v_nsize);
    __pyx_v_elem_size = __pyx_v_nsize;

    /* "renom/cuda/thrust_funcs.pxi":415
 *         axis_size = nsize
 *         elem_size = nsize
 *         child_size = 1             # <<<<<<<<<<<<<<
 *         result_shape = ()
 *         result_size = 1
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_child_size = __pyx_int_1;

    /* "renom/cuda/thrust_funcs.pxi":416
 *         elem_size = nsize
 *         child_size = 1
 *         result_shape = ()             # <<<<<<<<<<<<<<
 *         result_size = 1
 *     else:
 */
    __Pyx_INCREF(__pyx_empty_tuple);
    __pyx_v_result_shape = __pyx_empty_tuple;

    /* "renom/cuda/thrust_funcs.pxi":417
 *         child_size = 1
 *         result_shape = ()
 *         result_size = 1             # <<<<<<<<<<<<<<
 *     else:
 *         axis_size = gpu_value1.shape[axis]
 */
    __Pyx_INCREF(__pyx_int_1);
    __pyx_v_result_size = __pyx_int_1;

    /* "renom/cuda/thrust_funcs.pxi":412
 *     nsize = functools.reduce(operator.__mul__, gpu_value1.shape, 1)
 * 
 *     if axis is None:             # <<<<<<<<<<<<<<
 *         axis_size = nsize
 *         elem_size = nsize
 */
    goto __pyx_L3;
  }

  /* "renom/cuda/thrust_funcs.pxi":419
 *         result_size = 1
 *     else:
 *         axis_size = gpu_value1.shape[axis]             # <<<<<<<<<<<<<<
 *         elem_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *         child_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 */
  /*else*/ {
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_3 = PyObject_GetItem(__pyx_t_1, __pyx_v_axis); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 419, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_axis_size = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust_funcs.pxi":420
 *     else:
 *         axis_size = gpu_value1.shape[axis]
 *         elem_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)             # <<<<<<<<<<<<<<
 *         child_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 *         result_shape = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 */
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_reduce); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_t_1, __pyx_n_s_mul); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __pyx_t_4 = __Pyx_PyObject_GetSlice(__pyx_t_1, 0, 0, &__pyx_v_axis, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 420, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_1 = NULL;
    __pyx_t_6 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_7))) {
      __pyx_t_1 = PyMethod_GET_SELF(__pyx_t_7);
      if (likely(__pyx_t_1)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_7);
        __Pyx_INCREF(__pyx_t_1);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_7, function);
        __pyx_t_6 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_2, __pyx_t_4, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 420, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_7)) {
      PyObject *__pyx_temp[4] = {__pyx_t_1, __pyx_t_2, __pyx_t_4, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_7, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 420, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_1); __pyx_t_1 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    } else
    #endif
    {
      __pyx_t_5 = PyTuple_New(3+__pyx_t_6); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 420, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_5);
      if (__pyx_t_1) {
        __Pyx_GIVEREF(__pyx_t_1); PyTuple_SET_ITEM(__pyx_t_5, 0, __pyx_t_1); __pyx_t_1 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_2);
      PyTuple_SET_ITEM(__pyx_t_5, 0+__pyx_t_6, __pyx_t_2);
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_5, 1+__pyx_t_6, __pyx_t_4);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_5, 2+__pyx_t_6, __pyx_int_1);
      __pyx_t_2 = 0;
      __pyx_t_4 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_7, __pyx_t_5, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 420, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    }
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_v_elem_size = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust_funcs.pxi":421
 *         axis_size = gpu_value1.shape[axis]
 *         elem_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *         child_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)             # <<<<<<<<<<<<<<
 *         result_shape = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 *         result_size = np.product(result_shape, dtype=int)
 */
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_functools); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_reduce); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_operator); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_mul); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_2 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_t_7, 0, 0, &__pyx_t_2, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 421, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
    __pyx_t_2 = NULL;
    __pyx_t_6 = 0;
    if (CYTHON_UNPACK_METHODS && unlikely(PyMethod_Check(__pyx_t_5))) {
      __pyx_t_2 = PyMethod_GET_SELF(__pyx_t_5);
      if (likely(__pyx_t_2)) {
        PyObject* function = PyMethod_GET_FUNCTION(__pyx_t_5);
        __Pyx_INCREF(__pyx_t_2);
        __Pyx_INCREF(function);
        __Pyx_DECREF_SET(__pyx_t_5, function);
        __pyx_t_6 = 1;
      }
    }
    #if CYTHON_FAST_PYCALL
    if (PyFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_t_4, __pyx_t_1, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 421, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    #if CYTHON_FAST_PYCCALL
    if (__Pyx_PyFastCFunction_Check(__pyx_t_5)) {
      PyObject *__pyx_temp[4] = {__pyx_t_2, __pyx_t_4, __pyx_t_1, __pyx_int_1};
      __pyx_t_3 = __Pyx_PyCFunction_FastCall(__pyx_t_5, __pyx_temp+1-__pyx_t_6, 3+__pyx_t_6); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 421, __pyx_L1_error)
      __Pyx_XDECREF(__pyx_t_2); __pyx_t_2 = 0;
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
      __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    } else
    #endif
    {
      __pyx_t_7 = PyTuple_New(3+__pyx_t_6); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 421, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_7);
      if (__pyx_t_2) {
        __Pyx_GIVEREF(__pyx_t_2); PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_t_2); __pyx_t_2 = NULL;
      }
      __Pyx_GIVEREF(__pyx_t_4);
      PyTuple_SET_ITEM(__pyx_t_7, 0+__pyx_t_6, __pyx_t_4);
      __Pyx_GIVEREF(__pyx_t_1);
      PyTuple_SET_ITEM(__pyx_t_7, 1+__pyx_t_6, __pyx_t_1);
      __Pyx_INCREF(__pyx_int_1);
      __Pyx_GIVEREF(__pyx_int_1);
      PyTuple_SET_ITEM(__pyx_t_7, 2+__pyx_t_6, __pyx_int_1);
      __pyx_t_4 = 0;
      __pyx_t_1 = 0;
      __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_t_7, NULL); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 421, __pyx_L1_error)
      __Pyx_GOTREF(__pyx_t_3);
      __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    }
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_child_size = __pyx_t_3;
    __pyx_t_3 = 0;

    /* "renom/cuda/thrust_funcs.pxi":422
 *         elem_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis:], 1)
 *         child_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 *         result_shape = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]             # <<<<<<<<<<<<<<
 *         result_size = np.product(result_shape, dtype=int)
 * 
 */
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_5 = __Pyx_PyObject_GetSlice(__pyx_t_3, 0, 0, NULL, &__pyx_v_axis, NULL, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_7 = __Pyx_PyInt_AddObjC(__pyx_v_axis, __pyx_int_1, 1, 0); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __Pyx_PyObject_GetSlice(__pyx_t_3, 0, 0, &__pyx_t_7, NULL, NULL, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyNumber_Add(__pyx_t_5, __pyx_t_1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 422, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_v_result_shape = __pyx_t_7;
    __pyx_t_7 = 0;

    /* "renom/cuda/thrust_funcs.pxi":423
 *         child_size = functools.reduce(operator.__mul__, gpu_value1.shape[axis + 1:], 1)
 *         result_shape = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 *         result_size = np.product(result_shape, dtype=int)             # <<<<<<<<<<<<<<
 * 
 *     result = renom.core.GPUValue(shape=result_shape)
 */
    __pyx_t_7 = __Pyx_GetModuleGlobalName(__pyx_n_s_np); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_t_7, __pyx_n_s_product); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_1);
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __pyx_t_7 = PyTuple_New(1); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_7);
    __Pyx_INCREF(__pyx_v_result_shape);
    __Pyx_GIVEREF(__pyx_v_result_shape);
    PyTuple_SET_ITEM(__pyx_t_7, 0, __pyx_v_result_shape);
    __pyx_t_5 = PyDict_New(); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    if (PyDict_SetItem(__pyx_t_5, __pyx_n_s_dtype, ((PyObject *)(&PyInt_Type))) < 0) __PYX_ERR(0, 423, __pyx_L1_error)
    __pyx_t_3 = __Pyx_PyObject_Call(__pyx_t_1, __pyx_t_7, __pyx_t_5); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 423, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_v_result_size = __pyx_t_3;
    __pyx_t_3 = 0;
  }
  __pyx_L3:;

  /* "renom/cuda/thrust_funcs.pxi":425
 *         result_size = np.product(result_shape, dtype=int)
 * 
 *     result = renom.core.GPUValue(shape=result_shape)             # <<<<<<<<<<<<<<
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_renom, __pyx_n_s_core); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 425, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_5 = __Pyx_PyObject_GetAttrStr(__pyx_t_3, __pyx_n_s_GPUValue); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 425, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyDict_New(); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 425, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  if (PyDict_SetItem(__pyx_t_3, __pyx_n_s_shape, __pyx_v_result_shape) < 0) __PYX_ERR(0, 425, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyObject_Call(__pyx_t_5, __pyx_empty_tuple, __pyx_t_3); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 425, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_result = __pyx_t_7;
  __pyx_t_7 = 0;

  /* "renom/cuda/thrust_funcs.pxi":427
 *     result = renom.core.GPUValue(shape=result_shape)
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 427, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_10));

  /* "renom/cuda/thrust_funcs.pxi":428
 * 
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr             # <<<<<<<<<<<<<<
 * 
 *     f(ptr1, nsize, axis_size, elem_size, child_size, ptr2, result_size)
 */
  __pyx_t_7 = __Pyx_PyObject_GetAttrStr(__pyx_v_result, __pyx_n_s_ptr); if (unlikely(!__pyx_t_7)) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_7);
  __pyx_t_10 = __Pyx_PyInt_As_size_t(__pyx_t_7); if (unlikely((__pyx_t_10 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 428, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_7); __pyx_t_7 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_10));

  /* "renom/cuda/thrust_funcs.pxi":430
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > result._ptr
 * 
 *     f(ptr1, nsize, axis_size, elem_size, child_size, ptr2, result_size)             # <<<<<<<<<<<<<<
 *     return result
 * 
 */
  __pyx_t_11 = __Pyx_PyInt_As_size_t(__pyx_v_nsize); if (unlikely((__pyx_t_11 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyInt_As_size_t(__pyx_v_axis_size); if (unlikely((__pyx_t_12 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyInt_As_size_t(__pyx_v_elem_size); if (unlikely((__pyx_t_13 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __pyx_t_14 = __Pyx_PyInt_As_size_t(__pyx_v_child_size); if (unlikely((__pyx_t_14 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __pyx_t_15 = __Pyx_PyInt_As_size_t(__pyx_v_result_size); if (unlikely((__pyx_t_15 == (size_t)-1) && PyErr_Occurred())) __PYX_ERR(0, 430, __pyx_L1_error)
  __pyx_v_f(__pyx_v_ptr1, __pyx_t_11, __pyx_t_12, __pyx_t_13, __pyx_t_14, __pyx_v_ptr2, __pyx_t_15);

  /* "renom/cuda/thrust_funcs.pxi":431
 * 
 *     f(ptr1, nsize, axis_size, elem_size, child_size, ptr2, result_size)
 *     return result             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __Pyx_INCREF(__pyx_v_result);
  __pyx_r = __pyx_v_result;
  goto __pyx_L0;

  /* "renom/cuda/thrust_funcs.pxi":407
 *                             const size_t result_size)
 * 
 * cdef _reduce_array(gpu_value1, axis, REDUCE_FUNC f):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE xxx
 *     import renom.cuda
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_XDECREF(__pyx_t_7);
  __Pyx_AddTraceback("renom.cuda.thrust_double._reduce_array", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = 0;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_renom);
  __Pyx_XDECREF(__pyx_v_nsize);
  __Pyx_XDECREF(__pyx_v_axis_size);
  __Pyx_XDECREF(__pyx_v_elem_size);
  __Pyx_XDECREF(__pyx_v_child_size);
  __Pyx_XDECREF(__pyx_v_result_shape);
  __Pyx_XDECREF(__pyx_v_result_size);
  __Pyx_XDECREF(__pyx_v_result);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":434
 * 
 * 
 * def cusum(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_sum)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_77cusum(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_77cusum = {"cusum", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_77cusum, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_77cusum(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cusum (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cusum") < 0)) __PYX_ERR(0, 434, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cusum", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 434, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_76cusum(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_76cusum(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cusum", 0);

  /* "renom/cuda/thrust_funcs.pxi":435
 * 
 * def cusum(gpu_value1, axis=None):
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_sum)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double__reduce_array(__pyx_v_gpu_value1, __pyx_v_axis, renom::thrust_reduce_sum); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 435, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust_funcs.pxi":434
 * 
 * 
 * def cusum(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_sum)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cusum", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":438
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_79cu_reduce_min(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_79cu_reduce_min = {"cu_reduce_min", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_79cu_reduce_min, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_79cu_reduce_min(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_min (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_min") < 0)) __PYX_ERR(0, 438, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_min", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 438, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_reduce_min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_78cu_reduce_min(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_78cu_reduce_min(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_min", 0);

  /* "renom/cuda/thrust_funcs.pxi":439
 * 
 * def cu_reduce_min(gpu_value1, axis=None):
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double__reduce_array(__pyx_v_gpu_value1, __pyx_v_axis, renom::thrust_reduce_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 439, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust_funcs.pxi":438
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_reduce_min", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":442
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_81cu_reduce_max(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_81cu_reduce_max = {"cu_reduce_max", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_81cu_reduce_max, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_81cu_reduce_max(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_gpu_value1 = 0;
  PyObject *__pyx_v_axis = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_reduce_max (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_gpu_value1,&__pyx_n_s_axis,0};
    PyObject* values[2] = {0,0};
    values[1] = ((PyObject *)Py_None);
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (kw_args > 0) {
          PyObject* value = PyDict_GetItem(__pyx_kwds, __pyx_n_s_axis);
          if (value) { values[1] = value; kw_args--; }
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_reduce_max") < 0)) __PYX_ERR(0, 442, __pyx_L3_error)
      }
    } else {
      switch (PyTuple_GET_SIZE(__pyx_args)) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        break;
        default: goto __pyx_L5_argtuple_error;
      }
    }
    __pyx_v_gpu_value1 = values[0];
    __pyx_v_axis = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_reduce_max", 0, 1, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 442, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_reduce_max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_80cu_reduce_max(__pyx_self, __pyx_v_gpu_value1, __pyx_v_axis);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_80cu_reduce_max(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_gpu_value1, PyObject *__pyx_v_axis) {
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannySetupContext("cu_reduce_max", 0);

  /* "renom/cuda/thrust_funcs.pxi":443
 * 
 * def cu_reduce_max(gpu_value1, axis=None):
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __Pyx_XDECREF(__pyx_r);
  __pyx_t_1 = __pyx_f_5renom_4cuda_13thrust_double__reduce_array(__pyx_v_gpu_value1, __pyx_v_axis, renom::thrust_reduce_min); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 443, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_r = __pyx_t_1;
  __pyx_t_1 = 0;
  goto __pyx_L0;

  /* "renom/cuda/thrust_funcs.pxi":442
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */

  /* function exit code */
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_reduce_max", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":446
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_83cu_add_bias(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_83cu_add_bias = {"cu_add_bias", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_83cu_add_bias, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_83cu_add_bias(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_bias = 0;
  PyObject *__pyx_v_gpu_value = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_add_bias (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_bias,&__pyx_n_s_gpu_value,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_bias)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_gpu_value)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_add_bias", 1, 2, 2, 1); __PYX_ERR(0, 446, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_add_bias") < 0)) __PYX_ERR(0, 446, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_bias = values[0];
    __pyx_v_gpu_value = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_add_bias", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 446, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_add_bias", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_82cu_add_bias(__pyx_self, __pyx_v_bias, __pyx_v_gpu_value);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_82cu_add_bias(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bias, PyObject *__pyx_v_gpu_value) {
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  int __pyx_v_size;
  int __pyx_v_wh;
  int __pyx_v_n;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  uintptr_t __pyx_t_2;
  int __pyx_t_3;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  __Pyx_RefNannySetupContext("cu_add_bias", 0);

  /* "renom/cuda/thrust_funcs.pxi":447
 * 
 * def cu_add_bias(bias, gpu_value):
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *     cdef int size = <int > gpu_value.size
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bias, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 447, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 447, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust_funcs.pxi":448
 * def cu_add_bias(bias, gpu_value):
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_2 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 448, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_2));

  /* "renom/cuda/thrust_funcs.pxi":449
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *     cdef int size = <int > gpu_value.size             # <<<<<<<<<<<<<<
 *     cdef int wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     cdef int n = <int > gpu_value.shape[0]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 449, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_size = ((int)__pyx_t_3);

  /* "renom/cuda/thrust_funcs.pxi":450
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])             # <<<<<<<<<<<<<<
 *     cdef int n = <int > gpu_value.shape[0]
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_4, __pyx_t_5); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_1); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 450, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_wh = ((int)__pyx_t_3);

  /* "renom/cuda/thrust_funcs.pxi":451
 *     cdef int size = <int > gpu_value.size
 *     cdef int wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     cdef int n = <int > gpu_value.shape[0]             # <<<<<<<<<<<<<<
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_gpu_value, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_5 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_5);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_3 = __Pyx_PyInt_As_int(__pyx_t_5); if (unlikely((__pyx_t_3 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 451, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
  __pyx_v_n = ((int)__pyx_t_3);

  /* "renom/cuda/thrust_funcs.pxi":452
 *     cdef int wh = <int > (gpu_value.shape[2] * gpu_value.shape[3])
 *     cdef int n = <int > gpu_value.shape[0]
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):
 */
  renom::thrust_add_bias(__pyx_v_size, __pyx_v_n, __pyx_v_wh, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":446
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_add_bias", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":454
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_85cu_get_fg_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_85cu_get_fg_ary_forward = {"cu_get_fg_ary_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_85cu_get_fg_ary_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_85cu_get_fg_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_v_fg_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_fg_ary_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary,&__pyx_n_s_fg_ary,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_fg_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_forward", 1, 2, 2, 1); __PYX_ERR(0, 454, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_fg_ary_forward") < 0)) __PYX_ERR(0, 454, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_ary = values[0];
    __pyx_v_fg_ary = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_forward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 454, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_fg_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_84cu_get_fg_ary_forward(__pyx_self, __pyx_v_ary, __pyx_v_fg_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_84cu_get_fg_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_fg_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("cu_get_fg_ary_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":455
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]             # <<<<<<<<<<<<<<
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 455, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":456
 * def cu_get_fg_ary_forward(ary, fg_ary):
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > fg_ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 456, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":457
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > fg_ary._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 457, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 457, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":458
 *     M = ary.shape[3] * ary.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > fg_ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_fg_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 458, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":459
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > fg_ary._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_fg_ary_backward(du, zero):
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 459, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 459, __pyx_L1_error)
  renom::thrust_get_fg_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":454
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_fg_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":461
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_87cu_get_fg_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_87cu_get_fg_ary_backward = {"cu_get_fg_ary_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_87cu_get_fg_ary_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_87cu_get_fg_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_zero = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_fg_ary_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_zero,0};
    PyObject* values[2] = {0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_zero)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_backward", 1, 2, 2, 1); __PYX_ERR(0, 461, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_fg_ary_backward") < 0)) __PYX_ERR(0, 461, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 2) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
    }
    __pyx_v_du = values[0];
    __pyx_v_zero = values[1];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_fg_ary_backward", 1, 2, 2, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 461, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_fg_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_86cu_get_fg_ary_backward(__pyx_self, __pyx_v_du, __pyx_v_zero);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_86cu_get_fg_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  __Pyx_RefNannySetupContext("cu_get_fg_ary_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":462
 * 
 * def cu_get_fg_ary_backward(du, zero):
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]             # <<<<<<<<<<<<<<
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_3, 2, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_t_3 = PyNumber_Multiply(__pyx_t_1, __pyx_t_2); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = PyNumber_Multiply(__pyx_t_3, __pyx_t_1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_2, __pyx_t_3); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 462, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":463
 * def cu_get_fg_ary_backward(du, zero):
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_1, 3, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 4, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_t_1 = PyNumber_Multiply(__pyx_t_3, __pyx_t_2); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 463, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":464
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 464, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":465
 *     M = du.shape[3] * du.shape[4]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 465, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":466
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 466, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 466, __pyx_L1_error)
  renom::thrust_get_fg_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":461
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_fg_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":468
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_89cu_get_ith_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_89cu_get_ith_ary_forward = {"cu_get_ith_ary_forward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_89cu_get_ith_ary_forward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_89cu_get_ith_ary_forward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_v_ith_ary = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_ary_forward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary,&__pyx_n_s_ith_ary,&__pyx_n_s_i,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ith_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, 1); __PYX_ERR(0, 468, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, 2); __PYX_ERR(0, 468, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_ary_forward") < 0)) __PYX_ERR(0, 468, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_ary = values[0];
    __pyx_v_ith_ary = values[1];
    __pyx_v_i = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_forward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 468, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_88cu_get_ith_ary_forward(__pyx_self, __pyx_v_ary, __pyx_v_ith_ary, __pyx_v_i);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_88cu_get_ith_ary_forward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary, PyObject *__pyx_v_ith_ary, PyObject *__pyx_v_i) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_ith_ary_forward", 0);

  /* "renom/cuda/thrust_funcs.pxi":469
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):
 *     N = ary.size             # <<<<<<<<<<<<<<
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 469, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":470
 * def cu_get_ith_ary_forward(ary, ith_ary, i):
 *     N = ary.size
 *     M = ary.size / ary.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ith_ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyNumber_Divide(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 470, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_M = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":471
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ith_ary._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 471, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 471, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":472
 *     M = ary.size / ary.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ith_ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ith_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 472, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 472, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":473
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ith_ary._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_ith_ary_backward(du, zero, i):
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 473, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 473, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 473, __pyx_L1_error)
  renom::thrust_get_ith_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":468
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_ary_forward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":475
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_91cu_get_ith_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_91cu_get_ith_ary_backward = {"cu_get_ith_ary_backward", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_91cu_get_ith_ary_backward, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_91cu_get_ith_ary_backward(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_du = 0;
  PyObject *__pyx_v_zero = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_ary_backward (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_du,&__pyx_n_s_zero,&__pyx_n_s_i,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_du)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_zero)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, 1); __PYX_ERR(0, 475, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, 2); __PYX_ERR(0, 475, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_ary_backward") < 0)) __PYX_ERR(0, 475, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_du = values[0];
    __pyx_v_zero = values[1];
    __pyx_v_i = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_ary_backward", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 475, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_90cu_get_ith_ary_backward(__pyx_self, __pyx_v_du, __pyx_v_zero, __pyx_v_i);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_90cu_get_ith_ary_backward(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_du, PyObject *__pyx_v_zero, PyObject *__pyx_v_i) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  uintptr_t __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_ith_ary_backward", 0);

  /* "renom/cuda/thrust_funcs.pxi":476
 * 
 * def cu_get_ith_ary_backward(du, zero, i):
 *     N = zero.size             # <<<<<<<<<<<<<<
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 476, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_v_N = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":477
 * def cu_get_ith_ary_backward(du, zero, i):
 *     N = zero.size
 *     M = zero.size / zero.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_size); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_3 = __Pyx_GetItemInt(__pyx_t_2, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_3);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_t_2 = __Pyx_PyNumber_Divide(__pyx_t_1, __pyx_t_3); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 477, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __Pyx_DECREF(__pyx_t_3); __pyx_t_3 = 0;
  __pyx_v_M = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":478
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_du, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 478, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":479
 *     M = zero.size / zero.shape[0]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_zero, __pyx_n_s_ptr); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_4 = __Pyx_PyInt_As_size_t(__pyx_t_2); if (unlikely((__pyx_t_4 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 479, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_4));

  /* "renom/cuda/thrust_funcs.pxi":480
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > du._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > zero._ptr
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):
 */
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 480, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 480, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 480, __pyx_L1_error)
  renom::thrust_get_ith_ary_forward(__pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":475
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_ary_backward", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":482
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_93cu_get_every_nth_ary(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_93cu_get_every_nth_ary = {"cu_get_every_nth_ary", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_93cu_get_every_nth_ary, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_93cu_get_every_nth_ary(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_ary1 = 0;
  PyObject *__pyx_v_ary2 = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_v_j = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_every_nth_ary (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_ary1,&__pyx_n_s_ary2,&__pyx_n_s_i,&__pyx_n_s_j,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary1)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary2)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 1); __PYX_ERR(0, 482, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 2); __PYX_ERR(0, 482, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_j)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, 3); __PYX_ERR(0, 482, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_every_nth_ary") < 0)) __PYX_ERR(0, 482, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_ary1 = values[0];
    __pyx_v_ary2 = values[1];
    __pyx_v_i = values[2];
    __pyx_v_j = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_every_nth_ary", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 482, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_every_nth_ary", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_92cu_get_every_nth_ary(__pyx_self, __pyx_v_ary1, __pyx_v_ary2, __pyx_v_i, __pyx_v_j);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_92cu_get_every_nth_ary(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_ary1, PyObject *__pyx_v_ary2, PyObject *__pyx_v_i, PyObject *__pyx_v_j) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ptr1;
  VALUE_TYPE *__pyx_v_ptr2;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  uintptr_t __pyx_t_3;
  int __pyx_t_4;
  int __pyx_t_5;
  int __pyx_t_6;
  int __pyx_t_7;
  __Pyx_RefNannySetupContext("cu_get_every_nth_ary", 0);

  /* "renom/cuda/thrust_funcs.pxi":483
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):
 *     N = ary1.shape[0]             # <<<<<<<<<<<<<<
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary1._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_2 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 483, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;

  /* "renom/cuda/thrust_funcs.pxi":484
 * def cu_get_every_nth_ary(ary1, ary2, i, j):
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ary2._ptr
 */
  __pyx_t_2 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_shape); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 484, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_2);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_2, 1, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 484, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_2); __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":485
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary1._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ary2._ptr
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary1, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 485, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 485, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr1 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":486
 *     M = ary1.shape[1]
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ary2._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary2, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 486, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_3 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_3 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 486, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ptr2 = ((VALUE_TYPE *)((uintptr_t)__pyx_t_3));

  /* "renom/cuda/thrust_funcs.pxi":487
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > ary1._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > <uintptr_t > ary2._ptr
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)             # <<<<<<<<<<<<<<
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):
 */
  __pyx_t_4 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_4 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
  __pyx_t_5 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_5 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
  __pyx_t_6 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_6 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_j); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 487, __pyx_L1_error)
  renom::thrust_get_nth_ary(__pyx_t_4, __pyx_t_5, __pyx_t_6, __pyx_t_7, __pyx_v_ptr1, __pyx_v_ptr2);

  /* "renom/cuda/thrust_funcs.pxi":482
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_every_nth_ary", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":489
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_95cu_assign_pred_box(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_95cu_assign_pred_box = {"cu_assign_pred_box", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_95cu_assign_pred_box, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_95cu_assign_pred_box(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_x = 0;
  PyObject *__pyx_v_y = 0;
  PyObject *__pyx_v_w = 0;
  PyObject *__pyx_v_h = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_assign_pred_box (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_x,&__pyx_n_s_y,&__pyx_n_s_w,&__pyx_n_s_h,&__pyx_n_s_ary,0};
    PyObject* values[5] = {0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_x)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_y)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 1); __PYX_ERR(0, 489, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_w)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 2); __PYX_ERR(0, 489, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_h)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 3); __PYX_ERR(0, 489, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, 4); __PYX_ERR(0, 489, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_assign_pred_box") < 0)) __PYX_ERR(0, 489, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 5) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
    }
    __pyx_v_x = values[0];
    __pyx_v_y = values[1];
    __pyx_v_w = values[2];
    __pyx_v_h = values[3];
    __pyx_v_ary = values[4];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_assign_pred_box", 1, 5, 5, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 489, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_assign_pred_box", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_94cu_assign_pred_box(__pyx_self, __pyx_v_x, __pyx_v_y, __pyx_v_w, __pyx_v_h, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_94cu_assign_pred_box(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_x, PyObject *__pyx_v_y, PyObject *__pyx_v_w, PyObject *__pyx_v_h, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_ary_ptr;
  VALUE_TYPE *__pyx_v_x_ptr;
  VALUE_TYPE *__pyx_v_y_ptr;
  VALUE_TYPE *__pyx_v_h_ptr;
  VALUE_TYPE *__pyx_v_w_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_assign_pred_box", 0);

  /* "renom/cuda/thrust_funcs.pxi":490
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):
 *     N, M = ary.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE *> <uintptr_t> x._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 490, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 490, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 490, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 490, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 490, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 490, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 490, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust_funcs.pxi":491
 * def cu_assign_pred_box(x, y, w, h, ary):
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE *> <uintptr_t> x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE *> <uintptr_t> y._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 491, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 491, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":492
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE *> <uintptr_t> x._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE *> <uintptr_t> y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE *> <uintptr_t> h._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_x, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 492, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 492, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_x_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":493
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE *> <uintptr_t> x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE *> <uintptr_t> y._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE *> <uintptr_t> h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE *> <uintptr_t> w._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_y, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 493, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_y_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":494
 *     cdef VALUE_TYPE * x_ptr = <VALUE_TYPE *> <uintptr_t> x._ptr
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE *> <uintptr_t> y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE *> <uintptr_t> h._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE *> <uintptr_t> w._ptr
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_h, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 494, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 494, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_h_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":495
 *     cdef VALUE_TYPE * y_ptr = <VALUE_TYPE *> <uintptr_t> y._ptr
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE *> <uintptr_t> h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE *> <uintptr_t> w._ptr             # <<<<<<<<<<<<<<
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_w, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 495, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 495, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_w_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":496
 *     cdef VALUE_TYPE * h_ptr = <VALUE_TYPE *> <uintptr_t> h._ptr
 *     cdef VALUE_TYPE * w_ptr = <VALUE_TYPE *> <uintptr_t> w._ptr
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 496, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 496, __pyx_L1_error)
  renom::thrust_assign_pred_box(__pyx_t_7, __pyx_t_8, __pyx_v_x_ptr, __pyx_v_y_ptr, __pyx_v_h_ptr, __pyx_v_w_ptr, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust_funcs.pxi":489
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_assign_pred_box", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":498
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_97cu_pred_ctr(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_97cu_pred_ctr = {"cu_pred_ctr", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_97cu_pred_ctr, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_97cu_pred_ctr(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_arg = 0;
  PyObject *__pyx_v_length = 0;
  PyObject *__pyx_v_ctr = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_pred_ctr (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_arg,&__pyx_n_s_length,&__pyx_n_s_ctr,&__pyx_n_s_ary,0};
    PyObject* values[4] = {0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_arg)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_length)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 1); __PYX_ERR(0, 498, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ctr)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 2); __PYX_ERR(0, 498, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, 3); __PYX_ERR(0, 498, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_pred_ctr") < 0)) __PYX_ERR(0, 498, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 4) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
    }
    __pyx_v_arg = values[0];
    __pyx_v_length = values[1];
    __pyx_v_ctr = values[2];
    __pyx_v_ary = values[3];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_pred_ctr", 1, 4, 4, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 498, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_pred_ctr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_96cu_pred_ctr(__pyx_self, __pyx_v_arg, __pyx_v_length, __pyx_v_ctr, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_96cu_pred_ctr(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_arg, PyObject *__pyx_v_length, PyObject *__pyx_v_ctr, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_arg_ptr;
  VALUE_TYPE *__pyx_v_length_ptr;
  VALUE_TYPE *__pyx_v_ctr_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  __Pyx_RefNannySetupContext("cu_pred_ctr", 0);

  /* "renom/cuda/thrust_funcs.pxi":499
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):
 *     N, M = ary.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 *     cdef VALUE_TYPE *length_ptr = <VALUE_TYPE *><uintptr_t> length._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 499, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 499, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 499, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 499, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 499, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust_funcs.pxi":500
 * def cu_pred_ctr(arg, length, ctr, ary):
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE *length_ptr = <VALUE_TYPE *><uintptr_t> length._ptr
 *     cdef VALUE_TYPE *ctr_ptr = <VALUE_TYPE *><uintptr_t> ctr._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_arg, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 500, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 500, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_arg_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":501
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 *     cdef VALUE_TYPE *length_ptr = <VALUE_TYPE *><uintptr_t> length._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE *ctr_ptr = <VALUE_TYPE *><uintptr_t> ctr._ptr
 *     cdef VALUE_TYPE *ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_length, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 501, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 501, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_length_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":502
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 *     cdef VALUE_TYPE *length_ptr = <VALUE_TYPE *><uintptr_t> length._ptr
 *     cdef VALUE_TYPE *ctr_ptr = <VALUE_TYPE *><uintptr_t> ctr._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE *ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ctr, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 502, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 502, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ctr_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":503
 *     cdef VALUE_TYPE *length_ptr = <VALUE_TYPE *><uintptr_t> length._ptr
 *     cdef VALUE_TYPE *ctr_ptr = <VALUE_TYPE *><uintptr_t> ctr._ptr
 *     cdef VALUE_TYPE *ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 503, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 503, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":504
 *     cdef VALUE_TYPE *ctr_ptr = <VALUE_TYPE *><uintptr_t> ctr._ptr
 *     cdef VALUE_TYPE *ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 504, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 504, __pyx_L1_error)
  renom::thrust_pred_ctr(__pyx_t_7, __pyx_t_8, __pyx_v_arg_ptr, __pyx_v_length_ptr, __pyx_v_ctr_ptr, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust_funcs.pxi":498
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_pred_ctr", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":506
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_99cu_generate_anchors(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_99cu_generate_anchors = {"cu_generate_anchors", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_99cu_generate_anchors, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_99cu_generate_anchors(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_shifts = 0;
  PyObject *__pyx_v_base_size = 0;
  PyObject *__pyx_v_ratios = 0;
  PyObject *__pyx_v_scales = 0;
  PyObject *__pyx_v_feat_stride = 0;
  PyObject *__pyx_v_anchors = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_generate_anchors (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_shifts,&__pyx_n_s_base_size,&__pyx_n_s_ratios,&__pyx_n_s_scales,&__pyx_n_s_feat_stride,&__pyx_n_s_anchors,0};
    PyObject* values[6] = {0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_shifts)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_base_size)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 1); __PYX_ERR(0, 506, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ratios)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 2); __PYX_ERR(0, 506, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_scales)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 3); __PYX_ERR(0, 506, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_feat_stride)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 4); __PYX_ERR(0, 506, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_anchors)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, 5); __PYX_ERR(0, 506, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_generate_anchors") < 0)) __PYX_ERR(0, 506, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 6) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
    }
    __pyx_v_shifts = values[0];
    __pyx_v_base_size = values[1];
    __pyx_v_ratios = values[2];
    __pyx_v_scales = values[3];
    __pyx_v_feat_stride = values[4];
    __pyx_v_anchors = values[5];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_generate_anchors", 1, 6, 6, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 506, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_generate_anchors", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_98cu_generate_anchors(__pyx_self, __pyx_v_shifts, __pyx_v_base_size, __pyx_v_ratios, __pyx_v_scales, __pyx_v_feat_stride, __pyx_v_anchors);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_98cu_generate_anchors(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_shifts, PyObject *__pyx_v_base_size, PyObject *__pyx_v_ratios, PyObject *__pyx_v_scales, PyObject *__pyx_v_feat_stride, PyObject *__pyx_v_anchors) {
  PyObject *__pyx_v_K = NULL;
  PyObject *__pyx_v_A = NULL;
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_scale_size = NULL;
  PyObject *__pyx_v_ratio_size = NULL;
  VALUE_TYPE *__pyx_v_shifts_ptr;
  VALUE_TYPE *__pyx_v_ratios_ptr;
  VALUE_TYPE *__pyx_v_scales_ptr;
  VALUE_TYPE *__pyx_v_anchors_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *__pyx_t_5 = NULL;
  PyObject *(*__pyx_t_6)(PyObject *);
  uintptr_t __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  int __pyx_t_14;
  __Pyx_RefNannySetupContext("cu_generate_anchors", 0);

  /* "renom/cuda/thrust_funcs.pxi":507
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):
 *     K, A, N = anchors.shape             # <<<<<<<<<<<<<<
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_anchors, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 507, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 3)) {
      if (size > 3) __Pyx_RaiseTooManyValuesError(3);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 507, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
      __pyx_t_4 = PyTuple_GET_ITEM(sequence, 2); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
      __pyx_t_4 = PyList_GET_ITEM(sequence, 2); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    __Pyx_INCREF(__pyx_t_4);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 507, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 507, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    __pyx_t_4 = PySequence_ITEM(sequence, 2); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 507, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_5 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_5)) __PYX_ERR(0, 507, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_5);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_6 = Py_TYPE(__pyx_t_5)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    index = 2; __pyx_t_4 = __pyx_t_6(__pyx_t_5); if (unlikely(!__pyx_t_4)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_4);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_6(__pyx_t_5), 3) < 0) __PYX_ERR(0, 507, __pyx_L1_error)
    __pyx_t_6 = NULL;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_5); __pyx_t_5 = 0;
    __pyx_t_6 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 507, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_K = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_A = __pyx_t_3;
  __pyx_t_3 = 0;
  __pyx_v_N = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/thrust_funcs.pxi":508
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]             # <<<<<<<<<<<<<<
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE *><uintptr_t> shifts._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_scales, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_4 = __Pyx_GetItemInt(__pyx_t_1, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 508, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_scale_size = __pyx_t_4;
  __pyx_t_4 = 0;

  /* "renom/cuda/thrust_funcs.pxi":509
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE *><uintptr_t> shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE *><uintptr_t> ratios._ptr
 */
  __pyx_t_4 = __Pyx_PyObject_GetAttrStr(__pyx_v_ratios, __pyx_n_s_shape); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 509, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_4);
  __pyx_t_1 = __Pyx_GetItemInt(__pyx_t_4, 0, long, 1, __Pyx_PyInt_From_long, 0, 0, 1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 509, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
  __pyx_v_ratio_size = __pyx_t_1;
  __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":510
 *     scale_size = scales.shape[0]
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE *><uintptr_t> shifts._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE *><uintptr_t> ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE *><uintptr_t> scales._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_shifts, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 510, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_shifts_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust_funcs.pxi":511
 *     ratio_size = ratios.shape[0]
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE *><uintptr_t> shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE *><uintptr_t> ratios._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE *><uintptr_t> scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE *><uintptr_t> anchors._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ratios, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 511, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ratios_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust_funcs.pxi":512
 *     cdef VALUE_TYPE * shifts_ptr = <VALUE_TYPE *><uintptr_t> shifts._ptr
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE *><uintptr_t> ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE *><uintptr_t> scales._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE *><uintptr_t> anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_scales, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 512, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_scales_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust_funcs.pxi":513
 *     cdef VALUE_TYPE * ratios_ptr = <VALUE_TYPE *><uintptr_t> ratios._ptr
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE *><uintptr_t> scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE *><uintptr_t> anchors._ptr             # <<<<<<<<<<<<<<
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_anchors, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 513, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_7 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_7 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 513, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_anchors_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_7));

  /* "renom/cuda/thrust_funcs.pxi":514
 *     cdef VALUE_TYPE * scales_ptr = <VALUE_TYPE *><uintptr_t> scales._ptr
 *     cdef VALUE_TYPE * anchors_ptr = <VALUE_TYPE *><uintptr_t> anchors._ptr
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)             # <<<<<<<<<<<<<<
 * 
 * def cu_get_ith_bbox(bbox, i, ary):
 */
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_A); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_K); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_v_ratio_size); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_v_scale_size); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_v_feat_stride); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  __pyx_t_14 = __Pyx_PyInt_As_int(__pyx_v_base_size); if (unlikely((__pyx_t_14 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 514, __pyx_L1_error)
  renom::thrust_generate_anchors(__pyx_t_8, __pyx_t_9, __pyx_t_10, __pyx_v_shifts_ptr, __pyx_v_ratios_ptr, __pyx_v_scales_ptr, __pyx_t_11, __pyx_t_12, __pyx_t_13, __pyx_t_14, __pyx_v_anchors_ptr);

  /* "renom/cuda/thrust_funcs.pxi":506
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_XDECREF(__pyx_t_5);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_generate_anchors", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_K);
  __Pyx_XDECREF(__pyx_v_A);
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_scale_size);
  __Pyx_XDECREF(__pyx_v_ratio_size);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":516
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_101cu_get_ith_bbox(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_101cu_get_ith_bbox = {"cu_get_ith_bbox", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_101cu_get_ith_bbox, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_101cu_get_ith_bbox(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_bbox = 0;
  PyObject *__pyx_v_i = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_get_ith_bbox (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_bbox,&__pyx_n_s_i,&__pyx_n_s_ary,0};
    PyObject* values[3] = {0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_bbox)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_i)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, 1); __PYX_ERR(0, 516, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, 2); __PYX_ERR(0, 516, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_get_ith_bbox") < 0)) __PYX_ERR(0, 516, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 3) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
    }
    __pyx_v_bbox = values[0];
    __pyx_v_i = values[1];
    __pyx_v_ary = values[2];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_get_ith_bbox", 1, 3, 3, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 516, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_bbox", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_100cu_get_ith_bbox(__pyx_self, __pyx_v_bbox, __pyx_v_i, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_100cu_get_ith_bbox(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_bbox, PyObject *__pyx_v_i, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_bbox_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  __Pyx_RefNannySetupContext("cu_get_ith_bbox", 0);

  /* "renom/cuda/thrust_funcs.pxi":517
 * 
 * def cu_get_ith_bbox(bbox, i, ary):
 *     N, M = bbox.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bbox, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 517, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 517, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 517, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 517, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 517, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 517, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 517, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust_funcs.pxi":518
 * def cu_get_ith_bbox(bbox, i, ary):
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_bbox, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 518, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 518, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_bbox_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":519
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 519, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 519, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":520
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)             # <<<<<<<<<<<<<<
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 520, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 520, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_i); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 520, __pyx_L1_error)
  renom::thrust_get_ith_bbox(__pyx_t_7, __pyx_t_8, __pyx_v_bbox_ptr, __pyx_t_9, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust_funcs.pxi":516
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_get_ith_bbox", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

/* "renom/cuda/thrust_funcs.pxi":522
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 */

/* Python wrapper */
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_103cu_clip_roi(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds); /*proto*/
static PyMethodDef __pyx_mdef_5renom_4cuda_13thrust_double_103cu_clip_roi = {"cu_clip_roi", (PyCFunction)__pyx_pw_5renom_4cuda_13thrust_double_103cu_clip_roi, METH_VARARGS|METH_KEYWORDS, 0};
static PyObject *__pyx_pw_5renom_4cuda_13thrust_double_103cu_clip_roi(PyObject *__pyx_self, PyObject *__pyx_args, PyObject *__pyx_kwds) {
  PyObject *__pyx_v_roi = 0;
  PyObject *__pyx_v_start = 0;
  PyObject *__pyx_v_end = 0;
  PyObject *__pyx_v_step = 0;
  PyObject *__pyx_v_min_v = 0;
  PyObject *__pyx_v_max_v = 0;
  PyObject *__pyx_v_ary = 0;
  PyObject *__pyx_r = 0;
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("cu_clip_roi (wrapper)", 0);
  {
    static PyObject **__pyx_pyargnames[] = {&__pyx_n_s_roi,&__pyx_n_s_start,&__pyx_n_s_end,&__pyx_n_s_step,&__pyx_n_s_min_v,&__pyx_n_s_max_v,&__pyx_n_s_ary,0};
    PyObject* values[7] = {0,0,0,0,0,0,0};
    if (unlikely(__pyx_kwds)) {
      Py_ssize_t kw_args;
      const Py_ssize_t pos_args = PyTuple_GET_SIZE(__pyx_args);
      switch (pos_args) {
        case  7: values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
        CYTHON_FALLTHROUGH;
        case  6: values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
        CYTHON_FALLTHROUGH;
        case  5: values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
        CYTHON_FALLTHROUGH;
        case  4: values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
        CYTHON_FALLTHROUGH;
        case  3: values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
        CYTHON_FALLTHROUGH;
        case  2: values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
        CYTHON_FALLTHROUGH;
        case  1: values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
        CYTHON_FALLTHROUGH;
        case  0: break;
        default: goto __pyx_L5_argtuple_error;
      }
      kw_args = PyDict_Size(__pyx_kwds);
      switch (pos_args) {
        case  0:
        if (likely((values[0] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_roi)) != 0)) kw_args--;
        else goto __pyx_L5_argtuple_error;
        CYTHON_FALLTHROUGH;
        case  1:
        if (likely((values[1] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_start)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 1); __PYX_ERR(0, 522, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  2:
        if (likely((values[2] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_end)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 2); __PYX_ERR(0, 522, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  3:
        if (likely((values[3] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_step)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 3); __PYX_ERR(0, 522, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  4:
        if (likely((values[4] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_min_v)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 4); __PYX_ERR(0, 522, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  5:
        if (likely((values[5] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_max_v)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 5); __PYX_ERR(0, 522, __pyx_L3_error)
        }
        CYTHON_FALLTHROUGH;
        case  6:
        if (likely((values[6] = PyDict_GetItem(__pyx_kwds, __pyx_n_s_ary)) != 0)) kw_args--;
        else {
          __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, 6); __PYX_ERR(0, 522, __pyx_L3_error)
        }
      }
      if (unlikely(kw_args > 0)) {
        if (unlikely(__Pyx_ParseOptionalKeywords(__pyx_kwds, __pyx_pyargnames, 0, values, pos_args, "cu_clip_roi") < 0)) __PYX_ERR(0, 522, __pyx_L3_error)
      }
    } else if (PyTuple_GET_SIZE(__pyx_args) != 7) {
      goto __pyx_L5_argtuple_error;
    } else {
      values[0] = PyTuple_GET_ITEM(__pyx_args, 0);
      values[1] = PyTuple_GET_ITEM(__pyx_args, 1);
      values[2] = PyTuple_GET_ITEM(__pyx_args, 2);
      values[3] = PyTuple_GET_ITEM(__pyx_args, 3);
      values[4] = PyTuple_GET_ITEM(__pyx_args, 4);
      values[5] = PyTuple_GET_ITEM(__pyx_args, 5);
      values[6] = PyTuple_GET_ITEM(__pyx_args, 6);
    }
    __pyx_v_roi = values[0];
    __pyx_v_start = values[1];
    __pyx_v_end = values[2];
    __pyx_v_step = values[3];
    __pyx_v_min_v = values[4];
    __pyx_v_max_v = values[5];
    __pyx_v_ary = values[6];
  }
  goto __pyx_L4_argument_unpacking_done;
  __pyx_L5_argtuple_error:;
  __Pyx_RaiseArgtupleInvalid("cu_clip_roi", 1, 7, 7, PyTuple_GET_SIZE(__pyx_args)); __PYX_ERR(0, 522, __pyx_L3_error)
  __pyx_L3_error:;
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_clip_roi", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __Pyx_RefNannyFinishContext();
  return NULL;
  __pyx_L4_argument_unpacking_done:;
  __pyx_r = __pyx_pf_5renom_4cuda_13thrust_double_102cu_clip_roi(__pyx_self, __pyx_v_roi, __pyx_v_start, __pyx_v_end, __pyx_v_step, __pyx_v_min_v, __pyx_v_max_v, __pyx_v_ary);

  /* function exit code */
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyObject *__pyx_pf_5renom_4cuda_13thrust_double_102cu_clip_roi(CYTHON_UNUSED PyObject *__pyx_self, PyObject *__pyx_v_roi, PyObject *__pyx_v_start, PyObject *__pyx_v_end, PyObject *__pyx_v_step, PyObject *__pyx_v_min_v, PyObject *__pyx_v_max_v, PyObject *__pyx_v_ary) {
  PyObject *__pyx_v_N = NULL;
  PyObject *__pyx_v_M = NULL;
  VALUE_TYPE *__pyx_v_roi_ptr;
  VALUE_TYPE *__pyx_v_ary_ptr;
  PyObject *__pyx_r = NULL;
  __Pyx_RefNannyDeclarations
  PyObject *__pyx_t_1 = NULL;
  PyObject *__pyx_t_2 = NULL;
  PyObject *__pyx_t_3 = NULL;
  PyObject *__pyx_t_4 = NULL;
  PyObject *(*__pyx_t_5)(PyObject *);
  uintptr_t __pyx_t_6;
  int __pyx_t_7;
  int __pyx_t_8;
  int __pyx_t_9;
  int __pyx_t_10;
  int __pyx_t_11;
  int __pyx_t_12;
  int __pyx_t_13;
  __Pyx_RefNannySetupContext("cu_clip_roi", 0);

  /* "renom/cuda/thrust_funcs.pxi":523
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):
 *     N, M = roi.shape             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_roi, __pyx_n_s_shape); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 523, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if ((likely(PyTuple_CheckExact(__pyx_t_1))) || (PyList_CheckExact(__pyx_t_1))) {
    PyObject* sequence = __pyx_t_1;
    #if !CYTHON_COMPILING_IN_PYPY
    Py_ssize_t size = Py_SIZE(sequence);
    #else
    Py_ssize_t size = PySequence_Size(sequence);
    #endif
    if (unlikely(size != 2)) {
      if (size > 2) __Pyx_RaiseTooManyValuesError(2);
      else if (size >= 0) __Pyx_RaiseNeedMoreValuesError(size);
      __PYX_ERR(0, 523, __pyx_L1_error)
    }
    #if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    if (likely(PyTuple_CheckExact(sequence))) {
      __pyx_t_2 = PyTuple_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyTuple_GET_ITEM(sequence, 1); 
    } else {
      __pyx_t_2 = PyList_GET_ITEM(sequence, 0); 
      __pyx_t_3 = PyList_GET_ITEM(sequence, 1); 
    }
    __Pyx_INCREF(__pyx_t_2);
    __Pyx_INCREF(__pyx_t_3);
    #else
    __pyx_t_2 = PySequence_ITEM(sequence, 0); if (unlikely(!__pyx_t_2)) __PYX_ERR(0, 523, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_2);
    __pyx_t_3 = PySequence_ITEM(sequence, 1); if (unlikely(!__pyx_t_3)) __PYX_ERR(0, 523, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_3);
    #endif
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  } else {
    Py_ssize_t index = -1;
    __pyx_t_4 = PyObject_GetIter(__pyx_t_1); if (unlikely(!__pyx_t_4)) __PYX_ERR(0, 523, __pyx_L1_error)
    __Pyx_GOTREF(__pyx_t_4);
    __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
    __pyx_t_5 = Py_TYPE(__pyx_t_4)->tp_iternext;
    index = 0; __pyx_t_2 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_2)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_2);
    index = 1; __pyx_t_3 = __pyx_t_5(__pyx_t_4); if (unlikely(!__pyx_t_3)) goto __pyx_L3_unpacking_failed;
    __Pyx_GOTREF(__pyx_t_3);
    if (__Pyx_IternextUnpackEndCheck(__pyx_t_5(__pyx_t_4), 2) < 0) __PYX_ERR(0, 523, __pyx_L1_error)
    __pyx_t_5 = NULL;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    goto __pyx_L4_unpacking_done;
    __pyx_L3_unpacking_failed:;
    __Pyx_DECREF(__pyx_t_4); __pyx_t_4 = 0;
    __pyx_t_5 = NULL;
    if (__Pyx_IterFinish() == 0) __Pyx_RaiseNeedMoreValuesError(index);
    __PYX_ERR(0, 523, __pyx_L1_error)
    __pyx_L4_unpacking_done:;
  }
  __pyx_v_N = __pyx_t_2;
  __pyx_t_2 = 0;
  __pyx_v_M = __pyx_t_3;
  __pyx_t_3 = 0;

  /* "renom/cuda/thrust_funcs.pxi":524
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_roi, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 524, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 524, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_roi_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":525
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr             # <<<<<<<<<<<<<<
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)
 */
  __pyx_t_1 = __Pyx_PyObject_GetAttrStr(__pyx_v_ary, __pyx_n_s_ptr); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  __pyx_t_6 = __Pyx_PyInt_As_size_t(__pyx_t_1); if (unlikely((__pyx_t_6 == ((uintptr_t)-1)) && PyErr_Occurred())) __PYX_ERR(0, 525, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;
  __pyx_v_ary_ptr = ((VALUE_TYPE *)((uintptr_t)__pyx_t_6));

  /* "renom/cuda/thrust_funcs.pxi":526
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *><uintptr_t> ary._ptr
 *     thrust_clip_roi(N, M, roi_ptr, start, end, step, min_v, max_v, ary_ptr)             # <<<<<<<<<<<<<<
 */
  __pyx_t_7 = __Pyx_PyInt_As_int(__pyx_v_N); if (unlikely((__pyx_t_7 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_8 = __Pyx_PyInt_As_int(__pyx_v_M); if (unlikely((__pyx_t_8 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_9 = __Pyx_PyInt_As_int(__pyx_v_start); if (unlikely((__pyx_t_9 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_10 = __Pyx_PyInt_As_int(__pyx_v_end); if (unlikely((__pyx_t_10 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_11 = __Pyx_PyInt_As_int(__pyx_v_step); if (unlikely((__pyx_t_11 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_12 = __Pyx_PyInt_As_int(__pyx_v_min_v); if (unlikely((__pyx_t_12 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  __pyx_t_13 = __Pyx_PyInt_As_int(__pyx_v_max_v); if (unlikely((__pyx_t_13 == (int)-1) && PyErr_Occurred())) __PYX_ERR(0, 526, __pyx_L1_error)
  renom::thrust_clip_roi(__pyx_t_7, __pyx_t_8, __pyx_v_roi_ptr, __pyx_t_9, __pyx_t_10, __pyx_t_11, __pyx_t_12, __pyx_t_13, __pyx_v_ary_ptr);

  /* "renom/cuda/thrust_funcs.pxi":522
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 */

  /* function exit code */
  __pyx_r = Py_None; __Pyx_INCREF(Py_None);
  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  __Pyx_XDECREF(__pyx_t_2);
  __Pyx_XDECREF(__pyx_t_3);
  __Pyx_XDECREF(__pyx_t_4);
  __Pyx_AddTraceback("renom.cuda.thrust_double.cu_clip_roi", __pyx_clineno, __pyx_lineno, __pyx_filename);
  __pyx_r = NULL;
  __pyx_L0:;
  __Pyx_XDECREF(__pyx_v_N);
  __Pyx_XDECREF(__pyx_v_M);
  __Pyx_XGIVEREF(__pyx_r);
  __Pyx_RefNannyFinishContext();
  return __pyx_r;
}

static PyMethodDef __pyx_methods[] = {
  {0, 0, 0, 0}
};

#if PY_MAJOR_VERSION >= 3
static struct PyModuleDef __pyx_moduledef = {
  #if PY_VERSION_HEX < 0x03020000
    { PyObject_HEAD_INIT(NULL) NULL, 0, NULL },
  #else
    PyModuleDef_HEAD_INIT,
  #endif
    "thrust_double",
    0, /* m_doc */
    -1, /* m_size */
    __pyx_methods /* m_methods */,
    NULL, /* m_reload */
    NULL, /* m_traverse */
    NULL, /* m_clear */
    NULL /* m_free */
};
#endif

static __Pyx_StringTabEntry __pyx_string_tab[] = {
  {&__pyx_n_s_A, __pyx_k_A, sizeof(__pyx_k_A), 0, 0, 1, 1},
  {&__pyx_n_s_GPUValue, __pyx_k_GPUValue, sizeof(__pyx_k_GPUValue), 0, 0, 1, 1},
  {&__pyx_kp_s_Insufficient_destination_buffer, __pyx_k_Insufficient_destination_buffer, sizeof(__pyx_k_Insufficient_destination_buffer), 0, 0, 1, 0},
  {&__pyx_n_s_K, __pyx_k_K, sizeof(__pyx_k_K), 0, 0, 1, 1},
  {&__pyx_n_s_M, __pyx_k_M, sizeof(__pyx_k_M), 0, 0, 1, 1},
  {&__pyx_n_s_N, __pyx_k_N, sizeof(__pyx_k_N), 0, 0, 1, 1},
  {&__pyx_n_s_ValueError, __pyx_k_ValueError, sizeof(__pyx_k_ValueError), 0, 0, 1, 1},
  {&__pyx_kp_s_all_the_input_array_dimensions_e, __pyx_k_all_the_input_array_dimensions_e, sizeof(__pyx_k_all_the_input_array_dimensions_e), 0, 0, 1, 0},
  {&__pyx_n_s_anchors, __pyx_k_anchors, sizeof(__pyx_k_anchors), 0, 0, 1, 1},
  {&__pyx_n_s_anchors_ptr, __pyx_k_anchors_ptr, sizeof(__pyx_k_anchors_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_arg, __pyx_k_arg, sizeof(__pyx_k_arg), 0, 0, 1, 1},
  {&__pyx_n_s_arg_ptr, __pyx_k_arg_ptr, sizeof(__pyx_k_arg_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_argmax, __pyx_k_argmax, sizeof(__pyx_k_argmax), 0, 0, 1, 1},
  {&__pyx_n_s_ary, __pyx_k_ary, sizeof(__pyx_k_ary), 0, 0, 1, 1},
  {&__pyx_n_s_ary1, __pyx_k_ary1, sizeof(__pyx_k_ary1), 0, 0, 1, 1},
  {&__pyx_n_s_ary2, __pyx_k_ary2, sizeof(__pyx_k_ary2), 0, 0, 1, 1},
  {&__pyx_n_s_ary_ptr, __pyx_k_ary_ptr, sizeof(__pyx_k_ary_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_augmax_data, __pyx_k_augmax_data, sizeof(__pyx_k_augmax_data), 0, 0, 1, 1},
  {&__pyx_n_s_axis, __pyx_k_axis, sizeof(__pyx_k_axis), 0, 0, 1, 1},
  {&__pyx_n_s_base_size, __pyx_k_base_size, sizeof(__pyx_k_base_size), 0, 0, 1, 1},
  {&__pyx_n_s_bbox, __pyx_k_bbox, sizeof(__pyx_k_bbox), 0, 0, 1, 1},
  {&__pyx_n_s_bbox_ptr, __pyx_k_bbox_ptr, sizeof(__pyx_k_bbox_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_bias, __pyx_k_bias, sizeof(__pyx_k_bias), 0, 0, 1, 1},
  {&__pyx_n_s_ch, __pyx_k_ch, sizeof(__pyx_k_ch), 0, 0, 1, 1},
  {&__pyx_n_s_channels, __pyx_k_channels, sizeof(__pyx_k_channels), 0, 0, 1, 1},
  {&__pyx_n_s_check_heap_device, __pyx_k_check_heap_device, sizeof(__pyx_k_check_heap_device), 0, 0, 1, 1},
  {&__pyx_n_s_cline_in_traceback, __pyx_k_cline_in_traceback, sizeof(__pyx_k_cline_in_traceback), 0, 0, 1, 1},
  {&__pyx_n_s_core, __pyx_k_core, sizeof(__pyx_k_core), 0, 0, 1, 1},
  {&__pyx_n_s_ctr, __pyx_k_ctr, sizeof(__pyx_k_ctr), 0, 0, 1, 1},
  {&__pyx_n_s_ctr_ptr, __pyx_k_ctr_ptr, sizeof(__pyx_k_ctr_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_cu_add_bias, __pyx_k_cu_add_bias, sizeof(__pyx_k_cu_add_bias), 0, 0, 1, 1},
  {&__pyx_n_s_cu_assign_pred_box, __pyx_k_cu_assign_pred_box, sizeof(__pyx_k_cu_assign_pred_box), 0, 0, 1, 1},
  {&__pyx_n_s_cu_clip_roi, __pyx_k_cu_clip_roi, sizeof(__pyx_k_cu_clip_roi), 0, 0, 1, 1},
  {&__pyx_n_s_cu_generate_anchors, __pyx_k_cu_generate_anchors, sizeof(__pyx_k_cu_generate_anchors), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_every_nth_ary, __pyx_k_cu_get_every_nth_ary, sizeof(__pyx_k_cu_get_every_nth_ary), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_fg_ary_backward, __pyx_k_cu_get_fg_ary_backward, sizeof(__pyx_k_cu_get_fg_ary_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_fg_ary_forward, __pyx_k_cu_get_fg_ary_forward, sizeof(__pyx_k_cu_get_fg_ary_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_ary_backward, __pyx_k_cu_get_ith_ary_backward, sizeof(__pyx_k_cu_get_ith_ary_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_ary_forward, __pyx_k_cu_get_ith_ary_forward, sizeof(__pyx_k_cu_get_ith_ary_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cu_get_ith_bbox, __pyx_k_cu_get_ith_bbox, sizeof(__pyx_k_cu_get_ith_bbox), 0, 0, 1, 1},
  {&__pyx_n_s_cu_pred_ctr, __pyx_k_cu_pred_ctr, sizeof(__pyx_k_cu_pred_ctr), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_max, __pyx_k_cu_reduce_max, sizeof(__pyx_k_cu_reduce_max), 0, 0, 1, 1},
  {&__pyx_n_s_cu_reduce_min, __pyx_k_cu_reduce_min, sizeof(__pyx_k_cu_reduce_min), 0, 0, 1, 1},
  {&__pyx_n_s_cuabs_backward, __pyx_k_cuabs_backward, sizeof(__pyx_k_cuabs_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuabs_forward, __pyx_k_cuabs_forward, sizeof(__pyx_k_cuabs_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cuadd, __pyx_k_cuadd, sizeof(__pyx_k_cuadd), 0, 0, 1, 1},
  {&__pyx_n_s_cubinarize, __pyx_k_cubinarize, sizeof(__pyx_k_cubinarize), 0, 0, 1, 1},
  {&__pyx_n_s_cubroadcast, __pyx_k_cubroadcast, sizeof(__pyx_k_cubroadcast), 0, 0, 1, 1},
  {&__pyx_n_s_cuconcat, __pyx_k_cuconcat, sizeof(__pyx_k_cuconcat), 0, 0, 1, 1},
  {&__pyx_n_s_cucross_entropy, __pyx_k_cucross_entropy, sizeof(__pyx_k_cucross_entropy), 0, 0, 1, 1},
  {&__pyx_n_s_cuda_base, __pyx_k_cuda_base, sizeof(__pyx_k_cuda_base), 0, 0, 1, 1},
  {&__pyx_n_s_cudiv, __pyx_k_cudiv, sizeof(__pyx_k_cudiv), 0, 0, 1, 1},
  {&__pyx_n_s_cuembedding_backward, __pyx_k_cuembedding_backward, sizeof(__pyx_k_cuembedding_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cuembedding_forward, __pyx_k_cuembedding_forward, sizeof(__pyx_k_cuembedding_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cueru_backward, __pyx_k_cueru_backward, sizeof(__pyx_k_cueru_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cueru_forward, __pyx_k_cueru_forward, sizeof(__pyx_k_cueru_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cuexp, __pyx_k_cuexp, sizeof(__pyx_k_cuexp), 0, 0, 1, 1},
  {&__pyx_n_s_cufill, __pyx_k_cufill, sizeof(__pyx_k_cufill), 0, 0, 1, 1},
  {&__pyx_n_s_culeaky_leru_backward, __pyx_k_culeaky_leru_backward, sizeof(__pyx_k_culeaky_leru_backward), 0, 0, 1, 1},
  {&__pyx_n_s_culeaky_leru_forward, __pyx_k_culeaky_leru_forward, sizeof(__pyx_k_culeaky_leru_forward), 0, 0, 1, 1},
  {&__pyx_n_s_culoge, __pyx_k_culoge, sizeof(__pyx_k_culoge), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_backward, __pyx_k_culstm_backward, sizeof(__pyx_k_culstm_backward), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_forward, __pyx_k_culstm_forward, sizeof(__pyx_k_culstm_forward), 0, 0, 1, 1},
  {&__pyx_n_s_culstm_forward_activate, __pyx_k_culstm_forward_activate, sizeof(__pyx_k_culstm_forward_activate), 0, 0, 1, 1},
  {&__pyx_n_s_cumax, __pyx_k_cumax, sizeof(__pyx_k_cumax), 0, 0, 1, 1},
  {&__pyx_n_s_cumin, __pyx_k_cumin, sizeof(__pyx_k_cumin), 0, 0, 1, 1},
  {&__pyx_n_s_cumul, __pyx_k_cumul, sizeof(__pyx_k_cumul), 0, 0, 1, 1},
  {&__pyx_n_s_cunegate, __pyx_k_cunegate, sizeof(__pyx_k_cunegate), 0, 0, 1, 1},
  {&__pyx_n_s_cupeepholelstm_backward, __pyx_k_cupeepholelstm_backward, sizeof(__pyx_k_cupeepholelstm_backward), 0, 0, 1, 1},
  {&__pyx_n_s_cupeepholelstm_forward, __pyx_k_cupeepholelstm_forward, sizeof(__pyx_k_cupeepholelstm_forward), 0, 0, 1, 1},
  {&__pyx_n_s_cupow, __pyx_k_cupow, sizeof(__pyx_k_cupow), 0, 0, 1, 1},
  {&__pyx_n_s_curdiv, __pyx_k_curdiv, sizeof(__pyx_k_curdiv), 0, 0, 1, 1},
  {&__pyx_n_s_curelu_backard, __pyx_k_curelu_backard, sizeof(__pyx_k_curelu_backard), 0, 0, 1, 1},
  {&__pyx_n_s_curelu_foward, __pyx_k_curelu_foward, sizeof(__pyx_k_curelu_foward), 0, 0, 1, 1},
  {&__pyx_n_s_curoi_pool2d_backward, __pyx_k_curoi_pool2d_backward, sizeof(__pyx_k_curoi_pool2d_backward), 0, 0, 1, 1},
  {&__pyx_n_s_curoi_pool2d_forward, __pyx_k_curoi_pool2d_forward, sizeof(__pyx_k_curoi_pool2d_forward), 0, 0, 1, 1},
  {&__pyx_n_s_curpow, __pyx_k_curpow, sizeof(__pyx_k_curpow), 0, 0, 1, 1},
  {&__pyx_n_s_cusigmoid, __pyx_k_cusigmoid, sizeof(__pyx_k_cusigmoid), 0, 0, 1, 1},
  {&__pyx_n_s_cusign, __pyx_k_cusign, sizeof(__pyx_k_cusign), 0, 0, 1, 1},
  {&__pyx_n_s_cusqrt, __pyx_k_cusqrt, sizeof(__pyx_k_cusqrt), 0, 0, 1, 1},
  {&__pyx_n_s_cusub, __pyx_k_cusub, sizeof(__pyx_k_cusub), 0, 0, 1, 1},
  {&__pyx_n_s_cusum, __pyx_k_cusum, sizeof(__pyx_k_cusum), 0, 0, 1, 1},
  {&__pyx_n_s_cutanh, __pyx_k_cutanh, sizeof(__pyx_k_cutanh), 0, 0, 1, 1},
  {&__pyx_n_s_dot, __pyx_k_dot, sizeof(__pyx_k_dot), 0, 0, 1, 1},
  {&__pyx_n_s_dou, __pyx_k_dou, sizeof(__pyx_k_dou), 0, 0, 1, 1},
  {&__pyx_n_s_dou_n, __pyx_k_dou_n, sizeof(__pyx_k_dou_n), 0, 0, 1, 1},
  {&__pyx_n_s_dr, __pyx_k_dr, sizeof(__pyx_k_dr), 0, 0, 1, 1},
  {&__pyx_n_s_drt, __pyx_k_drt, sizeof(__pyx_k_drt), 0, 0, 1, 1},
  {&__pyx_n_s_dtype, __pyx_k_dtype, sizeof(__pyx_k_dtype), 0, 0, 1, 1},
  {&__pyx_n_s_du, __pyx_k_du, sizeof(__pyx_k_du), 0, 0, 1, 1},
  {&__pyx_n_s_dwc, __pyx_k_dwc, sizeof(__pyx_k_dwc), 0, 0, 1, 1},
  {&__pyx_n_s_dx, __pyx_k_dx, sizeof(__pyx_k_dx), 0, 0, 1, 1},
  {&__pyx_n_s_dx_ptr, __pyx_k_dx_ptr, sizeof(__pyx_k_dx_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_dy, __pyx_k_dy, sizeof(__pyx_k_dy), 0, 0, 1, 1},
  {&__pyx_n_s_dy_ptr, __pyx_k_dy_ptr, sizeof(__pyx_k_dy_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_e, __pyx_k_e, sizeof(__pyx_k_e), 0, 0, 1, 1},
  {&__pyx_n_s_end, __pyx_k_end, sizeof(__pyx_k_end), 0, 0, 1, 1},
  {&__pyx_n_s_feat_stride, __pyx_k_feat_stride, sizeof(__pyx_k_feat_stride), 0, 0, 1, 1},
  {&__pyx_n_s_fg_ary, __pyx_k_fg_ary, sizeof(__pyx_k_fg_ary), 0, 0, 1, 1},
  {&__pyx_n_s_first, __pyx_k_first, sizeof(__pyx_k_first), 0, 0, 1, 1},
  {&__pyx_n_s_functools, __pyx_k_functools, sizeof(__pyx_k_functools), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_dx, __pyx_k_gpu_dx, sizeof(__pyx_k_gpu_dx), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_dy, __pyx_k_gpu_dy, sizeof(__pyx_k_gpu_dy), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_index, __pyx_k_gpu_index, sizeof(__pyx_k_gpu_index), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_ptr1, __pyx_k_gpu_ptr1, sizeof(__pyx_k_gpu_ptr1), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_ptr2, __pyx_k_gpu_ptr2, sizeof(__pyx_k_gpu_ptr2), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value, __pyx_k_gpu_value, sizeof(__pyx_k_gpu_value), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value1, __pyx_k_gpu_value1, sizeof(__pyx_k_gpu_value1), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value2, __pyx_k_gpu_value2, sizeof(__pyx_k_gpu_value2), 0, 0, 1, 1},
  {&__pyx_n_s_gpu_value3, __pyx_k_gpu_value3, sizeof(__pyx_k_gpu_value3), 0, 0, 1, 1},
  {&__pyx_n_s_h, __pyx_k_h, sizeof(__pyx_k_h), 0, 0, 1, 1},
  {&__pyx_n_s_h_ptr, __pyx_k_h_ptr, sizeof(__pyx_k_h_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_height, __pyx_k_height, sizeof(__pyx_k_height), 0, 0, 1, 1},
  {&__pyx_n_s_i, __pyx_k_i, sizeof(__pyx_k_i), 0, 0, 1, 1},
  {&__pyx_n_s_import, __pyx_k_import, sizeof(__pyx_k_import), 0, 0, 1, 1},
  {&__pyx_n_s_index_ptr, __pyx_k_index_ptr, sizeof(__pyx_k_index_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_input, __pyx_k_input, sizeof(__pyx_k_input), 0, 0, 1, 1},
  {&__pyx_n_s_ith_ary, __pyx_k_ith_ary, sizeof(__pyx_k_ith_ary), 0, 0, 1, 1},
  {&__pyx_n_s_j, __pyx_k_j, sizeof(__pyx_k_j), 0, 0, 1, 1},
  {&__pyx_n_s_last, __pyx_k_last, sizeof(__pyx_k_last), 0, 0, 1, 1},
  {&__pyx_n_s_length, __pyx_k_length, sizeof(__pyx_k_length), 0, 0, 1, 1},
  {&__pyx_n_s_length_ptr, __pyx_k_length_ptr, sizeof(__pyx_k_length_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_main, __pyx_k_main, sizeof(__pyx_k_main), 0, 0, 1, 1},
  {&__pyx_n_s_max_v, __pyx_k_max_v, sizeof(__pyx_k_max_v), 0, 0, 1, 1},
  {&__pyx_n_s_min_v, __pyx_k_min_v, sizeof(__pyx_k_min_v), 0, 0, 1, 1},
  {&__pyx_n_s_mul, __pyx_k_mul, sizeof(__pyx_k_mul), 0, 0, 1, 1},
  {&__pyx_n_s_n, __pyx_k_n, sizeof(__pyx_k_n), 0, 0, 1, 1},
  {&__pyx_n_s_nbytes, __pyx_k_nbytes, sizeof(__pyx_k_nbytes), 0, 0, 1, 1},
  {&__pyx_n_s_np, __pyx_k_np, sizeof(__pyx_k_np), 0, 0, 1, 1},
  {&__pyx_n_s_numpy, __pyx_k_numpy, sizeof(__pyx_k_numpy), 0, 0, 1, 1},
  {&__pyx_n_s_operator, __pyx_k_operator, sizeof(__pyx_k_operator), 0, 0, 1, 1},
  {&__pyx_n_s_outh, __pyx_k_outh, sizeof(__pyx_k_outh), 0, 0, 1, 1},
  {&__pyx_n_s_output, __pyx_k_output, sizeof(__pyx_k_output), 0, 0, 1, 1},
  {&__pyx_n_s_outw, __pyx_k_outw, sizeof(__pyx_k_outw), 0, 0, 1, 1},
  {&__pyx_n_s_pgf, __pyx_k_pgf, sizeof(__pyx_k_pgf), 0, 0, 1, 1},
  {&__pyx_n_s_prefg, __pyx_k_prefg, sizeof(__pyx_k_prefg), 0, 0, 1, 1},
  {&__pyx_n_s_prestate, __pyx_k_prestate, sizeof(__pyx_k_prestate), 0, 0, 1, 1},
  {&__pyx_n_s_product, __pyx_k_product, sizeof(__pyx_k_product), 0, 0, 1, 1},
  {&__pyx_n_s_ps, __pyx_k_ps, sizeof(__pyx_k_ps), 0, 0, 1, 1},
  {&__pyx_n_s_ptr, __pyx_k_ptr, sizeof(__pyx_k_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr1, __pyx_k_ptr1, sizeof(__pyx_k_ptr1), 0, 0, 1, 1},
  {&__pyx_n_s_ptr2, __pyx_k_ptr2, sizeof(__pyx_k_ptr2), 0, 0, 1, 1},
  {&__pyx_n_s_ptr3, __pyx_k_ptr3, sizeof(__pyx_k_ptr3), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_2, __pyx_k_ptr_2, sizeof(__pyx_k_ptr_2), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_argmax, __pyx_k_ptr_argmax, sizeof(__pyx_k_ptr_argmax), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_augmax_data, __pyx_k_ptr_augmax_data, sizeof(__pyx_k_ptr_augmax_data), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dot, __pyx_k_ptr_dot, sizeof(__pyx_k_ptr_dot), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dou, __pyx_k_ptr_dou, sizeof(__pyx_k_ptr_dou), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dou_n, __pyx_k_ptr_dou_n, sizeof(__pyx_k_ptr_dou_n), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dr, __pyx_k_ptr_dr, sizeof(__pyx_k_ptr_dr), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_drt, __pyx_k_ptr_drt, sizeof(__pyx_k_ptr_drt), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_du, __pyx_k_ptr_du, sizeof(__pyx_k_ptr_du), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dwc, __pyx_k_ptr_dwc, sizeof(__pyx_k_ptr_dwc), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dx, __pyx_k_ptr_dx, sizeof(__pyx_k_ptr_dx), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_dy, __pyx_k_ptr_dy, sizeof(__pyx_k_ptr_dy), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_e, __pyx_k_ptr_e, sizeof(__pyx_k_ptr_e), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_pfg, __pyx_k_ptr_pfg, sizeof(__pyx_k_ptr_pfg), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_pgf, __pyx_k_ptr_pgf, sizeof(__pyx_k_ptr_pgf), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_ps, __pyx_k_ptr_ps, sizeof(__pyx_k_ptr_ps), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_rois, __pyx_k_ptr_rois, sizeof(__pyx_k_ptr_rois), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_s, __pyx_k_ptr_s, sizeof(__pyx_k_ptr_s), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_u, __pyx_k_ptr_u, sizeof(__pyx_k_ptr_u), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_wc, __pyx_k_ptr_wc, sizeof(__pyx_k_ptr_wc), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_x, __pyx_k_ptr_x, sizeof(__pyx_k_ptr_x), 0, 0, 1, 1},
  {&__pyx_n_s_ptr_z, __pyx_k_ptr_z, sizeof(__pyx_k_ptr_z), 0, 0, 1, 1},
  {&__pyx_n_s_ratio_size, __pyx_k_ratio_size, sizeof(__pyx_k_ratio_size), 0, 0, 1, 1},
  {&__pyx_n_s_ratios, __pyx_k_ratios, sizeof(__pyx_k_ratios), 0, 0, 1, 1},
  {&__pyx_n_s_ratios_ptr, __pyx_k_ratios_ptr, sizeof(__pyx_k_ratios_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_rec_size, __pyx_k_rec_size, sizeof(__pyx_k_rec_size), 0, 0, 1, 1},
  {&__pyx_n_s_reduce, __pyx_k_reduce, sizeof(__pyx_k_reduce), 0, 0, 1, 1},
  {&__pyx_n_s_renom, __pyx_k_renom, sizeof(__pyx_k_renom), 0, 0, 1, 1},
  {&__pyx_n_s_renom_core, __pyx_k_renom_core, sizeof(__pyx_k_renom_core), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda, __pyx_k_renom_cuda, sizeof(__pyx_k_renom_cuda), 0, 0, 1, 1},
  {&__pyx_n_s_renom_cuda_thrust_double, __pyx_k_renom_cuda_thrust_double, sizeof(__pyx_k_renom_cuda_thrust_double), 0, 0, 1, 1},
  {&__pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_k_renom_cuda_thrust_funcs_pxi, sizeof(__pyx_k_renom_cuda_thrust_funcs_pxi), 0, 0, 1, 0},
  {&__pyx_n_s_result, __pyx_k_result, sizeof(__pyx_k_result), 0, 0, 1, 1},
  {&__pyx_n_s_roi, __pyx_k_roi, sizeof(__pyx_k_roi), 0, 0, 1, 1},
  {&__pyx_n_s_roi_ptr, __pyx_k_roi_ptr, sizeof(__pyx_k_roi_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_rois, __pyx_k_rois, sizeof(__pyx_k_rois), 0, 0, 1, 1},
  {&__pyx_n_s_s, __pyx_k_s, sizeof(__pyx_k_s), 0, 0, 1, 1},
  {&__pyx_n_s_s1, __pyx_k_s1, sizeof(__pyx_k_s1), 0, 0, 1, 1},
  {&__pyx_n_s_s2, __pyx_k_s2, sizeof(__pyx_k_s2), 0, 0, 1, 1},
  {&__pyx_n_s_scale_size, __pyx_k_scale_size, sizeof(__pyx_k_scale_size), 0, 0, 1, 1},
  {&__pyx_n_s_scales, __pyx_k_scales, sizeof(__pyx_k_scales), 0, 0, 1, 1},
  {&__pyx_n_s_scales_ptr, __pyx_k_scales_ptr, sizeof(__pyx_k_scales_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_shape, __pyx_k_shape, sizeof(__pyx_k_shape), 0, 0, 1, 1},
  {&__pyx_n_s_shifts, __pyx_k_shifts, sizeof(__pyx_k_shifts), 0, 0, 1, 1},
  {&__pyx_n_s_shifts_ptr, __pyx_k_shifts_ptr, sizeof(__pyx_k_shifts_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_size, __pyx_k_size, sizeof(__pyx_k_size), 0, 0, 1, 1},
  {&__pyx_n_s_size1, __pyx_k_size1, sizeof(__pyx_k_size1), 0, 0, 1, 1},
  {&__pyx_n_s_size2, __pyx_k_size2, sizeof(__pyx_k_size2), 0, 0, 1, 1},
  {&__pyx_n_s_size_1, __pyx_k_size_1, sizeof(__pyx_k_size_1), 0, 0, 1, 1},
  {&__pyx_n_s_size_2, __pyx_k_size_2, sizeof(__pyx_k_size_2), 0, 0, 1, 1},
  {&__pyx_n_s_spatial_scale, __pyx_k_spatial_scale, sizeof(__pyx_k_spatial_scale), 0, 0, 1, 1},
  {&__pyx_n_s_start, __pyx_k_start, sizeof(__pyx_k_start), 0, 0, 1, 1},
  {&__pyx_n_s_state, __pyx_k_state, sizeof(__pyx_k_state), 0, 0, 1, 1},
  {&__pyx_n_s_step, __pyx_k_step, sizeof(__pyx_k_step), 0, 0, 1, 1},
  {&__pyx_n_s_temp, __pyx_k_temp, sizeof(__pyx_k_temp), 0, 0, 1, 1},
  {&__pyx_n_s_temporal, __pyx_k_temporal, sizeof(__pyx_k_temporal), 0, 0, 1, 1},
  {&__pyx_n_s_test, __pyx_k_test, sizeof(__pyx_k_test), 0, 0, 1, 1},
  {&__pyx_n_s_th, __pyx_k_th, sizeof(__pyx_k_th), 0, 0, 1, 1},
  {&__pyx_n_s_threathold, __pyx_k_threathold, sizeof(__pyx_k_threathold), 0, 0, 1, 1},
  {&__pyx_n_s_u, __pyx_k_u, sizeof(__pyx_k_u), 0, 0, 1, 1},
  {&__pyx_n_s_v, __pyx_k_v, sizeof(__pyx_k_v), 0, 0, 1, 1},
  {&__pyx_n_s_value, __pyx_k_value, sizeof(__pyx_k_value), 0, 0, 1, 1},
  {&__pyx_n_s_w, __pyx_k_w, sizeof(__pyx_k_w), 0, 0, 1, 1},
  {&__pyx_n_s_w_ptr, __pyx_k_w_ptr, sizeof(__pyx_k_w_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_wc, __pyx_k_wc, sizeof(__pyx_k_wc), 0, 0, 1, 1},
  {&__pyx_n_s_weight, __pyx_k_weight, sizeof(__pyx_k_weight), 0, 0, 1, 1},
  {&__pyx_n_s_weight_ptr, __pyx_k_weight_ptr, sizeof(__pyx_k_weight_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_wh, __pyx_k_wh, sizeof(__pyx_k_wh), 0, 0, 1, 1},
  {&__pyx_n_s_width, __pyx_k_width, sizeof(__pyx_k_width), 0, 0, 1, 1},
  {&__pyx_n_s_x, __pyx_k_x, sizeof(__pyx_k_x), 0, 0, 1, 1},
  {&__pyx_n_s_x_ptr, __pyx_k_x_ptr, sizeof(__pyx_k_x_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_y, __pyx_k_y, sizeof(__pyx_k_y), 0, 0, 1, 1},
  {&__pyx_n_s_y_ptr, __pyx_k_y_ptr, sizeof(__pyx_k_y_ptr), 0, 0, 1, 1},
  {&__pyx_n_s_z, __pyx_k_z, sizeof(__pyx_k_z), 0, 0, 1, 1},
  {&__pyx_n_s_zero, __pyx_k_zero, sizeof(__pyx_k_zero), 0, 0, 1, 1},
  {&__pyx_kp_s_zero_dimensional_arrays_cannot_b, __pyx_k_zero_dimensional_arrays_cannot_b, sizeof(__pyx_k_zero_dimensional_arrays_cannot_b), 0, 0, 1, 0},
  {0, 0, 0, 0, 0, 0, 0}
};
static int __Pyx_InitCachedBuiltins(void) {
  __pyx_builtin_ValueError = __Pyx_GetBuiltinName(__pyx_n_s_ValueError); if (!__pyx_builtin_ValueError) __PYX_ERR(0, 378, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

static int __Pyx_InitCachedConstants(void) {
  __Pyx_RefNannyDeclarations
  __Pyx_RefNannySetupContext("__Pyx_InitCachedConstants", 0);

  /* "renom/cuda/thrust_funcs.pxi":378
 *     cdef size_t size = gpu_value1.nbytes + gpu_value2.nbytes
 *     if gpu_value3.nbytes < size:
 *         raise ValueError("Insufficient destination buffer size")             # <<<<<<<<<<<<<<
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):
 */
  __pyx_tuple_ = PyTuple_Pack(1, __pyx_kp_s_Insufficient_destination_buffer); if (unlikely(!__pyx_tuple_)) __PYX_ERR(0, 378, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple_);
  __Pyx_GIVEREF(__pyx_tuple_);

  /* "renom/cuda/thrust_funcs.pxi":381
 * 
 *     if (not gpu_value1.shape) or (not gpu_value2.shape):
 *         raise ValueError("zero-dimensional arrays cannot be concatenated")             # <<<<<<<<<<<<<<
 * 
 *     s1 = gpu_value1.shape[:axis] + gpu_value1.shape[axis + 1:]
 */
  __pyx_tuple__2 = PyTuple_Pack(1, __pyx_kp_s_zero_dimensional_arrays_cannot_b); if (unlikely(!__pyx_tuple__2)) __PYX_ERR(0, 381, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__2);
  __Pyx_GIVEREF(__pyx_tuple__2);

  /* "renom/cuda/thrust_funcs.pxi":387
 * 
 *     if s1 != s2:
 *         raise ValueError("all the input array dimensions except"             # <<<<<<<<<<<<<<
 *                          " for the concatenation axis must match exactly")
 * 
 */
  __pyx_tuple__3 = PyTuple_Pack(1, __pyx_kp_s_all_the_input_array_dimensions_e); if (unlikely(!__pyx_tuple__3)) __PYX_ERR(0, 387, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__3);
  __Pyx_GIVEREF(__pyx_tuple__3);

  /* "renom/cuda/thrust_funcs.pxi":19
 * 
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */
  __pyx_tuple__4 = PyTuple_Pack(5, __pyx_n_s_input, __pyx_n_s_result, __pyx_n_s_first, __pyx_n_s_last, __pyx_n_s_output); if (unlikely(!__pyx_tuple__4)) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__4);
  __Pyx_GIVEREF(__pyx_tuple__4);
  __pyx_codeobj__5 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__4, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cunegate, 19, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__5)) __PYX_ERR(0, 19, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":28
 * 
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__6 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__6)) __PYX_ERR(0, 28, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__6);
  __Pyx_GIVEREF(__pyx_tuple__6);
  __pyx_codeobj__7 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__6, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curelu_foward, 28, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__7)) __PYX_ERR(0, 28, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":37
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__8 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__8)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__8);
  __Pyx_GIVEREF(__pyx_tuple__8);
  __pyx_codeobj__9 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__8, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curelu_backard, 37, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__9)) __PYX_ERR(0, 37, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":46
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__10 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__10)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__10);
  __Pyx_GIVEREF(__pyx_tuple__10);
  __pyx_codeobj__11 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__10, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culeaky_leru_forward, 46, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__11)) __PYX_ERR(0, 46, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":55
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__12 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__12)) __PYX_ERR(0, 55, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__12);
  __Pyx_GIVEREF(__pyx_tuple__12);
  __pyx_codeobj__13 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__12, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culeaky_leru_backward, 55, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__13)) __PYX_ERR(0, 55, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":64
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__14 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__14)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__14);
  __Pyx_GIVEREF(__pyx_tuple__14);
  __pyx_codeobj__15 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__14, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cueru_forward, 64, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__15)) __PYX_ERR(0, 64, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":73
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__16 = PyTuple_Pack(6, __pyx_n_s_s, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__16)) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__16);
  __Pyx_GIVEREF(__pyx_tuple__16);
  __pyx_codeobj__17 = (PyObject*)__Pyx_PyCode_New(3, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__16, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cueru_backward, 73, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__17)) __PYX_ERR(0, 73, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":82
 * 
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__18 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__18)) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__18);
  __Pyx_GIVEREF(__pyx_tuple__18);
  __pyx_codeobj__19 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__18, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cusigmoid, 82, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__19)) __PYX_ERR(0, 82, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":91
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_tuple__20 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__20)) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__20);
  __Pyx_GIVEREF(__pyx_tuple__20);
  __pyx_codeobj__21 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__20, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cutanh, 91, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__21)) __PYX_ERR(0, 91, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":119
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__22 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__22)) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__22);
  __Pyx_GIVEREF(__pyx_tuple__22);
  __pyx_codeobj__23 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__22, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cumul, 119, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__23)) __PYX_ERR(0, 119, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":124
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__24 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__24)) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__24);
  __Pyx_GIVEREF(__pyx_tuple__24);
  __pyx_codeobj__25 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__24, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuadd, 124, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__25)) __PYX_ERR(0, 124, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":129
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__26 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__26)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__26);
  __Pyx_GIVEREF(__pyx_tuple__26);
  __pyx_codeobj__27 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__26, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cusub, 129, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__27)) __PYX_ERR(0, 129, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":134
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__28 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__28)) __PYX_ERR(0, 134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__28);
  __Pyx_GIVEREF(__pyx_tuple__28);
  __pyx_codeobj__29 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__28, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cudiv, 134, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__29)) __PYX_ERR(0, 134, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":139
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__30 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__30)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__30);
  __Pyx_GIVEREF(__pyx_tuple__30);
  __pyx_codeobj__31 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__30, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curdiv, 139, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__31)) __PYX_ERR(0, 139, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":144
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__32 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__32)) __PYX_ERR(0, 144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__32);
  __Pyx_GIVEREF(__pyx_tuple__32);
  __pyx_codeobj__33 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__32, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cupow, 144, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__33)) __PYX_ERR(0, 144, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":149
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__34 = PyTuple_Pack(3, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3); if (unlikely(!__pyx_tuple__34)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__34);
  __Pyx_GIVEREF(__pyx_tuple__34);
  __pyx_codeobj__35 = (PyObject*)__Pyx_PyCode_New(3, 0, 3, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__34, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curpow, 149, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__35)) __PYX_ERR(0, 149, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":154
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_tuple__36 = PyTuple_Pack(5, __pyx_n_s_value, __pyx_n_s_gpu_value, __pyx_n_s_size, __pyx_n_s_v, __pyx_n_s_ptr_2); if (unlikely(!__pyx_tuple__36)) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__36);
  __Pyx_GIVEREF(__pyx_tuple__36);
  __pyx_codeobj__37 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__36, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cufill, 154, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__37)) __PYX_ERR(0, 154, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":163
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__38 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__38)) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__38);
  __Pyx_GIVEREF(__pyx_tuple__38);
  __pyx_codeobj__39 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__38, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culoge, 163, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__39)) __PYX_ERR(0, 163, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":172
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__40 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__40)) __PYX_ERR(0, 172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__40);
  __Pyx_GIVEREF(__pyx_tuple__40);
  __pyx_codeobj__41 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__40, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuexp, 172, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__41)) __PYX_ERR(0, 172, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":179
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__42 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__42)) __PYX_ERR(0, 179, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__42);
  __Pyx_GIVEREF(__pyx_tuple__42);
  __pyx_codeobj__43 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__42, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cusqrt, 179, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__43)) __PYX_ERR(0, 179, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":187
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__44 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__44)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__44);
  __Pyx_GIVEREF(__pyx_tuple__44);
  __pyx_codeobj__45 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__44, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cusign, 187, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__45)) __PYX_ERR(0, 187, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":194
 *     thrust_sign(ptr1, ptr2, size)
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__46 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_ptr3); if (unlikely(!__pyx_tuple__46)) __PYX_ERR(0, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__46);
  __Pyx_GIVEREF(__pyx_tuple__46);
  __pyx_codeobj__47 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__46, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cucross_entropy, 194, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__47)) __PYX_ERR(0, 194, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":204
 * 
 * 
 * def cubroadcast(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size
 */
  __pyx_tuple__48 = PyTuple_Pack(6, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size_1, __pyx_n_s_size_2, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__48)) __PYX_ERR(0, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__48);
  __Pyx_GIVEREF(__pyx_tuple__48);
  __pyx_codeobj__49 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__48, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cubroadcast, 204, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__49)) __PYX_ERR(0, 204, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":214
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__50 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__50)) __PYX_ERR(0, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__50);
  __Pyx_GIVEREF(__pyx_tuple__50);
  __pyx_codeobj__51 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__50, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuabs_forward, 214, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__51)) __PYX_ERR(0, 214, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":223
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__52 = PyTuple_Pack(5, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__52)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__52);
  __Pyx_GIVEREF(__pyx_tuple__52);
  __pyx_codeobj__53 = (PyObject*)__Pyx_PyCode_New(2, 0, 5, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__52, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuabs_backward, 223, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__53)) __PYX_ERR(0, 223, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":232
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__54 = PyTuple_Pack(7, __pyx_n_s_value, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_v); if (unlikely(!__pyx_tuple__54)) __PYX_ERR(0, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__54);
  __Pyx_GIVEREF(__pyx_tuple__54);
  __pyx_codeobj__55 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__54, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cumin, 232, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__55)) __PYX_ERR(0, 232, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":242
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__56 = PyTuple_Pack(7, __pyx_n_s_value, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_v); if (unlikely(!__pyx_tuple__56)) __PYX_ERR(0, 242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__56);
  __Pyx_GIVEREF(__pyx_tuple__56);
  __pyx_codeobj__57 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__56, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cumax, 242, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__57)) __PYX_ERR(0, 242, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":252
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                         width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */
  __pyx_tuple__58 = PyTuple_Pack(15, __pyx_n_s_rois, __pyx_n_s_x, __pyx_n_s_spatial_scale, __pyx_n_s_channels, __pyx_n_s_height, __pyx_n_s_width, __pyx_n_s_outh, __pyx_n_s_outw, __pyx_n_s_z, __pyx_n_s_augmax_data, __pyx_n_s_N, __pyx_n_s_ptr_x, __pyx_n_s_ptr_rois, __pyx_n_s_ptr_z, __pyx_n_s_ptr_augmax_data); if (unlikely(!__pyx_tuple__58)) __PYX_ERR(0, 252, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__58);
  __Pyx_GIVEREF(__pyx_tuple__58);
  __pyx_codeobj__59 = (PyObject*)__Pyx_PyCode_New(10, 0, 15, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__58, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curoi_pool2d_forward, 252, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__59)) __PYX_ERR(0, 252, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":262
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int N = rois.shape[0]
 * 
 */
  __pyx_tuple__60 = PyTuple_Pack(15, __pyx_n_s_du, __pyx_n_s_argmax, __pyx_n_s_rois, __pyx_n_s_spatial_scale, __pyx_n_s_ch, __pyx_n_s_h, __pyx_n_s_w, __pyx_n_s_outh, __pyx_n_s_outw, __pyx_n_s_dx, __pyx_n_s_N, __pyx_n_s_ptr_du, __pyx_n_s_ptr_argmax, __pyx_n_s_ptr_rois, __pyx_n_s_ptr_dx); if (unlikely(!__pyx_tuple__60)) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__60);
  __Pyx_GIVEREF(__pyx_tuple__60);
  __pyx_codeobj__61 = (PyObject*)__Pyx_PyCode_New(10, 0, 15, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__60, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_curoi_pool2d_backward, 262, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__61)) __PYX_ERR(0, 262, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":271
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__62 = PyTuple_Pack(4, __pyx_n_s_u, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u); if (unlikely(!__pyx_tuple__62)) __PYX_ERR(0, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__62);
  __Pyx_GIVEREF(__pyx_tuple__62);
  __pyx_codeobj__63 = (PyObject*)__Pyx_PyCode_New(1, 0, 4, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__62, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culstm_forward_activate, 271, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__63)) __PYX_ERR(0, 271, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":279
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__64 = PyTuple_Pack(10, __pyx_n_s_u, __pyx_n_s_s, __pyx_n_s_ps, __pyx_n_s_z, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_s, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_z); if (unlikely(!__pyx_tuple__64)) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__64);
  __Pyx_GIVEREF(__pyx_tuple__64);
  __pyx_codeobj__65 = (PyObject*)__Pyx_PyCode_New(4, 0, 10, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__64, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culstm_forward, 279, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__65)) __PYX_ERR(0, 279, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":290
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_tuple__66 = PyTuple_Pack(20, __pyx_n_s_u, __pyx_n_s_du, __pyx_n_s_s, __pyx_n_s_ps, __pyx_n_s_e, __pyx_n_s_pgf, __pyx_n_s_dou, __pyx_n_s_dou_n, __pyx_n_s_temporal, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_du, __pyx_n_s_ptr_s, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_e, __pyx_n_s_ptr_pgf, __pyx_n_s_ptr_dou, __pyx_n_s_ptr_dou_n, __pyx_n_s_temp); if (unlikely(!__pyx_tuple__66)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__66);
  __Pyx_GIVEREF(__pyx_tuple__66);
  __pyx_codeobj__67 = (PyObject*)__Pyx_PyCode_New(9, 0, 20, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__66, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_culstm_backward, 290, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__67)) __PYX_ERR(0, 290, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":306
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */
  __pyx_tuple__68 = PyTuple_Pack(12, __pyx_n_s_u, __pyx_n_s_wc, __pyx_n_s_prestate, __pyx_n_s_state, __pyx_n_s_z, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_z, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_s, __pyx_n_s_ptr_wc); if (unlikely(!__pyx_tuple__68)) __PYX_ERR(0, 306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__68);
  __Pyx_GIVEREF(__pyx_tuple__68);
  __pyx_codeobj__69 = (PyObject*)__Pyx_PyCode_New(5, 0, 12, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__68, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cupeepholelstm_forward, 306, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__69)) __PYX_ERR(0, 306, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":319
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 */
  __pyx_tuple__70 = PyTuple_Pack(26, __pyx_n_s_u, __pyx_n_s_prestate, __pyx_n_s_state, __pyx_n_s_prefg, __pyx_n_s_wc, __pyx_n_s_dy, __pyx_n_s_drt, __pyx_n_s_dot, __pyx_n_s_dr, __pyx_n_s_dou, __pyx_n_s_dwc, __pyx_n_s_temporal, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr_u, __pyx_n_s_ptr_ps, __pyx_n_s_ptr_s, __pyx_n_s_ptr_pfg, __pyx_n_s_ptr_wc, __pyx_n_s_ptr_dy, __pyx_n_s_ptr_drt, __pyx_n_s_ptr_dot, __pyx_n_s_ptr_dr, __pyx_n_s_ptr_dou, __pyx_n_s_ptr_dwc, __pyx_n_s_temp); if (unlikely(!__pyx_tuple__70)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__70);
  __Pyx_GIVEREF(__pyx_tuple__70);
  __pyx_codeobj__71 = (PyObject*)__Pyx_PyCode_New(12, 0, 26, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__70, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cupeepholelstm_backward, 319, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__71)) __PYX_ERR(0, 319, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":341
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_tuple__72 = PyTuple_Pack(7, __pyx_n_s_gpu_value1, __pyx_n_s_th, __pyx_n_s_gpu_value2, __pyx_n_s_N, __pyx_n_s_gpu_ptr1, __pyx_n_s_gpu_ptr2, __pyx_n_s_threathold); if (unlikely(!__pyx_tuple__72)) __PYX_ERR(0, 341, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__72);
  __Pyx_GIVEREF(__pyx_tuple__72);
  __pyx_codeobj__73 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__72, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cubinarize, 341, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__73)) __PYX_ERR(0, 341, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":350
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */
  __pyx_tuple__74 = PyTuple_Pack(9, __pyx_n_s_gpu_value1, __pyx_n_s_weight, __pyx_n_s_gpu_value2, __pyx_n_s_N, __pyx_n_s_K, __pyx_n_s_M, __pyx_n_s_gpu_ptr1, __pyx_n_s_gpu_ptr2, __pyx_n_s_weight_ptr); if (unlikely(!__pyx_tuple__74)) __PYX_ERR(0, 350, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__74);
  __Pyx_GIVEREF(__pyx_tuple__74);
  __pyx_codeobj__75 = (PyObject*)__Pyx_PyCode_New(3, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__74, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuembedding_forward, 350, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__75)) __PYX_ERR(0, 350, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":361
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */
  __pyx_tuple__76 = PyTuple_Pack(9, __pyx_n_s_gpu_index, __pyx_n_s_gpu_dy, __pyx_n_s_gpu_dx, __pyx_n_s_N, __pyx_n_s_K, __pyx_n_s_M, __pyx_n_s_index_ptr, __pyx_n_s_dy_ptr, __pyx_n_s_dx_ptr); if (unlikely(!__pyx_tuple__76)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__76);
  __Pyx_GIVEREF(__pyx_tuple__76);
  __pyx_codeobj__77 = (PyObject*)__Pyx_PyCode_New(3, 0, 9, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__76, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuembedding_backward, 361, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__77)) __PYX_ERR(0, 361, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":372
 * 
 * 
 * def cuconcat(gpu_value1, gpu_value2, gpu_value3, axis):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_tuple__78 = PyTuple_Pack(13, __pyx_n_s_gpu_value1, __pyx_n_s_gpu_value2, __pyx_n_s_gpu_value3, __pyx_n_s_axis, __pyx_n_s_size, __pyx_n_s_s1, __pyx_n_s_s2, __pyx_n_s_size1, __pyx_n_s_size2, __pyx_n_s_rec_size, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_ptr3); if (unlikely(!__pyx_tuple__78)) __PYX_ERR(0, 372, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__78);
  __Pyx_GIVEREF(__pyx_tuple__78);
  __pyx_codeobj__79 = (PyObject*)__Pyx_PyCode_New(4, 0, 13, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__78, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cuconcat, 372, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__79)) __PYX_ERR(0, 372, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":434
 * 
 * 
 * def cusum(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_sum)
 * 
 */
  __pyx_tuple__80 = PyTuple_Pack(2, __pyx_n_s_gpu_value1, __pyx_n_s_axis); if (unlikely(!__pyx_tuple__80)) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__80);
  __Pyx_GIVEREF(__pyx_tuple__80);
  __pyx_codeobj__81 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__80, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cusum, 434, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__81)) __PYX_ERR(0, 434, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":438
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */
  __pyx_tuple__82 = PyTuple_Pack(2, __pyx_n_s_gpu_value1, __pyx_n_s_axis); if (unlikely(!__pyx_tuple__82)) __PYX_ERR(0, 438, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__82);
  __Pyx_GIVEREF(__pyx_tuple__82);
  __pyx_codeobj__83 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__82, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_reduce_min, 438, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__83)) __PYX_ERR(0, 438, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":442
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */
  __pyx_tuple__84 = PyTuple_Pack(2, __pyx_n_s_gpu_value1, __pyx_n_s_axis); if (unlikely(!__pyx_tuple__84)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__84);
  __Pyx_GIVEREF(__pyx_tuple__84);
  __pyx_codeobj__85 = (PyObject*)__Pyx_PyCode_New(2, 0, 2, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__84, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_reduce_max, 442, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__85)) __PYX_ERR(0, 442, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":446
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_tuple__86 = PyTuple_Pack(7, __pyx_n_s_bias, __pyx_n_s_gpu_value, __pyx_n_s_ptr1, __pyx_n_s_ptr2, __pyx_n_s_size, __pyx_n_s_wh, __pyx_n_s_n); if (unlikely(!__pyx_tuple__86)) __PYX_ERR(0, 446, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__86);
  __Pyx_GIVEREF(__pyx_tuple__86);
  __pyx_codeobj__87 = (PyObject*)__Pyx_PyCode_New(2, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__86, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_add_bias, 446, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__87)) __PYX_ERR(0, 446, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":454
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */
  __pyx_tuple__88 = PyTuple_Pack(6, __pyx_n_s_ary, __pyx_n_s_fg_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__88)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__88);
  __Pyx_GIVEREF(__pyx_tuple__88);
  __pyx_codeobj__89 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__88, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_fg_ary_forward, 454, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__89)) __PYX_ERR(0, 454, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":461
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */
  __pyx_tuple__90 = PyTuple_Pack(6, __pyx_n_s_du, __pyx_n_s_zero, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__90)) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__90);
  __Pyx_GIVEREF(__pyx_tuple__90);
  __pyx_codeobj__91 = (PyObject*)__Pyx_PyCode_New(2, 0, 6, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__90, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_fg_ary_backward, 461, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__91)) __PYX_ERR(0, 461, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":468
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */
  __pyx_tuple__92 = PyTuple_Pack(7, __pyx_n_s_ary, __pyx_n_s_ith_ary, __pyx_n_s_i, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__92)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__92);
  __Pyx_GIVEREF(__pyx_tuple__92);
  __pyx_codeobj__93 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__92, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_ith_ary_forward, 468, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__93)) __PYX_ERR(0, 468, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":475
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */
  __pyx_tuple__94 = PyTuple_Pack(7, __pyx_n_s_du, __pyx_n_s_zero, __pyx_n_s_i, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__94)) __PYX_ERR(0, 475, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__94);
  __Pyx_GIVEREF(__pyx_tuple__94);
  __pyx_codeobj__95 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__94, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_ith_ary_backward, 475, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__95)) __PYX_ERR(0, 475, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":482
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */
  __pyx_tuple__96 = PyTuple_Pack(8, __pyx_n_s_ary1, __pyx_n_s_ary2, __pyx_n_s_i, __pyx_n_s_j, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ptr1, __pyx_n_s_ptr2); if (unlikely(!__pyx_tuple__96)) __PYX_ERR(0, 482, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__96);
  __Pyx_GIVEREF(__pyx_tuple__96);
  __pyx_codeobj__97 = (PyObject*)__Pyx_PyCode_New(4, 0, 8, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__96, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_every_nth_ary, 482, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__97)) __PYX_ERR(0, 482, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":489
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 */
  __pyx_tuple__98 = PyTuple_Pack(12, __pyx_n_s_x, __pyx_n_s_y, __pyx_n_s_w, __pyx_n_s_h, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_ary_ptr, __pyx_n_s_x_ptr, __pyx_n_s_y_ptr, __pyx_n_s_h_ptr, __pyx_n_s_w_ptr); if (unlikely(!__pyx_tuple__98)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__98);
  __Pyx_GIVEREF(__pyx_tuple__98);
  __pyx_codeobj__99 = (PyObject*)__Pyx_PyCode_New(5, 0, 12, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__98, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_assign_pred_box, 489, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__99)) __PYX_ERR(0, 489, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":498
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 */
  __pyx_tuple__100 = PyTuple_Pack(10, __pyx_n_s_arg, __pyx_n_s_length, __pyx_n_s_ctr, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_arg_ptr, __pyx_n_s_length_ptr, __pyx_n_s_ctr_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__100)) __PYX_ERR(0, 498, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__100);
  __Pyx_GIVEREF(__pyx_tuple__100);
  __pyx_codeobj__101 = (PyObject*)__Pyx_PyCode_New(4, 0, 10, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__100, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_pred_ctr, 498, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__101)) __PYX_ERR(0, 498, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":506
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */
  __pyx_tuple__102 = PyTuple_Pack(15, __pyx_n_s_shifts, __pyx_n_s_base_size, __pyx_n_s_ratios, __pyx_n_s_scales, __pyx_n_s_feat_stride, __pyx_n_s_anchors, __pyx_n_s_K, __pyx_n_s_A, __pyx_n_s_N, __pyx_n_s_scale_size, __pyx_n_s_ratio_size, __pyx_n_s_shifts_ptr, __pyx_n_s_ratios_ptr, __pyx_n_s_scales_ptr, __pyx_n_s_anchors_ptr); if (unlikely(!__pyx_tuple__102)) __PYX_ERR(0, 506, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__102);
  __Pyx_GIVEREF(__pyx_tuple__102);
  __pyx_codeobj__103 = (PyObject*)__Pyx_PyCode_New(6, 0, 15, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__102, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_generate_anchors, 506, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__103)) __PYX_ERR(0, 506, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":516
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 */
  __pyx_tuple__104 = PyTuple_Pack(7, __pyx_n_s_bbox, __pyx_n_s_i, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_bbox_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__104)) __PYX_ERR(0, 516, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__104);
  __Pyx_GIVEREF(__pyx_tuple__104);
  __pyx_codeobj__105 = (PyObject*)__Pyx_PyCode_New(3, 0, 7, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__104, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_get_ith_bbox, 516, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__105)) __PYX_ERR(0, 516, __pyx_L1_error)

  /* "renom/cuda/thrust_funcs.pxi":522
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 */
  __pyx_tuple__106 = PyTuple_Pack(11, __pyx_n_s_roi, __pyx_n_s_start, __pyx_n_s_end, __pyx_n_s_step, __pyx_n_s_min_v, __pyx_n_s_max_v, __pyx_n_s_ary, __pyx_n_s_N, __pyx_n_s_M, __pyx_n_s_roi_ptr, __pyx_n_s_ary_ptr); if (unlikely(!__pyx_tuple__106)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_tuple__106);
  __Pyx_GIVEREF(__pyx_tuple__106);
  __pyx_codeobj__107 = (PyObject*)__Pyx_PyCode_New(7, 0, 11, 0, 0, __pyx_empty_bytes, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_tuple__106, __pyx_empty_tuple, __pyx_empty_tuple, __pyx_kp_s_renom_cuda_thrust_funcs_pxi, __pyx_n_s_cu_clip_roi, 522, __pyx_empty_bytes); if (unlikely(!__pyx_codeobj__107)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_RefNannyFinishContext();
  return 0;
  __pyx_L1_error:;
  __Pyx_RefNannyFinishContext();
  return -1;
}

static int __Pyx_InitGlobals(void) {
  if (__Pyx_InitStrings(__pyx_string_tab) < 0) __PYX_ERR(1, 1, __pyx_L1_error);
  __pyx_int_0 = PyInt_FromLong(0); if (unlikely(!__pyx_int_0)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_int_1 = PyInt_FromLong(1); if (unlikely(!__pyx_int_1)) __PYX_ERR(1, 1, __pyx_L1_error)
  return 0;
  __pyx_L1_error:;
  return -1;
}

#if PY_MAJOR_VERSION < 3
PyMODINIT_FUNC initthrust_double(void); /*proto*/
PyMODINIT_FUNC initthrust_double(void)
#else
PyMODINIT_FUNC PyInit_thrust_double(void); /*proto*/
PyMODINIT_FUNC PyInit_thrust_double(void)
#endif
{
  PyObject *__pyx_t_1 = NULL;
  __Pyx_RefNannyDeclarations
  #if CYTHON_REFNANNY
  __Pyx_RefNanny = __Pyx_RefNannyImportAPI("refnanny");
  if (!__Pyx_RefNanny) {
      PyErr_Clear();
      __Pyx_RefNanny = __Pyx_RefNannyImportAPI("Cython.Runtime.refnanny");
      if (!__Pyx_RefNanny)
          Py_FatalError("failed to import 'refnanny' module");
  }
  #endif
  __Pyx_RefNannySetupContext("PyMODINIT_FUNC PyInit_thrust_double(void)", 0);
  if (__Pyx_check_binary_version() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_tuple = PyTuple_New(0); if (unlikely(!__pyx_empty_tuple)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_bytes = PyBytes_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_bytes)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_empty_unicode = PyUnicode_FromStringAndSize("", 0); if (unlikely(!__pyx_empty_unicode)) __PYX_ERR(1, 1, __pyx_L1_error)
  #ifdef __Pyx_CyFunction_USED
  if (__pyx_CyFunction_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_FusedFunction_USED
  if (__pyx_FusedFunction_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Coroutine_USED
  if (__pyx_Coroutine_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_Generator_USED
  if (__pyx_Generator_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  #ifdef __Pyx_StopAsyncIteration_USED
  if (__pyx_StopAsyncIteration_init() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  /*--- Library function declarations ---*/
  /*--- Threads initialization code ---*/
  #if defined(__PYX_FORCE_INIT_THREADS) && __PYX_FORCE_INIT_THREADS
  #ifdef WITH_THREAD /* Python build with threading support? */
  PyEval_InitThreads();
  #endif
  #endif
  /*--- Module creation code ---*/
  #if PY_MAJOR_VERSION < 3
  __pyx_m = Py_InitModule4("thrust_double", __pyx_methods, 0, 0, PYTHON_API_VERSION); Py_XINCREF(__pyx_m);
  #else
  __pyx_m = PyModule_Create(&__pyx_moduledef);
  #endif
  if (unlikely(!__pyx_m)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_d = PyModule_GetDict(__pyx_m); if (unlikely(!__pyx_d)) __PYX_ERR(1, 1, __pyx_L1_error)
  Py_INCREF(__pyx_d);
  __pyx_b = PyImport_AddModule(__Pyx_BUILTIN_MODULE_NAME); if (unlikely(!__pyx_b)) __PYX_ERR(1, 1, __pyx_L1_error)
  __pyx_cython_runtime = PyImport_AddModule((char *) "cython_runtime"); if (unlikely(!__pyx_cython_runtime)) __PYX_ERR(1, 1, __pyx_L1_error)
  #if CYTHON_COMPILING_IN_PYPY
  Py_INCREF(__pyx_b);
  #endif
  if (PyObject_SetAttrString(__pyx_m, "__builtins__", __pyx_b) < 0) __PYX_ERR(1, 1, __pyx_L1_error);
  /*--- Initialize various global constants etc. ---*/
  if (__Pyx_InitGlobals() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #if PY_MAJOR_VERSION < 3 && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
  if (__Pyx_init_sys_getdefaultencoding_params() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif
  if (__pyx_module_is_main_renom__cuda__thrust_double) {
    if (PyObject_SetAttrString(__pyx_m, "__name__", __pyx_n_s_main) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  }
  #if PY_MAJOR_VERSION >= 3
  {
    PyObject *modules = PyImport_GetModuleDict(); if (unlikely(!modules)) __PYX_ERR(1, 1, __pyx_L1_error)
    if (!PyDict_GetItemString(modules, "renom.cuda.thrust_double")) {
      if (unlikely(PyDict_SetItemString(modules, "renom.cuda.thrust_double", __pyx_m) < 0)) __PYX_ERR(1, 1, __pyx_L1_error)
    }
  }
  #endif
  /*--- Builtin init code ---*/
  if (__Pyx_InitCachedBuiltins() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  /*--- Constants init code ---*/
  if (__Pyx_InitCachedConstants() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  /*--- Global init code ---*/
  /*--- Variable export code ---*/
  /*--- Function export code ---*/
  /*--- Type init code ---*/
  /*--- Type import code ---*/
  /*--- Variable import code ---*/
  /*--- Function import code ---*/
  /*--- Execution code ---*/
  #if defined(__Pyx_Generator_USED) || defined(__Pyx_Coroutine_USED)
  if (__Pyx_patch_abc() < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  #endif

  /* "renom/cuda/thrust_funcs.pxi":9
 * : gpu_value
 * """
 * import numpy as np             # <<<<<<<<<<<<<<
 * from libc.stdint cimport uintptr_t
 * from libcpp cimport bool
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_numpy, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_np, __pyx_t_1) < 0) __PYX_ERR(0, 9, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":12
 * from libc.stdint cimport uintptr_t
 * from libcpp cimport bool
 * import cuda_base             # <<<<<<<<<<<<<<
 * import operator
 * import functools
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_cuda_base, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 12, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuda_base, __pyx_t_1) < 0) __PYX_ERR(0, 12, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":13
 * from libcpp cimport bool
 * import cuda_base
 * import operator             # <<<<<<<<<<<<<<
 * import functools
 * import renom.core
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_operator, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_operator, __pyx_t_1) < 0) __PYX_ERR(0, 13, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":14
 * import cuda_base
 * import operator
 * import functools             # <<<<<<<<<<<<<<
 * import renom.core
 * import renom.cuda
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_functools, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_functools, __pyx_t_1) < 0) __PYX_ERR(0, 14, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":15
 * import operator
 * import functools
 * import renom.core             # <<<<<<<<<<<<<<
 * import renom.cuda
 * 
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_renom_core, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_renom, __pyx_t_1) < 0) __PYX_ERR(0, 15, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":16
 * import functools
 * import renom.core
 * import renom.cuda             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = __Pyx_Import(__pyx_n_s_renom_cuda, 0, -1); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_renom, __pyx_t_1) < 0) __PYX_ERR(0, 16, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":19
 * 
 * 
 * def cunegate(input, result):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(input, result)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_1cunegate, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cunegate, __pyx_t_1) < 0) __PYX_ERR(0, 19, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":28
 * 
 * 
 * def curelu_foward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_3curelu_foward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 28, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curelu_foward, __pyx_t_1) < 0) __PYX_ERR(0, 28, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":37
 * 
 * 
 * def curelu_backard(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_5curelu_backard, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curelu_backard, __pyx_t_1) < 0) __PYX_ERR(0, 37, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":46
 * 
 * 
 * def culeaky_leru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_7culeaky_leru_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culeaky_leru_forward, __pyx_t_1) < 0) __PYX_ERR(0, 46, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":55
 * 
 * 
 * def culeaky_leru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_9culeaky_leru_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 55, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culeaky_leru_backward, __pyx_t_1) < 0) __PYX_ERR(0, 55, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":64
 * 
 * 
 * def cueru_forward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_11cueru_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cueru_forward, __pyx_t_1) < 0) __PYX_ERR(0, 64, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":73
 * 
 * 
 * def cueru_backward(s, gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_13cueru_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cueru_backward, __pyx_t_1) < 0) __PYX_ERR(0, 73, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":82
 * 
 * 
 * def cusigmoid(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_15cusigmoid, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusigmoid, __pyx_t_1) < 0) __PYX_ERR(0, 82, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":91
 * 
 * 
 * def cutanh(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_17cutanh, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cutanh, __pyx_t_1) < 0) __PYX_ERR(0, 91, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":119
 * 
 * 
 * def cumul(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.MUL, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_19cumul, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumul, __pyx_t_1) < 0) __PYX_ERR(0, 119, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":124
 * 
 * 
 * def cuadd(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.ADD, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_21cuadd, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuadd, __pyx_t_1) < 0) __PYX_ERR(0, 124, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":129
 * 
 * 
 * def cusub(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.SUB, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_23cusub, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusub, __pyx_t_1) < 0) __PYX_ERR(0, 129, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":134
 * 
 * 
 * def cudiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.DIV, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_25cudiv, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 134, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cudiv, __pyx_t_1) < 0) __PYX_ERR(0, 134, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":139
 * 
 * 
 * def curdiv(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RDIV, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_27curdiv, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curdiv, __pyx_t_1) < 0) __PYX_ERR(0, 139, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":144
 * 
 * 
 * def cupow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.POW, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_29cupow, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 144, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupow, __pyx_t_1) < 0) __PYX_ERR(0, 144, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":149
 * 
 * 
 * def curpow(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 *     basic_operation(Operation.RPOW, gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_31curpow, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curpow, __pyx_t_1) < 0) __PYX_ERR(0, 149, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":154
 * 
 * 
 * def cufill(value, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value.size
 *     cdef VALUE_TYPE v = <VALUE_TYPE > value
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_33cufill, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cufill, __pyx_t_1) < 0) __PYX_ERR(0, 154, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":163
 * 
 * 
 * def culoge(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_35culoge, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culoge, __pyx_t_1) < 0) __PYX_ERR(0, 163, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":172
 * 
 * 
 * def cuexp(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_37cuexp, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 172, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuexp, __pyx_t_1) < 0) __PYX_ERR(0, 172, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":179
 * 
 * 
 * def cusqrt(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_39cusqrt, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 179, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusqrt, __pyx_t_1) < 0) __PYX_ERR(0, 179, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":187
 *     thrust_sqrt(ptr1, ptr2, size)
 * 
 * def cusign(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > <uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_41cusign, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusign, __pyx_t_1) < 0) __PYX_ERR(0, 187, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":194
 *     thrust_sign(ptr1, ptr2, size)
 * 
 * def cucross_entropy(gpu_value1, gpu_value2, gpu_value3):             # <<<<<<<<<<<<<<
 *     cdef int size = <int > gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_43cucross_entropy, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 194, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cucross_entropy, __pyx_t_1) < 0) __PYX_ERR(0, 194, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":204
 * 
 * 
 * def cubroadcast(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size_1 = <int > gpu_value1.size
 *     cdef int size_2 = <int > gpu_value2.size
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_45cubroadcast, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 204, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cubroadcast, __pyx_t_1) < 0) __PYX_ERR(0, 204, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":214
 * 
 * 
 * def cuabs_forward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_47cuabs_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 214, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuabs_forward, __pyx_t_1) < 0) __PYX_ERR(0, 214, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":223
 * 
 * 
 * def cuabs_backward(gpu_value1, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_49cuabs_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuabs_backward, __pyx_t_1) < 0) __PYX_ERR(0, 223, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":232
 * 
 * 
 * def cumin(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_51cumin, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 232, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumin, __pyx_t_1) < 0) __PYX_ERR(0, 232, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":242
 * 
 * 
 * def cumax(value, gpu_value1, gpu_value2=None):             # <<<<<<<<<<<<<<
 *     cdef int size = gpu_value1.size
 *     cdef VALUE_TYPE * ptr1 = < VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_53cumax, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 242, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cumax, __pyx_t_1) < 0) __PYX_ERR(0, 242, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":252
 * 
 * 
 * def curoi_pool2d_forward(rois, x, spatial_scale, channels, height,             # <<<<<<<<<<<<<<
 *                         width, outh, outw, z, augmax_data):
 *     cdef int N = rois.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_55curoi_pool2d_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 252, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curoi_pool2d_forward, __pyx_t_1) < 0) __PYX_ERR(0, 252, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":262
 *     thrust_forward_roi_pool2d(N, ptr_x, spatial_scale, channels, height, width, outh, outw, ptr_rois, ptr_z, ptr_augmax_data)
 * 
 * def curoi_pool2d_backward(du, argmax, rois, spatial_scale, ch, h, w, outh, outw, dx):             # <<<<<<<<<<<<<<
 *     cdef int N = rois.shape[0]
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_57curoi_pool2d_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_curoi_pool2d_backward, __pyx_t_1) < 0) __PYX_ERR(0, 262, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":271
 *     thrust_backward_roi_pool2d(N, ptr_du, ptr_argmax, ptr_rois, spatial_scale, ch, h, w, outh, outw, ptr_dx)
 * 
 * def culstm_forward_activate(u):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_59culstm_forward_activate, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 271, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_forward_activate, __pyx_t_1) < 0) __PYX_ERR(0, 271, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":279
 * 
 * 
 * def culstm_forward(u, s, ps, z):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_61culstm_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_forward, __pyx_t_1) < 0) __PYX_ERR(0, 279, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":290
 * 
 * 
 * def culstm_backward(u, du, s, ps, e, pgf, dou, dou_n, temporal):             # <<<<<<<<<<<<<<
 *     cdef int N = u.shape[0]
 *     cdef int M = u.shape[1]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_63culstm_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_culstm_backward, __pyx_t_1) < 0) __PYX_ERR(0, 290, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":306
 * 
 * 
 * def cupeepholelstm_forward(u, wc, prestate, state, z):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, wc, z)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_65cupeepholelstm_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 306, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupeepholelstm_forward, __pyx_t_1) < 0) __PYX_ERR(0, 306, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":319
 * 
 * 
 * def cupeepholelstm_backward(u, prestate, state, prefg, wc, dy, drt, dot, dr, dou, dwc, temporal):             # <<<<<<<<<<<<<<
 *     cuda_base.check_heap_device(u, prestate, state, prestate, wc,
 *                                 dy, drt, dot, dou, dr, dwc, temporal)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_67cupeepholelstm_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cupeepholelstm_backward, __pyx_t_1) < 0) __PYX_ERR(0, 319, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":341
 * 
 * 
 * def cubinarize(gpu_value1, th, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.size
 *     cdef VALUE_TYPE * gpu_ptr1 = <VALUE_TYPE * > < uintptr_t > gpu_value1._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_69cubinarize, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 341, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cubinarize, __pyx_t_1) < 0) __PYX_ERR(0, 341, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":350
 * 
 * 
 * def cuembedding_forward(gpu_value1, weight, gpu_value2):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_value1.shape[0]
 *     cdef int K = weight.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_71cuembedding_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 350, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuembedding_forward, __pyx_t_1) < 0) __PYX_ERR(0, 350, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":361
 * 
 * 
 * def cuembedding_backward(gpu_index, gpu_dy, gpu_dx):             # <<<<<<<<<<<<<<
 *     cdef int N = gpu_index.shape[0]
 *     cdef int K = gpu_dx.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_73cuembedding_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuembedding_backward, __pyx_t_1) < 0) __PYX_ERR(0, 361, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":372
 * 
 * 
 * def cuconcat(gpu_value1, gpu_value2, gpu_value3, axis):             # <<<<<<<<<<<<<<
 * 
 *     cuda_base.check_heap_device(gpu_value1, gpu_value2, gpu_value3)
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_75cuconcat, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 372, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cuconcat, __pyx_t_1) < 0) __PYX_ERR(0, 372, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":434
 * 
 * 
 * def cusum(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_sum)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_77cusum, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cusum, __pyx_t_1) < 0) __PYX_ERR(0, 434, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":438
 * 
 * 
 * def cu_reduce_min(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_79cu_reduce_min, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 438, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_min, __pyx_t_1) < 0) __PYX_ERR(0, 438, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":442
 * 
 * 
 * def cu_reduce_max(gpu_value1, axis=None):             # <<<<<<<<<<<<<<
 *     return _reduce_array(gpu_value1, axis, thrust_reduce_min)
 * 
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_81cu_reduce_max, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_reduce_max, __pyx_t_1) < 0) __PYX_ERR(0, 442, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":446
 * 
 * 
 * def cu_add_bias(bias, gpu_value):             # <<<<<<<<<<<<<<
 *     cdef VALUE_TYPE * ptr1 = <VALUE_TYPE * > < uintptr_t > bias._ptr
 *     cdef VALUE_TYPE * ptr2 = <VALUE_TYPE * > < uintptr_t > gpu_value._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_83cu_add_bias, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 446, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_add_bias, __pyx_t_1) < 0) __PYX_ERR(0, 446, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":454
 *     thrust_add_bias(size, n, wh, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_forward(ary, fg_ary):             # <<<<<<<<<<<<<<
 *     N = ary.shape[0] * ary.shape[1] * ary.shape[2] * ary.shape[3] * ary.shape[4]
 *     M = ary.shape[3] * ary.shape[4]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_85cu_get_fg_ary_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_fg_ary_forward, __pyx_t_1) < 0) __PYX_ERR(0, 454, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":461
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_fg_ary_backward(du, zero):             # <<<<<<<<<<<<<<
 *     N = zero.shape[0] * zero.shape[1] * zero.shape[2] * zero.shape[3] * zero.shape[4]
 *     M = du.shape[3] * du.shape[4]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_87cu_get_fg_ary_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_fg_ary_backward, __pyx_t_1) < 0) __PYX_ERR(0, 461, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":468
 *     thrust_get_fg_ary_forward(N, M, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_forward(ary, ith_ary, i):             # <<<<<<<<<<<<<<
 *     N = ary.size
 *     M = ary.size / ary.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_89cu_get_ith_ary_forward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_ary_forward, __pyx_t_1) < 0) __PYX_ERR(0, 468, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":475
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_ith_ary_backward(du, zero, i):             # <<<<<<<<<<<<<<
 *     N = zero.size
 *     M = zero.size / zero.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_91cu_get_ith_ary_backward, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 475, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_ary_backward, __pyx_t_1) < 0) __PYX_ERR(0, 475, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":482
 *     thrust_get_ith_ary_forward(N, M, i, ptr1, ptr2)
 * 
 * def cu_get_every_nth_ary(ary1, ary2, i, j):             # <<<<<<<<<<<<<<
 *     N = ary1.shape[0]
 *     M = ary1.shape[1]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_93cu_get_every_nth_ary, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 482, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_every_nth_ary, __pyx_t_1) < 0) __PYX_ERR(0, 482, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":489
 *     thrust_get_nth_ary(N, M, i, j, ptr1, ptr2)
 * 
 * def cu_assign_pred_box(x, y, w, h, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE * ary_ptr = <VALUE_TYPE *> <uintptr_t> ary._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_95cu_assign_pred_box, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_assign_pred_box, __pyx_t_1) < 0) __PYX_ERR(0, 489, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":498
 *     thrust_assign_pred_box(N, M, x_ptr, y_ptr, h_ptr, w_ptr, ary_ptr)
 * 
 * def cu_pred_ctr(arg, length, ctr, ary):             # <<<<<<<<<<<<<<
 *     N, M = ary.shape
 *     cdef VALUE_TYPE *arg_ptr = <VALUE_TYPE *><uintptr_t> arg._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_97cu_pred_ctr, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 498, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_pred_ctr, __pyx_t_1) < 0) __PYX_ERR(0, 498, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":506
 *     thrust_pred_ctr(N, M, arg_ptr, length_ptr, ctr_ptr, ary_ptr)
 * 
 * def cu_generate_anchors(shifts, base_size, ratios, scales, feat_stride, anchors):             # <<<<<<<<<<<<<<
 *     K, A, N = anchors.shape
 *     scale_size = scales.shape[0]
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_99cu_generate_anchors, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 506, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_generate_anchors, __pyx_t_1) < 0) __PYX_ERR(0, 506, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":516
 *     thrust_generate_anchors(A, K, N, shifts_ptr, ratios_ptr, scales_ptr, ratio_size, scale_size, feat_stride, base_size, anchors_ptr)
 * 
 * def cu_get_ith_bbox(bbox, i, ary):             # <<<<<<<<<<<<<<
 *     N, M = bbox.shape
 *     cdef VALUE_TYPE * bbox_ptr = <VALUE_TYPE *><uintptr_t> bbox._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_101cu_get_ith_bbox, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 516, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_get_ith_bbox, __pyx_t_1) < 0) __PYX_ERR(0, 516, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_funcs.pxi":522
 *     thrust_get_ith_bbox(N, M, bbox_ptr, i, ary_ptr)
 * 
 * def cu_clip_roi(roi, start, end, step, min_v, max_v, ary):             # <<<<<<<<<<<<<<
 *     N, M = roi.shape
 *     cdef VALUE_TYPE * roi_ptr = <VALUE_TYPE *><uintptr_t> roi._ptr
 */
  __pyx_t_1 = PyCFunction_NewEx(&__pyx_mdef_5renom_4cuda_13thrust_double_103cu_clip_roi, NULL, __pyx_n_s_renom_cuda_thrust_double); if (unlikely(!__pyx_t_1)) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_cu_clip_roi, __pyx_t_1) < 0) __PYX_ERR(0, 522, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /* "renom/cuda/thrust_double.pyx":1
 * cimport thrust_double as renom_thrust             # <<<<<<<<<<<<<<
 * 
 * 
 */
  __pyx_t_1 = PyDict_New(); if (unlikely(!__pyx_t_1)) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_GOTREF(__pyx_t_1);
  if (PyDict_SetItem(__pyx_d, __pyx_n_s_test, __pyx_t_1) < 0) __PYX_ERR(1, 1, __pyx_L1_error)
  __Pyx_DECREF(__pyx_t_1); __pyx_t_1 = 0;

  /*--- Wrapped vars code ---*/

  goto __pyx_L0;
  __pyx_L1_error:;
  __Pyx_XDECREF(__pyx_t_1);
  if (__pyx_m) {
    if (__pyx_d) {
      __Pyx_AddTraceback("init renom.cuda.thrust_double", 0, __pyx_lineno, __pyx_filename);
    }
    Py_DECREF(__pyx_m); __pyx_m = 0;
  } else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_ImportError, "init renom.cuda.thrust_double");
  }
  __pyx_L0:;
  __Pyx_RefNannyFinishContext();
  #if PY_MAJOR_VERSION < 3
  return;
  #else
  return __pyx_m;
  #endif
}

/* --- Runtime support code --- */
/* Refnanny */
#if CYTHON_REFNANNY
static __Pyx_RefNannyAPIStruct *__Pyx_RefNannyImportAPI(const char *modname) {
    PyObject *m = NULL, *p = NULL;
    void *r = NULL;
    m = PyImport_ImportModule((char *)modname);
    if (!m) goto end;
    p = PyObject_GetAttrString(m, (char *)"RefNannyAPI");
    if (!p) goto end;
    r = PyLong_AsVoidPtr(p);
end:
    Py_XDECREF(p);
    Py_XDECREF(m);
    return (__Pyx_RefNannyAPIStruct *)r;
}
#endif

/* GetBuiltinName */
static PyObject *__Pyx_GetBuiltinName(PyObject *name) {
    PyObject* result = __Pyx_PyObject_GetAttrStr(__pyx_b, name);
    if (unlikely(!result)) {
        PyErr_Format(PyExc_NameError,
#if PY_MAJOR_VERSION >= 3
            "name '%U' is not defined", name);
#else
            "name '%.200s' is not defined", PyString_AS_STRING(name));
#endif
    }
    return result;
}

/* RaiseArgTupleInvalid */
static void __Pyx_RaiseArgtupleInvalid(
    const char* func_name,
    int exact,
    Py_ssize_t num_min,
    Py_ssize_t num_max,
    Py_ssize_t num_found)
{
    Py_ssize_t num_expected;
    const char *more_or_less;
    if (num_found < num_min) {
        num_expected = num_min;
        more_or_less = "at least";
    } else {
        num_expected = num_max;
        more_or_less = "at most";
    }
    if (exact) {
        more_or_less = "exactly";
    }
    PyErr_Format(PyExc_TypeError,
                 "%.200s() takes %.8s %" CYTHON_FORMAT_SSIZE_T "d positional argument%.1s (%" CYTHON_FORMAT_SSIZE_T "d given)",
                 func_name, more_or_less, num_expected,
                 (num_expected == 1) ? "" : "s", num_found);
}

/* RaiseDoubleKeywords */
static void __Pyx_RaiseDoubleKeywordsError(
    const char* func_name,
    PyObject* kw_name)
{
    PyErr_Format(PyExc_TypeError,
        #if PY_MAJOR_VERSION >= 3
        "%s() got multiple values for keyword argument '%U'", func_name, kw_name);
        #else
        "%s() got multiple values for keyword argument '%s'", func_name,
        PyString_AsString(kw_name));
        #endif
}

/* ParseKeywords */
static int __Pyx_ParseOptionalKeywords(
    PyObject *kwds,
    PyObject **argnames[],
    PyObject *kwds2,
    PyObject *values[],
    Py_ssize_t num_pos_args,
    const char* function_name)
{
    PyObject *key = 0, *value = 0;
    Py_ssize_t pos = 0;
    PyObject*** name;
    PyObject*** first_kw_arg = argnames + num_pos_args;
    while (PyDict_Next(kwds, &pos, &key, &value)) {
        name = first_kw_arg;
        while (*name && (**name != key)) name++;
        if (*name) {
            values[name-argnames] = value;
            continue;
        }
        name = first_kw_arg;
        #if PY_MAJOR_VERSION < 3
        if (likely(PyString_CheckExact(key)) || likely(PyString_Check(key))) {
            while (*name) {
                if ((CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**name) == PyString_GET_SIZE(key))
                        && _PyString_Eq(**name, key)) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    if ((**argname == key) || (
                            (CYTHON_COMPILING_IN_PYPY || PyString_GET_SIZE(**argname) == PyString_GET_SIZE(key))
                             && _PyString_Eq(**argname, key))) {
                        goto arg_passed_twice;
                    }
                    argname++;
                }
            }
        } else
        #endif
        if (likely(PyUnicode_Check(key))) {
            while (*name) {
                int cmp = (**name == key) ? 0 :
                #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                    (PyUnicode_GET_SIZE(**name) != PyUnicode_GET_SIZE(key)) ? 1 :
                #endif
                    PyUnicode_Compare(**name, key);
                if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                if (cmp == 0) {
                    values[name-argnames] = value;
                    break;
                }
                name++;
            }
            if (*name) continue;
            else {
                PyObject*** argname = argnames;
                while (argname != first_kw_arg) {
                    int cmp = (**argname == key) ? 0 :
                    #if !CYTHON_COMPILING_IN_PYPY && PY_MAJOR_VERSION >= 3
                        (PyUnicode_GET_SIZE(**argname) != PyUnicode_GET_SIZE(key)) ? 1 :
                    #endif
                        PyUnicode_Compare(**argname, key);
                    if (cmp < 0 && unlikely(PyErr_Occurred())) goto bad;
                    if (cmp == 0) goto arg_passed_twice;
                    argname++;
                }
            }
        } else
            goto invalid_keyword_type;
        if (kwds2) {
            if (unlikely(PyDict_SetItem(kwds2, key, value))) goto bad;
        } else {
            goto invalid_keyword;
        }
    }
    return 0;
arg_passed_twice:
    __Pyx_RaiseDoubleKeywordsError(function_name, key);
    goto bad;
invalid_keyword_type:
    PyErr_Format(PyExc_TypeError,
        "%.200s() keywords must be strings", function_name);
    goto bad;
invalid_keyword:
    PyErr_Format(PyExc_TypeError,
    #if PY_MAJOR_VERSION < 3
        "%.200s() got an unexpected keyword argument '%.200s'",
        function_name, PyString_AsString(key));
    #else
        "%s() got an unexpected keyword argument '%U'",
        function_name, key);
    #endif
bad:
    return -1;
}

/* GetModuleGlobalName */
static CYTHON_INLINE PyObject *__Pyx_GetModuleGlobalName(PyObject *name) {
    PyObject *result;
#if !CYTHON_AVOID_BORROWED_REFS
    result = PyDict_GetItem(__pyx_d, name);
    if (likely(result)) {
        Py_INCREF(result);
    } else {
#else
    result = PyObject_GetItem(__pyx_d, name);
    if (!result) {
        PyErr_Clear();
#endif
        result = __Pyx_GetBuiltinName(name);
    }
    return result;
}

/* PyFunctionFastCall */
  #if CYTHON_FAST_PYCALL
#include "frameobject.h"
static PyObject* __Pyx_PyFunction_FastCallNoKw(PyCodeObject *co, PyObject **args, Py_ssize_t na,
                                               PyObject *globals) {
    PyFrameObject *f;
    PyThreadState *tstate = PyThreadState_GET();
    PyObject **fastlocals;
    Py_ssize_t i;
    PyObject *result;
    assert(globals != NULL);
    /* XXX Perhaps we should create a specialized
       PyFrame_New() that doesn't take locals, but does
       take builtins without sanity checking them.
       */
    assert(tstate != NULL);
    f = PyFrame_New(tstate, co, globals, NULL);
    if (f == NULL) {
        return NULL;
    }
    fastlocals = f->f_localsplus;
    for (i = 0; i < na; i++) {
        Py_INCREF(*args);
        fastlocals[i] = *args++;
    }
    result = PyEval_EvalFrameEx(f,0);
    ++tstate->recursion_depth;
    Py_DECREF(f);
    --tstate->recursion_depth;
    return result;
}
#if 1 || PY_VERSION_HEX < 0x030600B1
static PyObject *__Pyx_PyFunction_FastCallDict(PyObject *func, PyObject **args, int nargs, PyObject *kwargs) {
    PyCodeObject *co = (PyCodeObject *)PyFunction_GET_CODE(func);
    PyObject *globals = PyFunction_GET_GLOBALS(func);
    PyObject *argdefs = PyFunction_GET_DEFAULTS(func);
    PyObject *closure;
#if PY_MAJOR_VERSION >= 3
    PyObject *kwdefs;
#endif
    PyObject *kwtuple, **k;
    PyObject **d;
    Py_ssize_t nd;
    Py_ssize_t nk;
    PyObject *result;
    assert(kwargs == NULL || PyDict_Check(kwargs));
    nk = kwargs ? PyDict_Size(kwargs) : 0;
    if (Py_EnterRecursiveCall((char*)" while calling a Python object")) {
        return NULL;
    }
    if (
#if PY_MAJOR_VERSION >= 3
            co->co_kwonlyargcount == 0 &&
#endif
            likely(kwargs == NULL || nk == 0) &&
            co->co_flags == (CO_OPTIMIZED | CO_NEWLOCALS | CO_NOFREE)) {
        if (argdefs == NULL && co->co_argcount == nargs) {
            result = __Pyx_PyFunction_FastCallNoKw(co, args, nargs, globals);
            goto done;
        }
        else if (nargs == 0 && argdefs != NULL
                 && co->co_argcount == Py_SIZE(argdefs)) {
            /* function called with no arguments, but all parameters have
               a default value: use default values as arguments .*/
            args = &PyTuple_GET_ITEM(argdefs, 0);
            result =__Pyx_PyFunction_FastCallNoKw(co, args, Py_SIZE(argdefs), globals);
            goto done;
        }
    }
    if (kwargs != NULL) {
        Py_ssize_t pos, i;
        kwtuple = PyTuple_New(2 * nk);
        if (kwtuple == NULL) {
            result = NULL;
            goto done;
        }
        k = &PyTuple_GET_ITEM(kwtuple, 0);
        pos = i = 0;
        while (PyDict_Next(kwargs, &pos, &k[i], &k[i+1])) {
            Py_INCREF(k[i]);
            Py_INCREF(k[i+1]);
            i += 2;
        }
        nk = i / 2;
    }
    else {
        kwtuple = NULL;
        k = NULL;
    }
    closure = PyFunction_GET_CLOSURE(func);
#if PY_MAJOR_VERSION >= 3
    kwdefs = PyFunction_GET_KW_DEFAULTS(func);
#endif
    if (argdefs != NULL) {
        d = &PyTuple_GET_ITEM(argdefs, 0);
        nd = Py_SIZE(argdefs);
    }
    else {
        d = NULL;
        nd = 0;
    }
#if PY_MAJOR_VERSION >= 3
    result = PyEval_EvalCodeEx((PyObject*)co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, kwdefs, closure);
#else
    result = PyEval_EvalCodeEx(co, globals, (PyObject *)NULL,
                               args, nargs,
                               k, (int)nk,
                               d, (int)nd, closure);
#endif
    Py_XDECREF(kwtuple);
done:
    Py_LeaveRecursiveCall();
    return result;
}
#endif
#endif

/* PyCFunctionFastCall */
  #if CYTHON_FAST_PYCCALL
static CYTHON_INLINE PyObject * __Pyx_PyCFunction_FastCall(PyObject *func_obj, PyObject **args, Py_ssize_t nargs) {
    PyCFunctionObject *func = (PyCFunctionObject*)func_obj;
    PyCFunction meth = PyCFunction_GET_FUNCTION(func);
    PyObject *self = PyCFunction_GET_SELF(func);
    int flags = PyCFunction_GET_FLAGS(func);
    assert(PyCFunction_Check(func));
    assert(METH_FASTCALL == (flags & ~(METH_CLASS | METH_STATIC | METH_COEXIST | METH_KEYWORDS)));
    assert(nargs >= 0);
    assert(nargs == 0 || args != NULL);
    /* _PyCFunction_FastCallDict() must not be called with an exception set,
       because it may clear it (directly or indirectly) and so the
       caller loses its exception */
    assert(!PyErr_Occurred());
    if ((PY_VERSION_HEX < 0x030700A0) || unlikely(flags & METH_KEYWORDS)) {
        return (*((__Pyx_PyCFunctionFastWithKeywords)meth)) (self, args, nargs, NULL);
    } else {
        return (*((__Pyx_PyCFunctionFast)meth)) (self, args, nargs);
    }
}
#endif

/* PyObjectCall */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_Call(PyObject *func, PyObject *arg, PyObject *kw) {
    PyObject *result;
    ternaryfunc call = func->ob_type->tp_call;
    if (unlikely(!call))
        return PyObject_Call(func, arg, kw);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = (*call)(func, arg, kw);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* GetAttr */
  static CYTHON_INLINE PyObject *__Pyx_GetAttr(PyObject *o, PyObject *n) {
#if CYTHON_COMPILING_IN_CPYTHON
#if PY_MAJOR_VERSION >= 3
    if (likely(PyUnicode_Check(n)))
#else
    if (likely(PyString_Check(n)))
#endif
        return __Pyx_PyObject_GetAttrStr(o, n);
#endif
    return PyObject_GetAttr(o, n);
}

/* HasAttr */
  static CYTHON_INLINE int __Pyx_HasAttr(PyObject *o, PyObject *n) {
    PyObject *r;
    if (unlikely(!__Pyx_PyBaseString_Check(n))) {
        PyErr_SetString(PyExc_TypeError,
                        "hasattr(): attribute name must be string");
        return -1;
    }
    r = __Pyx_GetAttr(o, n);
    if (unlikely(!r)) {
        PyErr_Clear();
        return 0;
    } else {
        Py_DECREF(r);
        return 1;
    }
}

/* PyObjectCallMethO */
  #if CYTHON_COMPILING_IN_CPYTHON
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallMethO(PyObject *func, PyObject *arg) {
    PyObject *self, *result;
    PyCFunction cfunc;
    cfunc = PyCFunction_GET_FUNCTION(func);
    self = PyCFunction_GET_SELF(func);
    if (unlikely(Py_EnterRecursiveCall((char*)" while calling a Python object")))
        return NULL;
    result = cfunc(self, arg);
    Py_LeaveRecursiveCall();
    if (unlikely(!result) && unlikely(!PyErr_Occurred())) {
        PyErr_SetString(
            PyExc_SystemError,
            "NULL result without error in PyObject_Call");
    }
    return result;
}
#endif

/* PyObjectCallOneArg */
  #if CYTHON_COMPILING_IN_CPYTHON
static PyObject* __Pyx__PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_New(1);
    if (unlikely(!args)) return NULL;
    Py_INCREF(arg);
    PyTuple_SET_ITEM(args, 0, arg);
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
#if CYTHON_FAST_PYCALL
    if (PyFunction_Check(func)) {
        return __Pyx_PyFunction_FastCall(func, &arg, 1);
    }
#endif
    if (likely(PyCFunction_Check(func))) {
        if (likely(PyCFunction_GET_FLAGS(func) & METH_O)) {
            return __Pyx_PyObject_CallMethO(func, arg);
#if CYTHON_FAST_PYCCALL
        } else if (PyCFunction_GET_FLAGS(func) & METH_FASTCALL) {
            return __Pyx_PyCFunction_FastCall(func, &arg, 1);
#endif
        }
    }
    return __Pyx__PyObject_CallOneArg(func, arg);
}
#else
static CYTHON_INLINE PyObject* __Pyx_PyObject_CallOneArg(PyObject *func, PyObject *arg) {
    PyObject *result;
    PyObject *args = PyTuple_Pack(1, arg);
    if (unlikely(!args)) return NULL;
    result = __Pyx_PyObject_Call(func, args, NULL);
    Py_DECREF(args);
    return result;
}
#endif

/* GetItemInt */
  static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Generic(PyObject *o, PyObject* j) {
    PyObject *r;
    if (!j) return NULL;
    r = PyObject_GetItem(o, j);
    Py_DECREF(j);
    return r;
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_List_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyList_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyList_GET_SIZE(o)))) {
        PyObject *r = PyList_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Tuple_Fast(PyObject *o, Py_ssize_t i,
                                                              CYTHON_NCP_UNUSED int wraparound,
                                                              CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS
    Py_ssize_t wrapped_i = i;
    if (wraparound & unlikely(i < 0)) {
        wrapped_i += PyTuple_GET_SIZE(o);
    }
    if ((!boundscheck) || likely((0 <= wrapped_i) & (wrapped_i < PyTuple_GET_SIZE(o)))) {
        PyObject *r = PyTuple_GET_ITEM(o, wrapped_i);
        Py_INCREF(r);
        return r;
    }
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
#else
    return PySequence_GetItem(o, i);
#endif
}
static CYTHON_INLINE PyObject *__Pyx_GetItemInt_Fast(PyObject *o, Py_ssize_t i, int is_list,
                                                     CYTHON_NCP_UNUSED int wraparound,
                                                     CYTHON_NCP_UNUSED int boundscheck) {
#if CYTHON_ASSUME_SAFE_MACROS && !CYTHON_AVOID_BORROWED_REFS && CYTHON_USE_TYPE_SLOTS
    if (is_list || PyList_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyList_GET_SIZE(o);
        if ((!boundscheck) || (likely((n >= 0) & (n < PyList_GET_SIZE(o))))) {
            PyObject *r = PyList_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    }
    else if (PyTuple_CheckExact(o)) {
        Py_ssize_t n = ((!wraparound) | likely(i >= 0)) ? i : i + PyTuple_GET_SIZE(o);
        if ((!boundscheck) || likely((n >= 0) & (n < PyTuple_GET_SIZE(o)))) {
            PyObject *r = PyTuple_GET_ITEM(o, n);
            Py_INCREF(r);
            return r;
        }
    } else {
        PySequenceMethods *m = Py_TYPE(o)->tp_as_sequence;
        if (likely(m && m->sq_item)) {
            if (wraparound && unlikely(i < 0) && likely(m->sq_length)) {
                Py_ssize_t l = m->sq_length(o);
                if (likely(l >= 0)) {
                    i += l;
                } else {
                    if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                        return NULL;
                    PyErr_Clear();
                }
            }
            return m->sq_item(o, i);
        }
    }
#else
    if (is_list || PySequence_Check(o)) {
        return PySequence_GetItem(o, i);
    }
#endif
    return __Pyx_GetItemInt_Generic(o, PyInt_FromSsize_t(i));
}

/* PyErrFetchRestore */
  #if CYTHON_FAST_THREAD_STATE
static CYTHON_INLINE void __Pyx_ErrRestoreInState(PyThreadState *tstate, PyObject *type, PyObject *value, PyObject *tb) {
    PyObject *tmp_type, *tmp_value, *tmp_tb;
    tmp_type = tstate->curexc_type;
    tmp_value = tstate->curexc_value;
    tmp_tb = tstate->curexc_traceback;
    tstate->curexc_type = type;
    tstate->curexc_value = value;
    tstate->curexc_traceback = tb;
    Py_XDECREF(tmp_type);
    Py_XDECREF(tmp_value);
    Py_XDECREF(tmp_tb);
}
static CYTHON_INLINE void __Pyx_ErrFetchInState(PyThreadState *tstate, PyObject **type, PyObject **value, PyObject **tb) {
    *type = tstate->curexc_type;
    *value = tstate->curexc_value;
    *tb = tstate->curexc_traceback;
    tstate->curexc_type = 0;
    tstate->curexc_value = 0;
    tstate->curexc_traceback = 0;
}
#endif

/* RaiseException */
  #if PY_MAJOR_VERSION < 3
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb,
                        CYTHON_UNUSED PyObject *cause) {
    __Pyx_PyThreadState_declare
    Py_XINCREF(type);
    if (!value || value == Py_None)
        value = NULL;
    else
        Py_INCREF(value);
    if (!tb || tb == Py_None)
        tb = NULL;
    else {
        Py_INCREF(tb);
        if (!PyTraceBack_Check(tb)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: arg 3 must be a traceback or None");
            goto raise_error;
        }
    }
    if (PyType_Check(type)) {
#if CYTHON_COMPILING_IN_PYPY
        if (!value) {
            Py_INCREF(Py_None);
            value = Py_None;
        }
#endif
        PyErr_NormalizeException(&type, &value, &tb);
    } else {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto raise_error;
        }
        value = type;
        type = (PyObject*) Py_TYPE(type);
        Py_INCREF(type);
        if (!PyType_IsSubtype((PyTypeObject *)type, (PyTypeObject *)PyExc_BaseException)) {
            PyErr_SetString(PyExc_TypeError,
                "raise: exception class must be a subclass of BaseException");
            goto raise_error;
        }
    }
    __Pyx_PyThreadState_assign
    __Pyx_ErrRestore(type, value, tb);
    return;
raise_error:
    Py_XDECREF(value);
    Py_XDECREF(type);
    Py_XDECREF(tb);
    return;
}
#else
static void __Pyx_Raise(PyObject *type, PyObject *value, PyObject *tb, PyObject *cause) {
    PyObject* owned_instance = NULL;
    if (tb == Py_None) {
        tb = 0;
    } else if (tb && !PyTraceBack_Check(tb)) {
        PyErr_SetString(PyExc_TypeError,
            "raise: arg 3 must be a traceback or None");
        goto bad;
    }
    if (value == Py_None)
        value = 0;
    if (PyExceptionInstance_Check(type)) {
        if (value) {
            PyErr_SetString(PyExc_TypeError,
                "instance exception may not have a separate value");
            goto bad;
        }
        value = type;
        type = (PyObject*) Py_TYPE(value);
    } else if (PyExceptionClass_Check(type)) {
        PyObject *instance_class = NULL;
        if (value && PyExceptionInstance_Check(value)) {
            instance_class = (PyObject*) Py_TYPE(value);
            if (instance_class != type) {
                int is_subclass = PyObject_IsSubclass(instance_class, type);
                if (!is_subclass) {
                    instance_class = NULL;
                } else if (unlikely(is_subclass == -1)) {
                    goto bad;
                } else {
                    type = instance_class;
                }
            }
        }
        if (!instance_class) {
            PyObject *args;
            if (!value)
                args = PyTuple_New(0);
            else if (PyTuple_Check(value)) {
                Py_INCREF(value);
                args = value;
            } else
                args = PyTuple_Pack(1, value);
            if (!args)
                goto bad;
            owned_instance = PyObject_Call(type, args, NULL);
            Py_DECREF(args);
            if (!owned_instance)
                goto bad;
            value = owned_instance;
            if (!PyExceptionInstance_Check(value)) {
                PyErr_Format(PyExc_TypeError,
                             "calling %R should have returned an instance of "
                             "BaseException, not %R",
                             type, Py_TYPE(value));
                goto bad;
            }
        }
    } else {
        PyErr_SetString(PyExc_TypeError,
            "raise: exception class must be a subclass of BaseException");
        goto bad;
    }
#if PY_VERSION_HEX >= 0x03030000
    if (cause) {
#else
    if (cause && cause != Py_None) {
#endif
        PyObject *fixed_cause;
        if (cause == Py_None) {
            fixed_cause = NULL;
        } else if (PyExceptionClass_Check(cause)) {
            fixed_cause = PyObject_CallObject(cause, NULL);
            if (fixed_cause == NULL)
                goto bad;
        } else if (PyExceptionInstance_Check(cause)) {
            fixed_cause = cause;
            Py_INCREF(fixed_cause);
        } else {
            PyErr_SetString(PyExc_TypeError,
                            "exception causes must derive from "
                            "BaseException");
            goto bad;
        }
        PyException_SetCause(value, fixed_cause);
    }
    PyErr_SetObject(type, value);
    if (tb) {
#if CYTHON_COMPILING_IN_PYPY
        PyObject *tmp_type, *tmp_value, *tmp_tb;
        PyErr_Fetch(&tmp_type, &tmp_value, &tmp_tb);
        Py_INCREF(tb);
        PyErr_Restore(tmp_type, tmp_value, tb);
        Py_XDECREF(tmp_tb);
#else
        PyThreadState *tstate = PyThreadState_GET();
        PyObject* tmp_tb = tstate->curexc_traceback;
        if (tb != tmp_tb) {
            Py_INCREF(tb);
            tstate->curexc_traceback = tb;
            Py_XDECREF(tmp_tb);
        }
#endif
    }
bad:
    Py_XDECREF(owned_instance);
    return;
}
#endif

/* SliceObject */
    static CYTHON_INLINE PyObject* __Pyx_PyObject_GetSlice(PyObject* obj,
        Py_ssize_t cstart, Py_ssize_t cstop,
        PyObject** _py_start, PyObject** _py_stop, PyObject** _py_slice,
        int has_cstart, int has_cstop, CYTHON_UNUSED int wraparound) {
#if CYTHON_USE_TYPE_SLOTS
    PyMappingMethods* mp;
#if PY_MAJOR_VERSION < 3
    PySequenceMethods* ms = Py_TYPE(obj)->tp_as_sequence;
    if (likely(ms && ms->sq_slice)) {
        if (!has_cstart) {
            if (_py_start && (*_py_start != Py_None)) {
                cstart = __Pyx_PyIndex_AsSsize_t(*_py_start);
                if ((cstart == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstart = 0;
        }
        if (!has_cstop) {
            if (_py_stop && (*_py_stop != Py_None)) {
                cstop = __Pyx_PyIndex_AsSsize_t(*_py_stop);
                if ((cstop == (Py_ssize_t)-1) && PyErr_Occurred()) goto bad;
            } else
                cstop = PY_SSIZE_T_MAX;
        }
        if (wraparound && unlikely((cstart < 0) | (cstop < 0)) && likely(ms->sq_length)) {
            Py_ssize_t l = ms->sq_length(obj);
            if (likely(l >= 0)) {
                if (cstop < 0) {
                    cstop += l;
                    if (cstop < 0) cstop = 0;
                }
                if (cstart < 0) {
                    cstart += l;
                    if (cstart < 0) cstart = 0;
                }
            } else {
                if (!PyErr_ExceptionMatches(PyExc_OverflowError))
                    goto bad;
                PyErr_Clear();
            }
        }
        return ms->sq_slice(obj, cstart, cstop);
    }
#endif
    mp = Py_TYPE(obj)->tp_as_mapping;
    if (likely(mp && mp->mp_subscript))
#endif
    {
        PyObject* result;
        PyObject *py_slice, *py_start, *py_stop;
        if (_py_slice) {
            py_slice = *_py_slice;
        } else {
            PyObject* owned_start = NULL;
            PyObject* owned_stop = NULL;
            if (_py_start) {
                py_start = *_py_start;
            } else {
                if (has_cstart) {
                    owned_start = py_start = PyInt_FromSsize_t(cstart);
                    if (unlikely(!py_start)) goto bad;
                } else
                    py_start = Py_None;
            }
            if (_py_stop) {
                py_stop = *_py_stop;
            } else {
                if (has_cstop) {
                    owned_stop = py_stop = PyInt_FromSsize_t(cstop);
                    if (unlikely(!py_stop)) {
                        Py_XDECREF(owned_start);
                        goto bad;
                    }
                } else
                    py_stop = Py_None;
            }
            py_slice = PySlice_New(py_start, py_stop, Py_None);
            Py_XDECREF(owned_start);
            Py_XDECREF(owned_stop);
            if (unlikely(!py_slice)) goto bad;
        }
#if CYTHON_USE_TYPE_SLOTS
        result = mp->mp_subscript(obj, py_slice);
#else
        result = PyObject_GetItem(obj, py_slice);
#endif
        if (!_py_slice) {
            Py_DECREF(py_slice);
        }
        return result;
    }
    PyErr_Format(PyExc_TypeError,
        "'%.200s' object is unsliceable", Py_TYPE(obj)->tp_name);
bad:
    return NULL;
}

/* PyIntBinop */
    #if !CYTHON_COMPILING_IN_PYPY
static PyObject* __Pyx_PyInt_AddObjC(PyObject *op1, PyObject *op2, CYTHON_UNUSED long intval, CYTHON_UNUSED int inplace) {
    #if PY_MAJOR_VERSION < 3
    if (likely(PyInt_CheckExact(op1))) {
        const long b = intval;
        long x;
        long a = PyInt_AS_LONG(op1);
            x = (long)((unsigned long)a + b);
            if (likely((x^a) >= 0 || (x^b) >= 0))
                return PyInt_FromLong(x);
            return PyLong_Type.tp_as_number->nb_add(op1, op2);
    }
    #endif
    #if CYTHON_USE_PYLONG_INTERNALS
    if (likely(PyLong_CheckExact(op1))) {
        const long b = intval;
        long a, x;
#ifdef HAVE_LONG_LONG
        const PY_LONG_LONG llb = intval;
        PY_LONG_LONG lla, llx;
#endif
        const digit* digits = ((PyLongObject*)op1)->ob_digit;
        const Py_ssize_t size = Py_SIZE(op1);
        if (likely(__Pyx_sst_abs(size) <= 1)) {
            a = likely(size) ? digits[0] : 0;
            if (size == -1) a = -a;
        } else {
            switch (size) {
                case -2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 2:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        a = (long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 2 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 3:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        a = (long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 3 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case -4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = -(PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                case 4:
                    if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                        a = (long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0]));
                        break;
#ifdef HAVE_LONG_LONG
                    } else if (8 * sizeof(PY_LONG_LONG) - 1 > 4 * PyLong_SHIFT) {
                        lla = (PY_LONG_LONG) (((((((((unsigned PY_LONG_LONG)digits[3]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[2]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[1]) << PyLong_SHIFT) | (unsigned PY_LONG_LONG)digits[0]));
                        goto long_long;
#endif
                    }
                default: return PyLong_Type.tp_as_number->nb_add(op1, op2);
            }
        }
                x = a + b;
            return PyLong_FromLong(x);
#ifdef HAVE_LONG_LONG
        long_long:
                llx = lla + llb;
            return PyLong_FromLongLong(llx);
#endif
        
        
    }
    #endif
    if (PyFloat_CheckExact(op1)) {
        const long b = intval;
        double a = PyFloat_AS_DOUBLE(op1);
            double result;
            PyFPE_START_PROTECT("add", return NULL)
            result = ((double)a) + (double)b;
            PyFPE_END_PROTECT(result)
            return PyFloat_FromDouble(result);
    }
    return (inplace ? PyNumber_InPlaceAdd : PyNumber_Add)(op1, op2);
}
#endif

/* Import */
    static PyObject *__Pyx_Import(PyObject *name, PyObject *from_list, int level) {
    PyObject *empty_list = 0;
    PyObject *module = 0;
    PyObject *global_dict = 0;
    PyObject *empty_dict = 0;
    PyObject *list;
    #if PY_VERSION_HEX < 0x03030000
    PyObject *py_import;
    py_import = __Pyx_PyObject_GetAttrStr(__pyx_b, __pyx_n_s_import);
    if (!py_import)
        goto bad;
    #endif
    if (from_list)
        list = from_list;
    else {
        empty_list = PyList_New(0);
        if (!empty_list)
            goto bad;
        list = empty_list;
    }
    global_dict = PyModule_GetDict(__pyx_m);
    if (!global_dict)
        goto bad;
    empty_dict = PyDict_New();
    if (!empty_dict)
        goto bad;
    {
        #if PY_MAJOR_VERSION >= 3
        if (level == -1) {
            if (strchr(__Pyx_MODULE_NAME, '.')) {
                #if PY_VERSION_HEX < 0x03030000
                PyObject *py_level = PyInt_FromLong(1);
                if (!py_level)
                    goto bad;
                module = PyObject_CallFunctionObjArgs(py_import,
                    name, global_dict, empty_dict, list, py_level, NULL);
                Py_DECREF(py_level);
                #else
                module = PyImport_ImportModuleLevelObject(
                    name, global_dict, empty_dict, list, 1);
                #endif
                if (!module) {
                    if (!PyErr_ExceptionMatches(PyExc_ImportError))
                        goto bad;
                    PyErr_Clear();
                }
            }
            level = 0;
        }
        #endif
        if (!module) {
            #if PY_VERSION_HEX < 0x03030000
            PyObject *py_level = PyInt_FromLong(level);
            if (!py_level)
                goto bad;
            module = PyObject_CallFunctionObjArgs(py_import,
                name, global_dict, empty_dict, list, py_level, NULL);
            Py_DECREF(py_level);
            #else
            module = PyImport_ImportModuleLevelObject(
                name, global_dict, empty_dict, list, level);
            #endif
        }
    }
bad:
    #if PY_VERSION_HEX < 0x03030000
    Py_XDECREF(py_import);
    #endif
    Py_XDECREF(empty_list);
    Py_XDECREF(empty_dict);
    return module;
}

/* RaiseTooManyValuesToUnpack */
    static CYTHON_INLINE void __Pyx_RaiseTooManyValuesError(Py_ssize_t expected) {
    PyErr_Format(PyExc_ValueError,
                 "too many values to unpack (expected %" CYTHON_FORMAT_SSIZE_T "d)", expected);
}

/* RaiseNeedMoreValuesToUnpack */
    static CYTHON_INLINE void __Pyx_RaiseNeedMoreValuesError(Py_ssize_t index) {
    PyErr_Format(PyExc_ValueError,
                 "need more than %" CYTHON_FORMAT_SSIZE_T "d value%.1s to unpack",
                 index, (index == 1) ? "" : "s");
}

/* IterFinish */
    static CYTHON_INLINE int __Pyx_IterFinish(void) {
#if CYTHON_FAST_THREAD_STATE
    PyThreadState *tstate = PyThreadState_GET();
    PyObject* exc_type = tstate->curexc_type;
    if (unlikely(exc_type)) {
        if (likely(exc_type == PyExc_StopIteration) || PyErr_GivenExceptionMatches(exc_type, PyExc_StopIteration)) {
            PyObject *exc_value, *exc_tb;
            exc_value = tstate->curexc_value;
            exc_tb = tstate->curexc_traceback;
            tstate->curexc_type = 0;
            tstate->curexc_value = 0;
            tstate->curexc_traceback = 0;
            Py_DECREF(exc_type);
            Py_XDECREF(exc_value);
            Py_XDECREF(exc_tb);
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#else
    if (unlikely(PyErr_Occurred())) {
        if (likely(PyErr_ExceptionMatches(PyExc_StopIteration))) {
            PyErr_Clear();
            return 0;
        } else {
            return -1;
        }
    }
    return 0;
#endif
}

/* UnpackItemEndCheck */
    static int __Pyx_IternextUnpackEndCheck(PyObject *retval, Py_ssize_t expected) {
    if (unlikely(retval)) {
        Py_DECREF(retval);
        __Pyx_RaiseTooManyValuesError(expected);
        return -1;
    } else {
        return __Pyx_IterFinish();
    }
    return 0;
}

/* CLineInTraceback */
    static int __Pyx_CLineForTraceback(int c_line) {
#ifdef CYTHON_CLINE_IN_TRACEBACK
    return ((CYTHON_CLINE_IN_TRACEBACK)) ? c_line : 0;
#else
    PyObject **cython_runtime_dict;
    PyObject *use_cline;
    cython_runtime_dict = _PyObject_GetDictPtr(__pyx_cython_runtime);
    if (unlikely(!cython_runtime_dict)) {
      PyObject *ptype, *pvalue, *ptraceback;
      PyObject *use_cline_obj;
      PyErr_Fetch(&ptype, &pvalue, &ptraceback);
      use_cline_obj = __Pyx_PyObject_GetAttrStr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback);
      if (use_cline_obj) {
        use_cline = PyObject_Not(use_cline_obj) ? Py_False : Py_True;
        Py_DECREF(use_cline_obj);
      } else {
        use_cline = NULL;
      }
      PyErr_Restore(ptype, pvalue, ptraceback);
    } else {
      use_cline = PyDict_GetItem(*_PyObject_GetDictPtr(__pyx_cython_runtime), __pyx_n_s_cline_in_traceback);
    }
    if (!use_cline) {
        c_line = 0;
        PyObject_SetAttr(__pyx_cython_runtime, __pyx_n_s_cline_in_traceback, Py_False);
    }
    else if (PyObject_Not(use_cline) != 0) {
        c_line = 0;
    }
    return c_line;
#endif
}

/* CodeObjectCache */
    static int __pyx_bisect_code_objects(__Pyx_CodeObjectCacheEntry* entries, int count, int code_line) {
    int start = 0, mid = 0, end = count - 1;
    if (end >= 0 && code_line > entries[end].code_line) {
        return count;
    }
    while (start < end) {
        mid = start + (end - start) / 2;
        if (code_line < entries[mid].code_line) {
            end = mid;
        } else if (code_line > entries[mid].code_line) {
             start = mid + 1;
        } else {
            return mid;
        }
    }
    if (code_line <= entries[mid].code_line) {
        return mid;
    } else {
        return mid + 1;
    }
}
static PyCodeObject *__pyx_find_code_object(int code_line) {
    PyCodeObject* code_object;
    int pos;
    if (unlikely(!code_line) || unlikely(!__pyx_code_cache.entries)) {
        return NULL;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if (unlikely(pos >= __pyx_code_cache.count) || unlikely(__pyx_code_cache.entries[pos].code_line != code_line)) {
        return NULL;
    }
    code_object = __pyx_code_cache.entries[pos].code_object;
    Py_INCREF(code_object);
    return code_object;
}
static void __pyx_insert_code_object(int code_line, PyCodeObject* code_object) {
    int pos, i;
    __Pyx_CodeObjectCacheEntry* entries = __pyx_code_cache.entries;
    if (unlikely(!code_line)) {
        return;
    }
    if (unlikely(!entries)) {
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Malloc(64*sizeof(__Pyx_CodeObjectCacheEntry));
        if (likely(entries)) {
            __pyx_code_cache.entries = entries;
            __pyx_code_cache.max_count = 64;
            __pyx_code_cache.count = 1;
            entries[0].code_line = code_line;
            entries[0].code_object = code_object;
            Py_INCREF(code_object);
        }
        return;
    }
    pos = __pyx_bisect_code_objects(__pyx_code_cache.entries, __pyx_code_cache.count, code_line);
    if ((pos < __pyx_code_cache.count) && unlikely(__pyx_code_cache.entries[pos].code_line == code_line)) {
        PyCodeObject* tmp = entries[pos].code_object;
        entries[pos].code_object = code_object;
        Py_DECREF(tmp);
        return;
    }
    if (__pyx_code_cache.count == __pyx_code_cache.max_count) {
        int new_max = __pyx_code_cache.max_count + 64;
        entries = (__Pyx_CodeObjectCacheEntry*)PyMem_Realloc(
            __pyx_code_cache.entries, (size_t)new_max*sizeof(__Pyx_CodeObjectCacheEntry));
        if (unlikely(!entries)) {
            return;
        }
        __pyx_code_cache.entries = entries;
        __pyx_code_cache.max_count = new_max;
    }
    for (i=__pyx_code_cache.count; i>pos; i--) {
        entries[i] = entries[i-1];
    }
    entries[pos].code_line = code_line;
    entries[pos].code_object = code_object;
    __pyx_code_cache.count++;
    Py_INCREF(code_object);
}

/* AddTraceback */
    #include "compile.h"
#include "frameobject.h"
#include "traceback.h"
static PyCodeObject* __Pyx_CreateCodeObjectForTraceback(
            const char *funcname, int c_line,
            int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyObject *py_srcfile = 0;
    PyObject *py_funcname = 0;
    #if PY_MAJOR_VERSION < 3
    py_srcfile = PyString_FromString(filename);
    #else
    py_srcfile = PyUnicode_FromString(filename);
    #endif
    if (!py_srcfile) goto bad;
    if (c_line) {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #else
        py_funcname = PyUnicode_FromFormat( "%s (%s:%d)", funcname, __pyx_cfilenm, c_line);
        #endif
    }
    else {
        #if PY_MAJOR_VERSION < 3
        py_funcname = PyString_FromString(funcname);
        #else
        py_funcname = PyUnicode_FromString(funcname);
        #endif
    }
    if (!py_funcname) goto bad;
    py_code = __Pyx_PyCode_New(
        0,
        0,
        0,
        0,
        0,
        __pyx_empty_bytes, /*PyObject *code,*/
        __pyx_empty_tuple, /*PyObject *consts,*/
        __pyx_empty_tuple, /*PyObject *names,*/
        __pyx_empty_tuple, /*PyObject *varnames,*/
        __pyx_empty_tuple, /*PyObject *freevars,*/
        __pyx_empty_tuple, /*PyObject *cellvars,*/
        py_srcfile,   /*PyObject *filename,*/
        py_funcname,  /*PyObject *name,*/
        py_line,
        __pyx_empty_bytes  /*PyObject *lnotab*/
    );
    Py_DECREF(py_srcfile);
    Py_DECREF(py_funcname);
    return py_code;
bad:
    Py_XDECREF(py_srcfile);
    Py_XDECREF(py_funcname);
    return NULL;
}
static void __Pyx_AddTraceback(const char *funcname, int c_line,
                               int py_line, const char *filename) {
    PyCodeObject *py_code = 0;
    PyFrameObject *py_frame = 0;
    if (c_line) {
        c_line = __Pyx_CLineForTraceback(c_line);
    }
    py_code = __pyx_find_code_object(c_line ? -c_line : py_line);
    if (!py_code) {
        py_code = __Pyx_CreateCodeObjectForTraceback(
            funcname, c_line, py_line, filename);
        if (!py_code) goto bad;
        __pyx_insert_code_object(c_line ? -c_line : py_line, py_code);
    }
    py_frame = PyFrame_New(
        PyThreadState_GET(), /*PyThreadState *tstate,*/
        py_code,             /*PyCodeObject *code,*/
        __pyx_d,      /*PyObject *globals,*/
        0                    /*PyObject *locals*/
    );
    if (!py_frame) goto bad;
    __Pyx_PyFrame_SetLineNumber(py_frame, py_line);
    PyTraceBack_Here(py_frame);
bad:
    Py_XDECREF(py_code);
    Py_XDECREF(py_frame);
}

/* CIntFromPyVerify */
    #define __PYX_VERIFY_RETURN_INT(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 0)
#define __PYX_VERIFY_RETURN_INT_EXC(target_type, func_type, func_value)\
    __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, 1)
#define __PYX__VERIFY_RETURN_INT(target_type, func_type, func_value, exc)\
    {\
        func_type value = func_value;\
        if (sizeof(target_type) < sizeof(func_type)) {\
            if (unlikely(value != (func_type) (target_type) value)) {\
                func_type zero = 0;\
                if (exc && unlikely(value == (func_type)-1 && PyErr_Occurred()))\
                    return (target_type) -1;\
                if (is_unsigned && unlikely(value < zero))\
                    goto raise_neg_overflow;\
                else\
                    goto raise_overflow;\
            }\
        }\
        return (target_type) value;\
    }

/* CIntToPy */
    static CYTHON_INLINE PyObject* __Pyx_PyInt_From_long(long value) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
    if (is_unsigned) {
        if (sizeof(long) < sizeof(long)) {
            return PyInt_FromLong((long) value);
        } else if (sizeof(long) <= sizeof(unsigned long)) {
            return PyLong_FromUnsignedLong((unsigned long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
            return PyLong_FromUnsignedLongLong((unsigned PY_LONG_LONG) value);
#endif
        }
    } else {
        if (sizeof(long) <= sizeof(long)) {
            return PyInt_FromLong((long) value);
#ifdef HAVE_LONG_LONG
        } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
            return PyLong_FromLongLong((PY_LONG_LONG) value);
#endif
        }
    }
    {
        int one = 1; int little = (int)*(unsigned char *)&one;
        unsigned char *bytes = (unsigned char *)&value;
        return _PyLong_FromByteArray(bytes, sizeof(long),
                                     little, !is_unsigned);
    }
}

/* CIntFromPy */
    static CYTHON_INLINE size_t __Pyx_PyInt_As_size_t(PyObject *x) {
    const size_t neg_one = (size_t) -1, const_zero = (size_t) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(size_t) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(size_t, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (size_t) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case  1: __PYX_VERIFY_RETURN_INT(size_t, digit, digits[0])
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 2 * PyLong_SHIFT) {
                            return (size_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 3 * PyLong_SHIFT) {
                            return (size_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) >= 4 * PyLong_SHIFT) {
                            return (size_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (size_t) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(size_t) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (size_t) 0;
                case -1: __PYX_VERIFY_RETURN_INT(size_t, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(size_t,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(size_t) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(size_t) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                            return (size_t) ((((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(size_t) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(size_t) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                            return (size_t) ((((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(size_t) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) (((size_t)-1)*(((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(size_t) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(size_t, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(size_t) - 1 > 4 * PyLong_SHIFT) {
                            return (size_t) ((((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(size_t) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(size_t) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(size_t, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            size_t val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (size_t) -1;
        }
    } else {
        size_t val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (size_t) -1;
        val = __Pyx_PyInt_As_size_t(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to size_t");
    return (size_t) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to size_t");
    return (size_t) -1;
}

/* CIntFromPy */
    static CYTHON_INLINE int __Pyx_PyInt_As_int(PyObject *x) {
    const int neg_one = (int) -1, const_zero = (int) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(int) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(int, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (int) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case  1: __PYX_VERIFY_RETURN_INT(int, digit, digits[0])
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 2 * PyLong_SHIFT) {
                            return (int) (((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 3 * PyLong_SHIFT) {
                            return (int) (((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) >= 4 * PyLong_SHIFT) {
                            return (int) (((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (int) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(int) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (int) 0;
                case -1: __PYX_VERIFY_RETURN_INT(int, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(int,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(int) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(int) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                            return (int) ((((((int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(int) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(int) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                            return (int) ((((((((int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(int) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) (((int)-1)*(((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(int) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(int, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(int) - 1 > 4 * PyLong_SHIFT) {
                            return (int) ((((((((((int)digits[3]) << PyLong_SHIFT) | (int)digits[2]) << PyLong_SHIFT) | (int)digits[1]) << PyLong_SHIFT) | (int)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(int) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(int) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(int, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            int val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (int) -1;
        }
    } else {
        int val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (int) -1;
        val = __Pyx_PyInt_As_int(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to int");
    return (int) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to int");
    return (int) -1;
}

/* CIntFromPy */
    static CYTHON_INLINE long __Pyx_PyInt_As_long(PyObject *x) {
    const long neg_one = (long) -1, const_zero = (long) 0;
    const int is_unsigned = neg_one > const_zero;
#if PY_MAJOR_VERSION < 3
    if (likely(PyInt_Check(x))) {
        if (sizeof(long) < sizeof(long)) {
            __PYX_VERIFY_RETURN_INT(long, long, PyInt_AS_LONG(x))
        } else {
            long val = PyInt_AS_LONG(x);
            if (is_unsigned && unlikely(val < 0)) {
                goto raise_neg_overflow;
            }
            return (long) val;
        }
    } else
#endif
    if (likely(PyLong_Check(x))) {
        if (is_unsigned) {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case  1: __PYX_VERIFY_RETURN_INT(long, digit, digits[0])
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 2 * PyLong_SHIFT) {
                            return (long) (((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 3 * PyLong_SHIFT) {
                            return (long) (((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) >= 4 * PyLong_SHIFT) {
                            return (long) (((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0]));
                        }
                    }
                    break;
            }
#endif
#if CYTHON_COMPILING_IN_CPYTHON
            if (unlikely(Py_SIZE(x) < 0)) {
                goto raise_neg_overflow;
            }
#else
            {
                int result = PyObject_RichCompareBool(x, Py_False, Py_LT);
                if (unlikely(result < 0))
                    return (long) -1;
                if (unlikely(result == 1))
                    goto raise_neg_overflow;
            }
#endif
            if (sizeof(long) <= sizeof(unsigned long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned long, PyLong_AsUnsignedLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(unsigned PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, unsigned PY_LONG_LONG, PyLong_AsUnsignedLongLong(x))
#endif
            }
        } else {
#if CYTHON_USE_PYLONG_INTERNALS
            const digit* digits = ((PyLongObject*)x)->ob_digit;
            switch (Py_SIZE(x)) {
                case  0: return (long) 0;
                case -1: __PYX_VERIFY_RETURN_INT(long, sdigit, (sdigit) (-(sdigit)digits[0]))
                case  1: __PYX_VERIFY_RETURN_INT(long,  digit, +digits[0])
                case -2:
                    if (8 * sizeof(long) - 1 > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 2:
                    if (8 * sizeof(long) > 1 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 2 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                            return (long) ((((((long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -3:
                    if (8 * sizeof(long) - 1 > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 3:
                    if (8 * sizeof(long) > 2 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 3 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                            return (long) ((((((((long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case -4:
                    if (8 * sizeof(long) - 1 > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, long, -(long) (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) (((long)-1)*(((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
                case 4:
                    if (8 * sizeof(long) > 3 * PyLong_SHIFT) {
                        if (8 * sizeof(unsigned long) > 4 * PyLong_SHIFT) {
                            __PYX_VERIFY_RETURN_INT(long, unsigned long, (((((((((unsigned long)digits[3]) << PyLong_SHIFT) | (unsigned long)digits[2]) << PyLong_SHIFT) | (unsigned long)digits[1]) << PyLong_SHIFT) | (unsigned long)digits[0])))
                        } else if (8 * sizeof(long) - 1 > 4 * PyLong_SHIFT) {
                            return (long) ((((((((((long)digits[3]) << PyLong_SHIFT) | (long)digits[2]) << PyLong_SHIFT) | (long)digits[1]) << PyLong_SHIFT) | (long)digits[0])));
                        }
                    }
                    break;
            }
#endif
            if (sizeof(long) <= sizeof(long)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, long, PyLong_AsLong(x))
#ifdef HAVE_LONG_LONG
            } else if (sizeof(long) <= sizeof(PY_LONG_LONG)) {
                __PYX_VERIFY_RETURN_INT_EXC(long, PY_LONG_LONG, PyLong_AsLongLong(x))
#endif
            }
        }
        {
#if CYTHON_COMPILING_IN_PYPY && !defined(_PyLong_AsByteArray)
            PyErr_SetString(PyExc_RuntimeError,
                            "_PyLong_AsByteArray() not available in PyPy, cannot convert large numbers");
#else
            long val;
            PyObject *v = __Pyx_PyNumber_IntOrLong(x);
 #if PY_MAJOR_VERSION < 3
            if (likely(v) && !PyLong_Check(v)) {
                PyObject *tmp = v;
                v = PyNumber_Long(tmp);
                Py_DECREF(tmp);
            }
 #endif
            if (likely(v)) {
                int one = 1; int is_little = (int)*(unsigned char *)&one;
                unsigned char *bytes = (unsigned char *)&val;
                int ret = _PyLong_AsByteArray((PyLongObject *)v,
                                              bytes, sizeof(val),
                                              is_little, !is_unsigned);
                Py_DECREF(v);
                if (likely(!ret))
                    return val;
            }
#endif
            return (long) -1;
        }
    } else {
        long val;
        PyObject *tmp = __Pyx_PyNumber_IntOrLong(x);
        if (!tmp) return (long) -1;
        val = __Pyx_PyInt_As_long(tmp);
        Py_DECREF(tmp);
        return val;
    }
raise_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "value too large to convert to long");
    return (long) -1;
raise_neg_overflow:
    PyErr_SetString(PyExc_OverflowError,
        "can't convert negative value to long");
    return (long) -1;
}

/* CheckBinaryVersion */
    static int __Pyx_check_binary_version(void) {
    char ctversion[4], rtversion[4];
    PyOS_snprintf(ctversion, 4, "%d.%d", PY_MAJOR_VERSION, PY_MINOR_VERSION);
    PyOS_snprintf(rtversion, 4, "%s", Py_GetVersion());
    if (ctversion[0] != rtversion[0] || ctversion[2] != rtversion[2]) {
        char message[200];
        PyOS_snprintf(message, sizeof(message),
                      "compiletime version %s of module '%.100s' "
                      "does not match runtime version %s",
                      ctversion, __Pyx_MODULE_NAME, rtversion);
        return PyErr_WarnEx(NULL, message, 1);
    }
    return 0;
}

/* InitStrings */
    static int __Pyx_InitStrings(__Pyx_StringTabEntry *t) {
    while (t->p) {
        #if PY_MAJOR_VERSION < 3
        if (t->is_unicode) {
            *t->p = PyUnicode_DecodeUTF8(t->s, t->n - 1, NULL);
        } else if (t->intern) {
            *t->p = PyString_InternFromString(t->s);
        } else {
            *t->p = PyString_FromStringAndSize(t->s, t->n - 1);
        }
        #else
        if (t->is_unicode | t->is_str) {
            if (t->intern) {
                *t->p = PyUnicode_InternFromString(t->s);
            } else if (t->encoding) {
                *t->p = PyUnicode_Decode(t->s, t->n - 1, t->encoding, NULL);
            } else {
                *t->p = PyUnicode_FromStringAndSize(t->s, t->n - 1);
            }
        } else {
            *t->p = PyBytes_FromStringAndSize(t->s, t->n - 1);
        }
        #endif
        if (!*t->p)
            return -1;
        if (PyObject_Hash(*t->p) == -1)
            PyErr_Clear();
        ++t;
    }
    return 0;
}

static CYTHON_INLINE PyObject* __Pyx_PyUnicode_FromString(const char* c_str) {
    return __Pyx_PyUnicode_FromStringAndSize(c_str, (Py_ssize_t)strlen(c_str));
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsString(PyObject* o) {
    Py_ssize_t ignore;
    return __Pyx_PyObject_AsStringAndSize(o, &ignore);
}
static CYTHON_INLINE const char* __Pyx_PyObject_AsStringAndSize(PyObject* o, Py_ssize_t *length) {
#if CYTHON_COMPILING_IN_CPYTHON && (__PYX_DEFAULT_STRING_ENCODING_IS_ASCII || __PYX_DEFAULT_STRING_ENCODING_IS_DEFAULT)
    if (
#if PY_MAJOR_VERSION < 3 && __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
            __Pyx_sys_getdefaultencoding_not_ascii &&
#endif
            PyUnicode_Check(o)) {
#if PY_VERSION_HEX < 0x03030000
        char* defenc_c;
        PyObject* defenc = _PyUnicode_AsDefaultEncodedString(o, NULL);
        if (!defenc) return NULL;
        defenc_c = PyBytes_AS_STRING(defenc);
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        {
            char* end = defenc_c + PyBytes_GET_SIZE(defenc);
            char* c;
            for (c = defenc_c; c < end; c++) {
                if ((unsigned char) (*c) >= 128) {
                    PyUnicode_AsASCIIString(o);
                    return NULL;
                }
            }
        }
#endif
        *length = PyBytes_GET_SIZE(defenc);
        return defenc_c;
#else
        if (__Pyx_PyUnicode_READY(o) == -1) return NULL;
#if __PYX_DEFAULT_STRING_ENCODING_IS_ASCII
        if (PyUnicode_IS_ASCII(o)) {
            *length = PyUnicode_GET_LENGTH(o);
            return PyUnicode_AsUTF8(o);
        } else {
            PyUnicode_AsASCIIString(o);
            return NULL;
        }
#else
        return PyUnicode_AsUTF8AndSize(o, length);
#endif
#endif
    } else
#endif
#if (!CYTHON_COMPILING_IN_PYPY) || (defined(PyByteArray_AS_STRING) && defined(PyByteArray_GET_SIZE))
    if (PyByteArray_Check(o)) {
        *length = PyByteArray_GET_SIZE(o);
        return PyByteArray_AS_STRING(o);
    } else
#endif
    {
        char* result;
        int r = PyBytes_AsStringAndSize(o, &result, length);
        if (unlikely(r < 0)) {
            return NULL;
        } else {
            return result;
        }
    }
}
static CYTHON_INLINE int __Pyx_PyObject_IsTrue(PyObject* x) {
   int is_true = x == Py_True;
   if (is_true | (x == Py_False) | (x == Py_None)) return is_true;
   else return PyObject_IsTrue(x);
}
static CYTHON_INLINE PyObject* __Pyx_PyNumber_IntOrLong(PyObject* x) {
#if CYTHON_USE_TYPE_SLOTS
  PyNumberMethods *m;
#endif
  const char *name = NULL;
  PyObject *res = NULL;
#if PY_MAJOR_VERSION < 3
  if (PyInt_Check(x) || PyLong_Check(x))
#else
  if (PyLong_Check(x))
#endif
    return __Pyx_NewRef(x);
#if CYTHON_USE_TYPE_SLOTS
  m = Py_TYPE(x)->tp_as_number;
  #if PY_MAJOR_VERSION < 3
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Int(x);
  }
  else if (m && m->nb_long) {
    name = "long";
    res = PyNumber_Long(x);
  }
  #else
  if (m && m->nb_int) {
    name = "int";
    res = PyNumber_Long(x);
  }
  #endif
#else
  res = PyNumber_Int(x);
#endif
  if (res) {
#if PY_MAJOR_VERSION < 3
    if (!PyInt_Check(res) && !PyLong_Check(res)) {
#else
    if (!PyLong_Check(res)) {
#endif
      PyErr_Format(PyExc_TypeError,
                   "__%.4s__ returned non-%.4s (type %.200s)",
                   name, name, Py_TYPE(res)->tp_name);
      Py_DECREF(res);
      return NULL;
    }
  }
  else if (!PyErr_Occurred()) {
    PyErr_SetString(PyExc_TypeError,
                    "an integer is required");
  }
  return res;
}
static CYTHON_INLINE Py_ssize_t __Pyx_PyIndex_AsSsize_t(PyObject* b) {
  Py_ssize_t ival;
  PyObject *x;
#if PY_MAJOR_VERSION < 3
  if (likely(PyInt_CheckExact(b))) {
    if (sizeof(Py_ssize_t) >= sizeof(long))
        return PyInt_AS_LONG(b);
    else
        return PyInt_AsSsize_t(x);
  }
#endif
  if (likely(PyLong_CheckExact(b))) {
    #if CYTHON_USE_PYLONG_INTERNALS
    const digit* digits = ((PyLongObject*)b)->ob_digit;
    const Py_ssize_t size = Py_SIZE(b);
    if (likely(__Pyx_sst_abs(size) <= 1)) {
        ival = likely(size) ? digits[0] : 0;
        if (size == -1) ival = -ival;
        return ival;
    } else {
      switch (size) {
         case 2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -2:
           if (8 * sizeof(Py_ssize_t) > 2 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -3:
           if (8 * sizeof(Py_ssize_t) > 3 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case 4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return (Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
         case -4:
           if (8 * sizeof(Py_ssize_t) > 4 * PyLong_SHIFT) {
             return -(Py_ssize_t) (((((((((size_t)digits[3]) << PyLong_SHIFT) | (size_t)digits[2]) << PyLong_SHIFT) | (size_t)digits[1]) << PyLong_SHIFT) | (size_t)digits[0]));
           }
           break;
      }
    }
    #endif
    return PyLong_AsSsize_t(b);
  }
  x = PyNumber_Index(b);
  if (!x) return -1;
  ival = PyInt_AsSsize_t(x);
  Py_DECREF(x);
  return ival;
}
static CYTHON_INLINE PyObject * __Pyx_PyInt_FromSize_t(size_t ival) {
    return PyInt_FromSize_t(ival);
}


#endif /* Py_PYTHON_H */
